{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "228px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "11_TC1_Cluster_PCA&tSNE.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "G3xrb51fMGGL"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengyaoo/FNL_GenesSelection/blob/main/11_TC1_Cluster_PCA%26tSNE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-iE_t7nyh1Q"
      },
      "source": [
        "# Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-23T11:46:55.156880Z",
          "start_time": "2020-11-23T11:46:54.748422Z"
        },
        "id": "V5Zg0wifMGGJ"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os, sys, gzip, glob, json, time, argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from pandas.io.json import json_normalize\n",
        "\n",
        "from pandas.io.json import json_normalize\n",
        "from keras.utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten\n",
        "from keras import optimizers\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.models import Sequential, Model, model_from_json, model_from_yaml\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import sklearn.manifold as sk_manif\n",
        "from keras.models import model_from_json\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwUo3_68MGGJ"
      },
      "source": [
        "# Data Preparation   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNRDQKlmiyGw",
        "outputId": "22a2ec0e-09df-43e7-dbbb-a0fd32947476"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-23T06:24:03.697460Z",
          "start_time": "2020-11-23T06:04:41.100012Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "f8SDzPeuMGGK",
        "outputId": "3750fb4d-0b9b-4b15-dcb8-55a95c713729"
      },
      "source": [
        "# Read features and output files \n",
        "TC1data15 = pd.read_csv(\"/content/drive/My Drive/FNL_TC1/TC1-S1-data15-genename.tsv\", sep=\"\\t\", low_memory = False)\n",
        "#TC1data15 = sfeatures1\n",
        "TC1data15"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TSPAN6</th>\n",
              "      <th>TNMD</th>\n",
              "      <th>DPM1</th>\n",
              "      <th>SCYL3</th>\n",
              "      <th>C1orf112</th>\n",
              "      <th>FGR</th>\n",
              "      <th>CFH</th>\n",
              "      <th>FUCA2</th>\n",
              "      <th>GCLC</th>\n",
              "      <th>NFYA</th>\n",
              "      <th>STPG1</th>\n",
              "      <th>NIPAL3</th>\n",
              "      <th>LAS1L</th>\n",
              "      <th>ENPP4</th>\n",
              "      <th>SEMA3F</th>\n",
              "      <th>CFTR</th>\n",
              "      <th>ANKIB1</th>\n",
              "      <th>CYP51A1</th>\n",
              "      <th>KRIT1</th>\n",
              "      <th>RAD52</th>\n",
              "      <th>MYH16</th>\n",
              "      <th>BAD</th>\n",
              "      <th>LAP3</th>\n",
              "      <th>CD99</th>\n",
              "      <th>HS3ST1</th>\n",
              "      <th>AOC1</th>\n",
              "      <th>WNT16</th>\n",
              "      <th>HECW1</th>\n",
              "      <th>MAD1L1</th>\n",
              "      <th>LASP1</th>\n",
              "      <th>SNX11</th>\n",
              "      <th>TMEM176A</th>\n",
              "      <th>M6PR</th>\n",
              "      <th>KLHL13</th>\n",
              "      <th>CYP26B1</th>\n",
              "      <th>ICA1</th>\n",
              "      <th>DBNDD1</th>\n",
              "      <th>ALS2</th>\n",
              "      <th>CASP10</th>\n",
              "      <th>CFLAR</th>\n",
              "      <th>...</th>\n",
              "      <th>PLCXD1.1</th>\n",
              "      <th>WASH6P.1</th>\n",
              "      <th>WASIR1.1</th>\n",
              "      <th>IL3RA.1</th>\n",
              "      <th>SHOX.1</th>\n",
              "      <th>ASMT.1</th>\n",
              "      <th>AKAP17A.1</th>\n",
              "      <th>CSF2RA.1</th>\n",
              "      <th>CRLF2.1</th>\n",
              "      <th>ZBED1.1</th>\n",
              "      <th>RNA5SP498.1</th>\n",
              "      <th>TRPC6P.1</th>\n",
              "      <th>RP13-297E16.4.1</th>\n",
              "      <th>DHRSX-IT1.1</th>\n",
              "      <th>CD99P1.1</th>\n",
              "      <th>RPL14P5.1</th>\n",
              "      <th>LINC00685.1</th>\n",
              "      <th>DDX11L16.1</th>\n",
              "      <th>TCEB1P24.1</th>\n",
              "      <th>LL0YNC03-29C1.1.1</th>\n",
              "      <th>KRT18P53.1</th>\n",
              "      <th>LINC00102.1</th>\n",
              "      <th>RP13-297E16.5.1</th>\n",
              "      <th>FABP5P13.1</th>\n",
              "      <th>ASMTL-AS1.1</th>\n",
              "      <th>LINC00106.1</th>\n",
              "      <th>DPH3P2.1</th>\n",
              "      <th>RP11-309M23.1.1</th>\n",
              "      <th>AMDP1.1</th>\n",
              "      <th>BX649553.1.1</th>\n",
              "      <th>BX649553.2.1</th>\n",
              "      <th>BX649553.3.1</th>\n",
              "      <th>BX649553.4.1</th>\n",
              "      <th>MIR3690.1</th>\n",
              "      <th>AJ271736.10.1</th>\n",
              "      <th>Metazoa_SRP.305</th>\n",
              "      <th>AJ271736.1.1</th>\n",
              "      <th>MIR6089.1</th>\n",
              "      <th>RP13-465B17.5.1</th>\n",
              "      <th>RP13-465B17.4.1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.829525</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.062846</td>\n",
              "      <td>0.913543</td>\n",
              "      <td>0.809255</td>\n",
              "      <td>0.365063</td>\n",
              "      <td>1.315347</td>\n",
              "      <td>1.936558</td>\n",
              "      <td>0.657487</td>\n",
              "      <td>1.437908</td>\n",
              "      <td>0.551174</td>\n",
              "      <td>0.719120</td>\n",
              "      <td>1.393872</td>\n",
              "      <td>1.118917</td>\n",
              "      <td>1.987483</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.393437</td>\n",
              "      <td>0.257243</td>\n",
              "      <td>1.161696</td>\n",
              "      <td>1.141140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.644513</td>\n",
              "      <td>1.765476</td>\n",
              "      <td>2.090856</td>\n",
              "      <td>0.549029</td>\n",
              "      <td>0.718534</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.750320</td>\n",
              "      <td>1.912752</td>\n",
              "      <td>1.141035</td>\n",
              "      <td>1.480509</td>\n",
              "      <td>1.567273</td>\n",
              "      <td>0.164270</td>\n",
              "      <td>0.101726</td>\n",
              "      <td>1.313405</td>\n",
              "      <td>1.158674</td>\n",
              "      <td>1.141063</td>\n",
              "      <td>0.798311</td>\n",
              "      <td>1.360485</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.541309</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.815986</td>\n",
              "      <td>0.593689</td>\n",
              "      <td>0.557331</td>\n",
              "      <td>0.608742</td>\n",
              "      <td>1.376983</td>\n",
              "      <td>1.592561</td>\n",
              "      <td>0.569209</td>\n",
              "      <td>1.103958</td>\n",
              "      <td>0.478385</td>\n",
              "      <td>1.033488</td>\n",
              "      <td>1.008026</td>\n",
              "      <td>0.758012</td>\n",
              "      <td>1.681421</td>\n",
              "      <td>1.453353</td>\n",
              "      <td>1.018066</td>\n",
              "      <td>0.223281</td>\n",
              "      <td>0.788680</td>\n",
              "      <td>0.693349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.098755</td>\n",
              "      <td>1.643610</td>\n",
              "      <td>2.391891</td>\n",
              "      <td>0.884490</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.128794</td>\n",
              "      <td>1.836294</td>\n",
              "      <td>0.778508</td>\n",
              "      <td>1.743826</td>\n",
              "      <td>1.415378</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.173718</td>\n",
              "      <td>0.749825</td>\n",
              "      <td>1.539502</td>\n",
              "      <td>0.676204</td>\n",
              "      <td>0.761320</td>\n",
              "      <td>0.964733</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.282789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.895928</td>\n",
              "      <td>0.571531</td>\n",
              "      <td>0.332523</td>\n",
              "      <td>0.576545</td>\n",
              "      <td>1.171834</td>\n",
              "      <td>1.351888</td>\n",
              "      <td>0.836259</td>\n",
              "      <td>1.423673</td>\n",
              "      <td>0.200690</td>\n",
              "      <td>0.874702</td>\n",
              "      <td>0.876875</td>\n",
              "      <td>0.904634</td>\n",
              "      <td>1.109651</td>\n",
              "      <td>0.617534</td>\n",
              "      <td>0.904555</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.724887</td>\n",
              "      <td>0.834916</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.567345</td>\n",
              "      <td>1.350662</td>\n",
              "      <td>2.029576</td>\n",
              "      <td>0.246144</td>\n",
              "      <td>2.193634</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.820252</td>\n",
              "      <td>1.581194</td>\n",
              "      <td>0.813868</td>\n",
              "      <td>1.547321</td>\n",
              "      <td>1.086540</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.464639</td>\n",
              "      <td>1.080810</td>\n",
              "      <td>0.456927</td>\n",
              "      <td>0.652686</td>\n",
              "      <td>0.725820</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.388260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.905475</td>\n",
              "      <td>0.399374</td>\n",
              "      <td>0.259750</td>\n",
              "      <td>0.219200</td>\n",
              "      <td>0.494936</td>\n",
              "      <td>1.822393</td>\n",
              "      <td>0.619865</td>\n",
              "      <td>0.793788</td>\n",
              "      <td>0.221321</td>\n",
              "      <td>0.567275</td>\n",
              "      <td>1.334915</td>\n",
              "      <td>0.984844</td>\n",
              "      <td>1.915951</td>\n",
              "      <td>0.458862</td>\n",
              "      <td>0.611663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.341496</td>\n",
              "      <td>0.735198</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.955291</td>\n",
              "      <td>1.635719</td>\n",
              "      <td>2.151499</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.956215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.867816</td>\n",
              "      <td>1.938688</td>\n",
              "      <td>1.049283</td>\n",
              "      <td>2.416171</td>\n",
              "      <td>1.523516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.663285</td>\n",
              "      <td>0.998184</td>\n",
              "      <td>0.468721</td>\n",
              "      <td>0.456932</td>\n",
              "      <td>0.606861</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.389160</td>\n",
              "      <td>0.530588</td>\n",
              "      <td>2.316735</td>\n",
              "      <td>0.349455</td>\n",
              "      <td>0.189075</td>\n",
              "      <td>0.623428</td>\n",
              "      <td>0.801534</td>\n",
              "      <td>1.685248</td>\n",
              "      <td>0.784901</td>\n",
              "      <td>0.922292</td>\n",
              "      <td>0.489743</td>\n",
              "      <td>0.968513</td>\n",
              "      <td>1.126255</td>\n",
              "      <td>0.844110</td>\n",
              "      <td>0.942073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.995927</td>\n",
              "      <td>0.169634</td>\n",
              "      <td>0.783794</td>\n",
              "      <td>0.614325</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.429317</td>\n",
              "      <td>1.840638</td>\n",
              "      <td>2.187733</td>\n",
              "      <td>0.238939</td>\n",
              "      <td>1.196076</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.040287</td>\n",
              "      <td>1.824699</td>\n",
              "      <td>0.927491</td>\n",
              "      <td>1.818541</td>\n",
              "      <td>1.317428</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.098857</td>\n",
              "      <td>1.070776</td>\n",
              "      <td>0.503460</td>\n",
              "      <td>0.218645</td>\n",
              "      <td>0.819567</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4495</th>\n",
              "      <td>1.897300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.829995</td>\n",
              "      <td>0.656801</td>\n",
              "      <td>0.001333</td>\n",
              "      <td>0.528604</td>\n",
              "      <td>2.618544</td>\n",
              "      <td>1.993496</td>\n",
              "      <td>1.487510</td>\n",
              "      <td>1.049062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.258848</td>\n",
              "      <td>1.455348</td>\n",
              "      <td>0.853410</td>\n",
              "      <td>1.215961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.571925</td>\n",
              "      <td>0.644190</td>\n",
              "      <td>0.536399</td>\n",
              "      <td>0.215012</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.704930</td>\n",
              "      <td>2.033992</td>\n",
              "      <td>2.059344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.811806</td>\n",
              "      <td>1.861269</td>\n",
              "      <td>1.084387</td>\n",
              "      <td>2.724172</td>\n",
              "      <td>1.159409</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.193960</td>\n",
              "      <td>1.282674</td>\n",
              "      <td>0.685311</td>\n",
              "      <td>0.463778</td>\n",
              "      <td>0.899169</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4496</th>\n",
              "      <td>1.740598</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.711895</td>\n",
              "      <td>0.752968</td>\n",
              "      <td>0.007715</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.653929</td>\n",
              "      <td>1.066585</td>\n",
              "      <td>1.322050</td>\n",
              "      <td>0.912586</td>\n",
              "      <td>0.171709</td>\n",
              "      <td>0.411544</td>\n",
              "      <td>1.287344</td>\n",
              "      <td>1.132854</td>\n",
              "      <td>0.781237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.690635</td>\n",
              "      <td>0.646052</td>\n",
              "      <td>0.710316</td>\n",
              "      <td>0.376035</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.615999</td>\n",
              "      <td>1.516171</td>\n",
              "      <td>1.912234</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906349</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.268835</td>\n",
              "      <td>1.832812</td>\n",
              "      <td>1.110583</td>\n",
              "      <td>2.753908</td>\n",
              "      <td>0.998629</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.265282</td>\n",
              "      <td>2.165311</td>\n",
              "      <td>0.786107</td>\n",
              "      <td>0.498035</td>\n",
              "      <td>0.821050</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4497</th>\n",
              "      <td>1.586418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.628429</td>\n",
              "      <td>0.956585</td>\n",
              "      <td>0.452424</td>\n",
              "      <td>0.487102</td>\n",
              "      <td>2.690098</td>\n",
              "      <td>1.546263</td>\n",
              "      <td>1.425311</td>\n",
              "      <td>1.104933</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.589411</td>\n",
              "      <td>1.175582</td>\n",
              "      <td>0.711138</td>\n",
              "      <td>1.257908</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.636265</td>\n",
              "      <td>0.637182</td>\n",
              "      <td>0.639831</td>\n",
              "      <td>0.695027</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.737526</td>\n",
              "      <td>1.594892</td>\n",
              "      <td>2.118825</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.165699</td>\n",
              "      <td>1.668184</td>\n",
              "      <td>1.049200</td>\n",
              "      <td>0.428853</td>\n",
              "      <td>1.358031</td>\n",
              "      <td>0.276150</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.466674</td>\n",
              "      <td>1.404276</td>\n",
              "      <td>0.876752</td>\n",
              "      <td>0.883134</td>\n",
              "      <td>1.270713</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4498</th>\n",
              "      <td>2.218943</td>\n",
              "      <td>0.093382</td>\n",
              "      <td>1.762568</td>\n",
              "      <td>0.730552</td>\n",
              "      <td>0.860424</td>\n",
              "      <td>0.460689</td>\n",
              "      <td>2.512682</td>\n",
              "      <td>1.811498</td>\n",
              "      <td>1.352379</td>\n",
              "      <td>1.079363</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.279831</td>\n",
              "      <td>1.425266</td>\n",
              "      <td>0.213678</td>\n",
              "      <td>0.960109</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.708863</td>\n",
              "      <td>0.691359</td>\n",
              "      <td>0.708711</td>\n",
              "      <td>0.402048</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.533745</td>\n",
              "      <td>2.210578</td>\n",
              "      <td>2.161809</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.689109</td>\n",
              "      <td>1.691350</td>\n",
              "      <td>1.040084</td>\n",
              "      <td>2.536552</td>\n",
              "      <td>1.177287</td>\n",
              "      <td>0.312845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.160542</td>\n",
              "      <td>0.815007</td>\n",
              "      <td>0.742583</td>\n",
              "      <td>0.238696</td>\n",
              "      <td>0.931445</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4499</th>\n",
              "      <td>1.497944</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.855045</td>\n",
              "      <td>0.953935</td>\n",
              "      <td>0.712152</td>\n",
              "      <td>1.157931</td>\n",
              "      <td>1.256340</td>\n",
              "      <td>1.789477</td>\n",
              "      <td>1.270349</td>\n",
              "      <td>1.314717</td>\n",
              "      <td>0.506252</td>\n",
              "      <td>1.188643</td>\n",
              "      <td>1.367650</td>\n",
              "      <td>0.804773</td>\n",
              "      <td>2.044645</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.324218</td>\n",
              "      <td>0.436810</td>\n",
              "      <td>1.063213</td>\n",
              "      <td>0.771213</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.720783</td>\n",
              "      <td>2.095478</td>\n",
              "      <td>2.298405</td>\n",
              "      <td>0.918700</td>\n",
              "      <td>1.104082</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.073634</td>\n",
              "      <td>1.984428</td>\n",
              "      <td>1.411239</td>\n",
              "      <td>1.500740</td>\n",
              "      <td>1.640880</td>\n",
              "      <td>0.380160</td>\n",
              "      <td>0.951493</td>\n",
              "      <td>1.209071</td>\n",
              "      <td>1.198688</td>\n",
              "      <td>0.695059</td>\n",
              "      <td>1.037333</td>\n",
              "      <td>1.130970</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4500 rows Ã— 60483 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        TSPAN6      TNMD      DPM1  ...  MIR6089.1  RP13-465B17.5.1  RP13-465B17.4.1\n",
              "0     1.829525  0.000000  2.062846  ...        0.0              0.0              0.0\n",
              "1     1.541309  0.000000  1.815986  ...        0.0              0.0              0.0\n",
              "2     1.282789  0.000000  1.895928  ...        0.0              0.0              0.0\n",
              "3     1.388260  0.000000  1.905475  ...        0.0              0.0              0.0\n",
              "4     1.389160  0.530588  2.316735  ...        0.0              0.0              0.0\n",
              "...        ...       ...       ...  ...        ...              ...              ...\n",
              "4495  1.897300  0.000000  1.829995  ...        0.0              0.0              0.0\n",
              "4496  1.740598  0.000000  1.711895  ...        0.0              0.0              0.0\n",
              "4497  1.586418  0.000000  1.628429  ...        0.0              0.0              0.0\n",
              "4498  2.218943  0.093382  1.762568  ...        0.0              0.0              0.0\n",
              "4499  1.497944  0.000000  1.855045  ...        0.0              0.0              0.0\n",
              "\n",
              "[4500 rows x 60483 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-23T06:24:03.787859Z",
          "start_time": "2020-11-23T06:24:03.727784Z"
        },
        "id": "955mydtlMGGK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1e583f41-9e52-4e51-d00a-d04de862c7b1"
      },
      "source": [
        "outcome = pd.read_csv('/content/drive/My Drive/FNL_TC1/TC1-outcome-data15-projectname.tsv', sep='\\t')\n",
        "outcome"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Project_id_name</th>\n",
              "      <th>Project_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TCGA-OV</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TCGA-OV</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TCGA-OV</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TCGA-OV</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TCGA-OV</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4495</th>\n",
              "      <td>TCGA-LIHC</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4496</th>\n",
              "      <td>TCGA-LIHC</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4497</th>\n",
              "      <td>TCGA-LIHC</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4498</th>\n",
              "      <td>TCGA-LIHC</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4499</th>\n",
              "      <td>TCGA-CESC</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4500 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Project_id_name  Project_id\n",
              "0            TCGA-OV          10\n",
              "1            TCGA-OV          10\n",
              "2            TCGA-OV          10\n",
              "3            TCGA-OV          10\n",
              "4            TCGA-OV          10\n",
              "...              ...         ...\n",
              "4495       TCGA-LIHC           7\n",
              "4496       TCGA-LIHC           7\n",
              "4497       TCGA-LIHC           7\n",
              "4498       TCGA-LIHC           7\n",
              "4499       TCGA-CESC           2\n",
              "\n",
              "[4500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IloCAWM_9KVi",
        "outputId": "9d661989-03ea-4954-8ec6-f68e8ccd8878"
      },
      "source": [
        "TC1data15['project_id_name'] = outcome['Project_id_name']\n",
        "TC1data15['project_id'] = outcome['Project_id']\n",
        "\n",
        "TC1data15_cluster = TC1data15.copy()\n",
        "TC1data15_cluster['project_id_name'] = TC1data15_cluster['project_id_name'].replace(['TCGA-CESC','TCGA-LUSC','TCGA-BLCA','TCGA-HNSC'],'SCC')\n",
        "TC1data15_cluster['project_id'] = TC1data15_cluster['project_id'].replace([0,2,4,9],0)\n",
        "\n",
        "cluster_300 = TC1data15_cluster[(TC1data15_cluster['project_id_name'] == 'SCC')].copy().sample(n = 300)\n",
        "TC1data15_reduced = TC1data15_cluster[(TC1data15_cluster['project_id_name'] != 'SCC')].copy()\n",
        "TC1data15_reduced = TC1data15_reduced.append(cluster_300)\n",
        "\n",
        "TC1data15_reduced['project_id'] = TC1data15_reduced['project_id'].replace([13],2)\n",
        "TC1data15_reduced['project_id'] = TC1data15_reduced['project_id'].replace([14],4)\n",
        "TC1data15_reduced['project_id'] = TC1data15_reduced['project_id'].replace([15],9)\n",
        "TC1data15 = TC1data15_reduced.copy()\n",
        "\n",
        "outcome = TC1data15.loc[:,['project_id','project_id_name']]\n",
        "TC1data15 = TC1data15.iloc[:,:-2]\n",
        "\n",
        "TC1data15.shape, outcome.shape"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3600, 60483), (3600, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-23T06:24:03.804464Z",
          "start_time": "2020-11-23T06:24:03.794335Z"
        },
        "id": "515X_Nv0MGGK"
      },
      "source": [
        "#outcome = outcome.values\n",
        "#outcome = outcome['Project_id_name']"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-23T06:24:03.881270Z",
          "start_time": "2020-11-23T06:24:03.811653Z"
        },
        "id": "S4Rqn8X1MGGK"
      },
      "source": [
        "def encode(data): \n",
        "    print('Shape of data (BEFORE encode): %s' % str(data.shape))\n",
        "    encoded = to_categorical(data)\n",
        "    print('Shape of data (AFTER  encode): %s\\n' % str(encoded.shape))\n",
        "    return encoded\n",
        "\n"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oCylRJYfE6W"
      },
      "source": [
        "# ConvNN(PCA) - Top150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywJbj4kcfD8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7666392b-55df-4c78-bda3-e6a911ed20b0"
      },
      "source": [
        "outcome = encode(outcome['project_id'])\n",
        "# outcome = np.expand_dims(outcome, axis=2)\n",
        "# outcome[0].value_counts()"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data (BEFORE encode): (3600,)\n",
            "Shape of data (AFTER  encode): (3600, 13)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71Z6J-bcsuRy"
      },
      "source": [
        "## Train/Test split    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWsySe7Mukdk"
      },
      "source": [
        "TC1data15_selected = TC1data15.loc[:,sum_loading.sort_values(ascending=False)[:150].index]"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJlEUw9osqgU"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(TC1data15_selected, \n",
        "                                                    outcome, \n",
        "                                                    train_size=0.75, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=123, \n",
        "                                                    stratify = outcome)"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2bREIhms0rF"
      },
      "source": [
        "## CONV1D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTEcQ1y3s8eN"
      },
      "source": [
        "# parameters  \n",
        "activation='relu'\n",
        "batch_size=20\n",
        "# Number of sites\n",
        "classes=13\n",
        "drop = 0.1\n",
        "feature_subsample = 0\n",
        "loss='categorical_crossentropy'\n",
        "# metrics='accuracy'\n",
        "out_act='softmax'\n",
        "pool=[1, 10]\n",
        "# optimizer='sgd'\n",
        "shuffle = False \n",
        "epochs=30\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.1)\n",
        "metrics = ['acc']"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XaoBYgBfvEBQ",
        "outputId": "1a33578f-88c6-49cb-abdb-7d3d0289a469"
      },
      "source": [
        "np.expand_dims(X_train, axis=2).shape"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2700, 150, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pSepbtsm88q",
        "outputId": "26289c1d-b15d-4a0b-a417-c650bcff690f"
      },
      "source": [
        "# X_train shape: (3375, 1883)\n",
        "# X_test shape:  (1125, 1883)\n",
        "# Y_train shape: (3375,15)\n",
        "# Y_test shape:  (1125,15)\n",
        "\n",
        "# 1883\n",
        "x_train_len = X_train.shape[1]   \n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# X_train shape: (3375, 1883, 1)\n",
        "# X_test shape:  (1125, 1883, 1)\n",
        "\n",
        "filters = 128 \n",
        "filter_len = 20 \n",
        "stride = 1 \n",
        "\n",
        "# inside pool_list loop\n",
        "pool_list = [1,10]\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# model.add  CONV1D\n",
        "model.add(Conv1D(filters = filters, \n",
        "                 kernel_size = filter_len, \n",
        "                 strides = stride, \n",
        "                 padding='valid', \n",
        "                 input_shape=(x_train_len, 1)))\n",
        "\n",
        "# x_train_len = 60,483\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 1))\n",
        "\n",
        "filters = 128\n",
        "filter_len = 10 \n",
        "stride = 1 \n",
        "# Conv1D\n",
        "model.add(Conv1D(filters=filters, \n",
        "                 kernel_size=filter_len, \n",
        "                 strides=stride, \n",
        "                 padding='valid'))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 10))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200))\n",
        "\n",
        "# activation \n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(20))\n",
        "# activation\n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(13))\n",
        "model.add(Activation(out_act))\n",
        "\n",
        "model.compile( loss= loss, \n",
        "              optimizer = optimizer, \n",
        "              metrics = metrics )\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 131, 128)          2688      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 131, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 131, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 122, 128)          163968    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 122, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 12, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               307400    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                4020      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                273       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 478,349\n",
            "Trainable params: 478,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qu7JwTvvdRM"
      },
      "source": [
        "# save\n",
        "save = '.'\n",
        "output_dir = \"/content/drive/My Drive/FNL_TC1/Model\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "model_name = 'tc1_pca129'\n",
        "path = '{}/{}.autosave.model.h5'.format(output_dir, model_name)\n",
        "checkpointer = ModelCheckpoint(filepath=path,\n",
        "                               verbose=1,\n",
        "                               save_weights_only=True,\n",
        "                               save_best_only=True)\n",
        "\n",
        "csv_logger = CSVLogger('{}/training.log'.format(output_dir))"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rj3tsWoUveI-"
      },
      "source": [
        "# SR: change epsilon to min_delta\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                              factor=0.1, \n",
        "                              patience=10, \n",
        "                              verbose=1, mode='auto', \n",
        "                              min_delta=0.0001, \n",
        "                              cooldown=0, \n",
        "                              min_lr=0)"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGs_-NQ6vijS",
        "outputId": "3df1f803-db19-4a4d-aca4-3534a0a64482"
      },
      "source": [
        "# batch_size = 20 \n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, \n",
        "                    epochs=epochs, verbose=1, validation_data=(X_test, Y_test), \n",
        "                    callbacks = [checkpointer, csv_logger, reduce_lr])\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "135/135 [==============================] - 7s 50ms/step - loss: 2.1313 - acc: 0.2774 - val_loss: 0.5001 - val_acc: 0.8744\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.50009, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca129.autosave.model.h5\n",
            "Epoch 2/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.4957 - acc: 0.8392 - val_loss: 0.2295 - val_acc: 0.9233\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.50009 to 0.22946, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca129.autosave.model.h5\n",
            "Epoch 3/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.2190 - acc: 0.9324 - val_loss: 0.1895 - val_acc: 0.9500\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.22946 to 0.18952, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca129.autosave.model.h5\n",
            "Epoch 4/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.1125 - acc: 0.9659 - val_loss: 0.2343 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.18952\n",
            "Epoch 5/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0997 - acc: 0.9758 - val_loss: 0.1504 - val_acc: 0.9589\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.18952 to 0.15040, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca129.autosave.model.h5\n",
            "Epoch 6/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0751 - acc: 0.9777 - val_loss: 0.1714 - val_acc: 0.9522\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.15040\n",
            "Epoch 7/30\n",
            "135/135 [==============================] - 6s 47ms/step - loss: 0.0467 - acc: 0.9856 - val_loss: 0.1756 - val_acc: 0.9522\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.15040\n",
            "Epoch 8/30\n",
            "135/135 [==============================] - 6s 47ms/step - loss: 0.0287 - acc: 0.9953 - val_loss: 0.1928 - val_acc: 0.9500\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.15040\n",
            "Epoch 9/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0209 - acc: 0.9919 - val_loss: 0.1516 - val_acc: 0.9667\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.15040\n",
            "Epoch 10/30\n",
            "135/135 [==============================] - 6s 45ms/step - loss: 0.0146 - acc: 0.9970 - val_loss: 0.1706 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.15040\n",
            "Epoch 11/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0166 - acc: 0.9946 - val_loss: 0.1752 - val_acc: 0.9578\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.15040\n",
            "Epoch 12/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0277 - acc: 0.9899 - val_loss: 0.1707 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.15040\n",
            "Epoch 13/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0066 - acc: 0.9987 - val_loss: 0.3252 - val_acc: 0.9367\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.15040\n",
            "Epoch 14/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0260 - acc: 0.9917 - val_loss: 0.1984 - val_acc: 0.9578\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.15040\n",
            "Epoch 15/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0144 - acc: 0.9970 - val_loss: 0.1617 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.15040\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 16/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0132 - acc: 0.9972 - val_loss: 0.1519 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.15040\n",
            "Epoch 17/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0050 - acc: 0.9982 - val_loss: 0.1517 - val_acc: 0.9611\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.15040\n",
            "Epoch 18/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0057 - acc: 0.9977 - val_loss: 0.1561 - val_acc: 0.9600\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.15040\n",
            "Epoch 19/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0066 - acc: 0.9975 - val_loss: 0.1576 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.15040\n",
            "Epoch 20/30\n",
            "135/135 [==============================] - 6s 48ms/step - loss: 0.0047 - acc: 0.9997 - val_loss: 0.1615 - val_acc: 0.9589\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.15040\n",
            "Epoch 21/30\n",
            "135/135 [==============================] - 6s 48ms/step - loss: 0.0030 - acc: 0.9999 - val_loss: 0.1647 - val_acc: 0.9600\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.15040\n",
            "Epoch 22/30\n",
            "135/135 [==============================] - 7s 48ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.1675 - val_acc: 0.9589\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.15040\n",
            "Epoch 23/30\n",
            "135/135 [==============================] - 6s 47ms/step - loss: 0.0072 - acc: 0.9988 - val_loss: 0.1651 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.15040\n",
            "Epoch 24/30\n",
            "135/135 [==============================] - 6s 45ms/step - loss: 0.0027 - acc: 0.9998 - val_loss: 0.1648 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.15040\n",
            "Epoch 25/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.1660 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.15040\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 26/30\n",
            "135/135 [==============================] - 6s 45ms/step - loss: 0.0032 - acc: 0.9987 - val_loss: 0.1661 - val_acc: 0.9611\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.15040\n",
            "Epoch 27/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.1665 - val_acc: 0.9611\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.15040\n",
            "Epoch 28/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1665 - val_acc: 0.9611\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.15040\n",
            "Epoch 29/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1666 - val_acc: 0.9611\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.15040\n",
            "Epoch 30/30\n",
            "135/135 [==============================] - 6s 46ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.1668 - val_acc: 0.9622\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.15040\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KceqeO5P9qMQ",
        "outputId": "679e3f75-7f3f-42aa-b30b-05f79019cc07"
      },
      "source": [
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.16680830717086792\n",
            "Test accuracy: 0.9622222185134888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "fdHn3i0W_pu7",
        "outputId": "8ace897c-9b5a-4482-d43c-b30ac96616bc"
      },
      "source": [
        "plt.plot(history.history['acc'],label=\"accuracy\")\n",
        "plt.plot(history.history['val_acc'],label=\"val_accuracy\")\n",
        "plt.plot(history.history['loss'],label=\"loss\")\n",
        "plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.xlabel('epoch')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K7_ZmR2_soA"
      },
      "source": [
        ""
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsGIUqN4qoW"
      },
      "source": [
        "## Save the model/weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2m3cnynufue",
        "outputId": "2825a5f6-b235-454d-997e-464dd428911b"
      },
      "source": [
        "# JSON JSON\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "\n",
        "# save the model architecture to JSON file\n",
        "with open('{}/{}.model.json'.format(output_dir, model_name), 'w') as json_file:\n",
        "    json_file.write(json_model)\n",
        "\n",
        "\n",
        "# YAML YAML\n",
        "# serialize model to YAML\n",
        "model_yaml = model.to_yaml()\n",
        "\n",
        "# save the model architecture to YAML file\n",
        "with open(\"{}/{}.model.yaml\".format(output_dir, model_name), \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "\n",
        "\n",
        "# WEIGHTS HDF5\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"{}/{}.model.h5\".format(output_dir,model_name))\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-yV0Ktr46Y2",
        "outputId": "692d0792-fb49-4266-b503-cd7af138154d"
      },
      "source": [
        "# Open the handle\n",
        "json_file = open('{}/{}.model.json'.format(output_dir, model_name), 'r')\n",
        "\n",
        "# load json and create model\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights('{}/{}.model.h5'.format(output_dir, model_name))\n",
        "print(\"Loaded model from disk\")\n",
        "# loaded_model_json"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djhkDlc2Fbeo",
        "outputId": "2fe0dbd6-df73-4489-8943-8e95ff04a7fb"
      },
      "source": [
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', \n",
        "                     metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.16680830717086792\n",
            "Test accuracy: 0.9622222185134888\n",
            "accuracy: 96.22%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvc0DUNEFbxk"
      },
      "source": [
        "# ConvNN(PCA) - top 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4agjwbFbxl"
      },
      "source": [
        "## Train/Test split    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0niWyzNw6Ax"
      },
      "source": [
        "# from keras.utils import to_categorical\n",
        "# outcome = encode(outcome['Project_id'])"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS9D16qIFbxn"
      },
      "source": [
        "TC1data15_selected = TC1data15.loc[:,sum_loading.sort_values(ascending=False)[:300].index]"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PWsfc3nFbxo"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(TC1data15_selected, \n",
        "                                                    outcome, \n",
        "                                                    train_size=0.75, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=123, \n",
        "                                                    stratify = outcome)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "ELJV_czkHjbj",
        "outputId": "b06040ba-e13a-4cb5-80f7-51451add791d"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MTND4P12</th>\n",
              "      <th>COX6CP1</th>\n",
              "      <th>MINOS1P3</th>\n",
              "      <th>H19</th>\n",
              "      <th>COX20P1</th>\n",
              "      <th>LTF</th>\n",
              "      <th>PLA2G2A</th>\n",
              "      <th>CST1</th>\n",
              "      <th>ERAP2</th>\n",
              "      <th>RPS28P7</th>\n",
              "      <th>HCG4P5</th>\n",
              "      <th>NLRP2</th>\n",
              "      <th>OLFM4</th>\n",
              "      <th>SST</th>\n",
              "      <th>MTRNR2L1</th>\n",
              "      <th>RP11-109M17.2</th>\n",
              "      <th>GSTM1</th>\n",
              "      <th>PIGR</th>\n",
              "      <th>NTS</th>\n",
              "      <th>IGLV8-61</th>\n",
              "      <th>IGHD</th>\n",
              "      <th>IGF2</th>\n",
              "      <th>EEF1A2</th>\n",
              "      <th>PRSS21</th>\n",
              "      <th>DEFB1</th>\n",
              "      <th>MSLN</th>\n",
              "      <th>CXCL5</th>\n",
              "      <th>CXCL14</th>\n",
              "      <th>MSMB</th>\n",
              "      <th>IGLV10-54</th>\n",
              "      <th>MTND1P23</th>\n",
              "      <th>RP11-467L13.5</th>\n",
              "      <th>C1DP1</th>\n",
              "      <th>IGLV4-60</th>\n",
              "      <th>CD177</th>\n",
              "      <th>BEX1</th>\n",
              "      <th>PCDHB5</th>\n",
              "      <th>PEG10</th>\n",
              "      <th>REG1A</th>\n",
              "      <th>PCSK1N</th>\n",
              "      <th>...</th>\n",
              "      <th>IGLV3-19</th>\n",
              "      <th>C2orf54</th>\n",
              "      <th>AP000351.3</th>\n",
              "      <th>SLITRK6</th>\n",
              "      <th>EPHX3</th>\n",
              "      <th>SPON1</th>\n",
              "      <th>GAL</th>\n",
              "      <th>CLDN2</th>\n",
              "      <th>NUPR1L</th>\n",
              "      <th>BPIFB2</th>\n",
              "      <th>IGLV5-37</th>\n",
              "      <th>ALDH1A1</th>\n",
              "      <th>SOSTDC1</th>\n",
              "      <th>UCHL1</th>\n",
              "      <th>SOX2</th>\n",
              "      <th>IGHA2</th>\n",
              "      <th>KRT20</th>\n",
              "      <th>CYP24A1</th>\n",
              "      <th>MAOB</th>\n",
              "      <th>SIX2</th>\n",
              "      <th>GLDC</th>\n",
              "      <th>CNTFR</th>\n",
              "      <th>AGR3</th>\n",
              "      <th>IGLV1-36</th>\n",
              "      <th>EDN2</th>\n",
              "      <th>C1QL1</th>\n",
              "      <th>IGHV4-39</th>\n",
              "      <th>AREG</th>\n",
              "      <th>ERP27</th>\n",
              "      <th>HOXC10</th>\n",
              "      <th>CYP4F11</th>\n",
              "      <th>PALM3</th>\n",
              "      <th>CASC9</th>\n",
              "      <th>ALB</th>\n",
              "      <th>MAGEA4</th>\n",
              "      <th>HS6ST2</th>\n",
              "      <th>PDZK1IP1</th>\n",
              "      <th>FABP6</th>\n",
              "      <th>RNU4-2</th>\n",
              "      <th>KRT6A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1.630203</td>\n",
              "      <td>0.245745</td>\n",
              "      <td>0.617475</td>\n",
              "      <td>1.531048</td>\n",
              "      <td>0.217401</td>\n",
              "      <td>0.151195</td>\n",
              "      <td>1.115843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.270616</td>\n",
              "      <td>2.456450</td>\n",
              "      <td>1.540806</td>\n",
              "      <td>1.604526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.007129</td>\n",
              "      <td>0.539980</td>\n",
              "      <td>1.672453</td>\n",
              "      <td>1.648313</td>\n",
              "      <td>0.848560</td>\n",
              "      <td>0.477534</td>\n",
              "      <td>1.559609</td>\n",
              "      <td>0.254776</td>\n",
              "      <td>1.392720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259556</td>\n",
              "      <td>2.906409</td>\n",
              "      <td>2.674018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.016438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.061648</td>\n",
              "      <td>1.948268</td>\n",
              "      <td>0.997439</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192577</td>\n",
              "      <td>0.871038</td>\n",
              "      <td>1.590481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.511048</td>\n",
              "      <td>...</td>\n",
              "      <td>3.141406</td>\n",
              "      <td>0.927782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.136099</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.732365</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.261969</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.772130</td>\n",
              "      <td>1.053052</td>\n",
              "      <td>1.571418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.704472</td>\n",
              "      <td>0.305838</td>\n",
              "      <td>0.581240</td>\n",
              "      <td>0.511640</td>\n",
              "      <td>0.249679</td>\n",
              "      <td>0.108730</td>\n",
              "      <td>0.755715</td>\n",
              "      <td>0.275099</td>\n",
              "      <td>2.402433</td>\n",
              "      <td>0.591675</td>\n",
              "      <td>1.439627</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.004386</td>\n",
              "      <td>1.454823</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.156108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.108844</td>\n",
              "      <td>1.291987</td>\n",
              "      <td>3.052099</td>\n",
              "      <td>0.906333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>0.913352</td>\n",
              "      <td>1.187209</td>\n",
              "      <td>1.191948</td>\n",
              "      <td>0.555510</td>\n",
              "      <td>0.101678</td>\n",
              "      <td>0.197502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.837544</td>\n",
              "      <td>2.730934</td>\n",
              "      <td>1.052432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.726351</td>\n",
              "      <td>1.403615</td>\n",
              "      <td>1.051820</td>\n",
              "      <td>2.120729</td>\n",
              "      <td>0.853222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.094274</td>\n",
              "      <td>2.055905</td>\n",
              "      <td>1.146227</td>\n",
              "      <td>1.219891</td>\n",
              "      <td>2.955669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.038178</td>\n",
              "      <td>0.648074</td>\n",
              "      <td>0.117067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.220576</td>\n",
              "      <td>0.402360</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.686118</td>\n",
              "      <td>0.876908</td>\n",
              "      <td>3.009419</td>\n",
              "      <td>0.875238</td>\n",
              "      <td>...</td>\n",
              "      <td>2.119397</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.867344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.253958</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.842135</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.331460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.281293</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.259375</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.835548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.643530</td>\n",
              "      <td>0.524939</td>\n",
              "      <td>1.713803</td>\n",
              "      <td>2.174148</td>\n",
              "      <td>1.037635</td>\n",
              "      <td>1.146442</td>\n",
              "      <td>1.267564</td>\n",
              "      <td>0.721462</td>\n",
              "      <td>1.437761</td>\n",
              "      <td>0.546841</td>\n",
              "      <td>0.793268</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.990324</td>\n",
              "      <td>2.307448</td>\n",
              "      <td>0.329036</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3589</th>\n",
              "      <td>2.220811</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.682109</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046970</td>\n",
              "      <td>1.167290</td>\n",
              "      <td>0.292887</td>\n",
              "      <td>0.507182</td>\n",
              "      <td>3.079196</td>\n",
              "      <td>0.818919</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.961562</td>\n",
              "      <td>1.040686</td>\n",
              "      <td>0.743894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.330595</td>\n",
              "      <td>2.815335</td>\n",
              "      <td>1.581307</td>\n",
              "      <td>2.238399</td>\n",
              "      <td>2.180905</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.355650</td>\n",
              "      <td>0.842468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.386654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.184625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.028673</td>\n",
              "      <td>1.127188</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.246907</td>\n",
              "      <td>1.109462</td>\n",
              "      <td>0.211231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.696248</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.462865</td>\n",
              "      <td>1.919780</td>\n",
              "      <td>0.865260</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.326671</td>\n",
              "      <td>0.849403</td>\n",
              "      <td>0.940579</td>\n",
              "      <td>0.204173</td>\n",
              "      <td>0.359708</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.543897</td>\n",
              "      <td>0.930868</td>\n",
              "      <td>1.722511</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.761585</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.822418</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.749791</td>\n",
              "      <td>1.436924</td>\n",
              "      <td>2.065042</td>\n",
              "      <td>0.850816</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.609317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3076</th>\n",
              "      <td>2.145148</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.741737</td>\n",
              "      <td>0.293831</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.231487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.559480</td>\n",
              "      <td>3.247094</td>\n",
              "      <td>1.450892</td>\n",
              "      <td>1.563270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.485607</td>\n",
              "      <td>1.713526</td>\n",
              "      <td>0.350373</td>\n",
              "      <td>0.064323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.523034</td>\n",
              "      <td>0.764995</td>\n",
              "      <td>0.350342</td>\n",
              "      <td>2.994062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.199072</td>\n",
              "      <td>0.478690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.387969</td>\n",
              "      <td>0.719004</td>\n",
              "      <td>1.892532</td>\n",
              "      <td>1.264773</td>\n",
              "      <td>0.269078</td>\n",
              "      <td>1.413557</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.137254</td>\n",
              "      <td>...</td>\n",
              "      <td>1.535040</td>\n",
              "      <td>0.115746</td>\n",
              "      <td>0.913475</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.795731</td>\n",
              "      <td>0.324460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.126812</td>\n",
              "      <td>1.263876</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.340142</td>\n",
              "      <td>2.059237</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.008338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.196203</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.451725</td>\n",
              "      <td>0.531147</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.596170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.473813</td>\n",
              "      <td>1.781845</td>\n",
              "      <td>1.872300</td>\n",
              "      <td>1.529948</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.204500</td>\n",
              "      <td>1.837543</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.482656</td>\n",
              "      <td>2.285589</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.439283</td>\n",
              "      <td>0.744030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>2.424581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.597254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.483586</td>\n",
              "      <td>2.980569</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.404005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.407930</td>\n",
              "      <td>0.920673</td>\n",
              "      <td>1.255731</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.008415</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379663</td>\n",
              "      <td>1.571226</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.881680</td>\n",
              "      <td>...</td>\n",
              "      <td>0.730314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062392</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.273454</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.433383</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.864628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.767294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.798710</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.497212</td>\n",
              "      <td>0.178639</td>\n",
              "      <td>0.018674</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.621385</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.835857</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.186081</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.579660</td>\n",
              "      <td>0.208330</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.839656</td>\n",
              "      <td>1.429009</td>\n",
              "      <td>0.255109</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.277703</td>\n",
              "      <td>2.712425</td>\n",
              "      <td>0.794239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.293664</td>\n",
              "      <td>3.313475</td>\n",
              "      <td>0.548254</td>\n",
              "      <td>1.804727</td>\n",
              "      <td>0.996873</td>\n",
              "      <td>0.276268</td>\n",
              "      <td>1.485759</td>\n",
              "      <td>0.428918</td>\n",
              "      <td>0.040674</td>\n",
              "      <td>1.607600</td>\n",
              "      <td>0.255471</td>\n",
              "      <td>1.786542</td>\n",
              "      <td>1.670226</td>\n",
              "      <td>2.619017</td>\n",
              "      <td>0.208159</td>\n",
              "      <td>1.332983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.692859</td>\n",
              "      <td>0.839632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.397033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.436764</td>\n",
              "      <td>1.446019</td>\n",
              "      <td>1.019898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.511442</td>\n",
              "      <td>...</td>\n",
              "      <td>1.310780</td>\n",
              "      <td>0.554341</td>\n",
              "      <td>0.380650</td>\n",
              "      <td>0.051614</td>\n",
              "      <td>1.731279</td>\n",
              "      <td>2.603556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.358146</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.037414</td>\n",
              "      <td>0.600863</td>\n",
              "      <td>2.347875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.119505</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.539113</td>\n",
              "      <td>0.003540</td>\n",
              "      <td>0.452539</td>\n",
              "      <td>0.770163</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.150496</td>\n",
              "      <td>1.141767</td>\n",
              "      <td>0.725164</td>\n",
              "      <td>2.304725</td>\n",
              "      <td>1.328992</td>\n",
              "      <td>0.878512</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.214997</td>\n",
              "      <td>1.008706</td>\n",
              "      <td>1.096842</td>\n",
              "      <td>0.098597</td>\n",
              "      <td>1.403100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.830478</td>\n",
              "      <td>0.076875</td>\n",
              "      <td>3.457129</td>\n",
              "      <td>1.277230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>2.750741</td>\n",
              "      <td>1.903935</td>\n",
              "      <td>1.317420</td>\n",
              "      <td>1.590538</td>\n",
              "      <td>0.954487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.280087</td>\n",
              "      <td>2.433834</td>\n",
              "      <td>1.483788</td>\n",
              "      <td>1.090087</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.186110</td>\n",
              "      <td>0.329995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.171839</td>\n",
              "      <td>1.353750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.581947</td>\n",
              "      <td>0.321847</td>\n",
              "      <td>0.084858</td>\n",
              "      <td>1.971798</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.504796</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.933845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.678913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.798841</td>\n",
              "      <td>0.277061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.789633</td>\n",
              "      <td>1.092416</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.595930</td>\n",
              "      <td>...</td>\n",
              "      <td>1.141120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.708778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.148113</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.926384</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.362641</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.506284</td>\n",
              "      <td>1.398098</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.317111</td>\n",
              "      <td>0.177758</td>\n",
              "      <td>1.430755</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.403067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.695060</td>\n",
              "      <td>1.706466</td>\n",
              "      <td>0.307176</td>\n",
              "      <td>1.867929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.818607</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.569462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>1.180832</td>\n",
              "      <td>0.069298</td>\n",
              "      <td>0.509213</td>\n",
              "      <td>0.609682</td>\n",
              "      <td>0.354218</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088950</td>\n",
              "      <td>0.872839</td>\n",
              "      <td>0.833113</td>\n",
              "      <td>2.991207</td>\n",
              "      <td>0.993619</td>\n",
              "      <td>0.574628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.582023</td>\n",
              "      <td>0.192836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.256023</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.111299</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.648261</td>\n",
              "      <td>2.301634</td>\n",
              "      <td>3.350609</td>\n",
              "      <td>0.005845</td>\n",
              "      <td>1.175837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.512434</td>\n",
              "      <td>1.563923</td>\n",
              "      <td>0.788736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.862815</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.277425</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.908714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.365142</td>\n",
              "      <td>0.805889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.379361</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.617930</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.130598</td>\n",
              "      <td>1.123123</td>\n",
              "      <td>1.531971</td>\n",
              "      <td>0.050762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.089291</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.402295</td>\n",
              "      <td>2.049080</td>\n",
              "      <td>0.251092</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.351510</td>\n",
              "      <td>0.783621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.224210</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.481600</td>\n",
              "      <td>1.411065</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.220524</td>\n",
              "      <td>2.048934</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.829802</td>\n",
              "      <td>0.273621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1701</th>\n",
              "      <td>0.722351</td>\n",
              "      <td>0.007708</td>\n",
              "      <td>0.913464</td>\n",
              "      <td>1.817012</td>\n",
              "      <td>1.188879</td>\n",
              "      <td>0.794850</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.755633</td>\n",
              "      <td>2.921452</td>\n",
              "      <td>1.691892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.206214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.261600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.705418</td>\n",
              "      <td>0.098885</td>\n",
              "      <td>1.803165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.144449</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.507038</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.834062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.161650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.780210</td>\n",
              "      <td>1.148091</td>\n",
              "      <td>1.604973</td>\n",
              "      <td>2.409997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.350393</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.657150</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.017671</td>\n",
              "      <td>0.153545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.562642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.478475</td>\n",
              "      <td>0.316139</td>\n",
              "      <td>0.362043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.758445</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.405386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.030069</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250904</td>\n",
              "      <td>1.689286</td>\n",
              "      <td>0.863361</td>\n",
              "      <td>1.155803</td>\n",
              "      <td>0.818671</td>\n",
              "      <td>0.499324</td>\n",
              "      <td>1.757079</td>\n",
              "      <td>0.572754</td>\n",
              "      <td>1.007657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.052165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.592051</td>\n",
              "      <td>1.481020</td>\n",
              "      <td>0.337056</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1073</th>\n",
              "      <td>0.842437</td>\n",
              "      <td>0.025683</td>\n",
              "      <td>1.426289</td>\n",
              "      <td>0.770426</td>\n",
              "      <td>1.095488</td>\n",
              "      <td>0.082222</td>\n",
              "      <td>1.945936</td>\n",
              "      <td>1.243680</td>\n",
              "      <td>0.382470</td>\n",
              "      <td>1.664291</td>\n",
              "      <td>0.303180</td>\n",
              "      <td>0.265456</td>\n",
              "      <td>2.356733</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.448552</td>\n",
              "      <td>1.337918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.161308</td>\n",
              "      <td>0.697870</td>\n",
              "      <td>1.613278</td>\n",
              "      <td>0.091775</td>\n",
              "      <td>0.869876</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.729846</td>\n",
              "      <td>0.637325</td>\n",
              "      <td>1.480615</td>\n",
              "      <td>2.578329</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591709</td>\n",
              "      <td>0.893089</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100443</td>\n",
              "      <td>0.307338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.955610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.007735</td>\n",
              "      <td>1.142572</td>\n",
              "      <td>0.516762</td>\n",
              "      <td>2.148903</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.876981</td>\n",
              "      <td>1.442148</td>\n",
              "      <td>0.628141</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.064004</td>\n",
              "      <td>1.303103</td>\n",
              "      <td>0.794201</td>\n",
              "      <td>0.384518</td>\n",
              "      <td>0.225101</td>\n",
              "      <td>2.632392</td>\n",
              "      <td>1.423823</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192641</td>\n",
              "      <td>0.542987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.404701</td>\n",
              "      <td>1.089544</td>\n",
              "      <td>0.240850</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.061018</td>\n",
              "      <td>1.223052</td>\n",
              "      <td>1.200475</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133351</td>\n",
              "      <td>0.311468</td>\n",
              "      <td>1.487679</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.289004</td>\n",
              "      <td>2.329650</td>\n",
              "      <td>1.793570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164552</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2700 rows Ã— 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      MTND4P12   COX6CP1  MINOS1P3  ...     FABP6    RNU4-2     KRT6A\n",
              "78    1.630203  0.245745  0.617475  ...  1.291987  3.052099  0.906333\n",
              "1425  0.913352  1.187209  1.191948  ...  2.307448  0.329036  0.000000\n",
              "3589  2.220811  0.000000  0.000000  ...  0.850816  0.000000  3.609317\n",
              "3076  2.145148  0.000000  0.741737  ...  0.000000  0.439283  0.744030\n",
              "2536  2.424581  0.000000  0.000000  ...  0.000000  1.186081  0.000000\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "13    1.579660  0.208330  0.000000  ...  0.076875  3.457129  1.277230\n",
              "1515  2.750741  1.903935  1.317420  ...  0.000000  0.000000  0.000000\n",
              "67    1.180832  0.069298  0.509213  ...  0.000000  3.829802  0.273621\n",
              "1701  0.722351  0.007708  0.913464  ...  1.481020  0.337056  0.000000\n",
              "1073  0.842437  0.025683  1.426289  ...  1.793570  0.000000  0.164552\n",
              "\n",
              "[2700 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4NiRi1SFbxo"
      },
      "source": [
        "## CONV1D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjD0T5I2Fbxo"
      },
      "source": [
        "# parameters  \n",
        "activation='relu'\n",
        "batch_size=20\n",
        "# Number of sites\n",
        "classes=13\n",
        "drop = 0.1\n",
        "feature_subsample = 0\n",
        "loss='categorical_crossentropy'\n",
        "# metrics='accuracy'\n",
        "out_act='softmax'\n",
        "pool=[1, 10]\n",
        "# optimizer='sgd'\n",
        "shuffle = False \n",
        "epochs=30\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.1)\n",
        "metrics = ['acc']"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztdyDFcoTXTH"
      },
      "source": [
        "# X_train shape: (3375, 300)\n",
        "# X_test shape:  (1125, 300)\n",
        "# Y_train shape: (3375,15)\n",
        "# Y_test shape:  (1125,15)\n",
        "\n",
        "# 300\n",
        "x_train_len = X_train.shape[1]   \n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# X_train shape: (3375, 300, 1)\n",
        "# X_test shape:  (1125, 300, 1)\n",
        "\n",
        "filters = 128 \n",
        "filter_len = 20 \n",
        "stride = 1 \n",
        "\n",
        "# inside pool_list loop\n",
        "pool_list = [1,10]\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muxPrNNYFbxp",
        "outputId": "d3857d5d-1a7f-44cb-8273-40ed4b7cb2c0"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add  CONV1D\n",
        "model.add(Conv1D(filters = filters, \n",
        "                 kernel_size = filter_len, \n",
        "                 strides = stride, \n",
        "                 padding='valid', \n",
        "                 input_shape=(x_train_len, 1)))\n",
        "\n",
        "# x_train_len = 300\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 1))\n",
        "\n",
        "filters = 128\n",
        "filter_len = 10 \n",
        "stride = 1 \n",
        "# Conv1D\n",
        "model.add(Conv1D(filters=filters, \n",
        "                 kernel_size=filter_len, \n",
        "                 strides=stride, \n",
        "                 padding='valid'))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 10))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200))\n",
        "\n",
        "# activation \n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(20))\n",
        "# activation\n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(13))\n",
        "model.add(Activation(out_act))\n",
        "\n",
        "model.compile( loss= loss, \n",
        "              optimizer = optimizer, \n",
        "              metrics = metrics )\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 281, 128)          2688      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 281, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 281, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 272, 128)          163968    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 272, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3456)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               691400    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                4020      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                273       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 862,349\n",
            "Trainable params: 862,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwoVbhQMFbxp"
      },
      "source": [
        "# save\n",
        "# save = '/content/drive/My Drive/FNL_TC1/'\n",
        "output_dir = \"/content/drive/My Drive/FNL_TC1/Model\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "model_name = 'tc1_pca300'\n",
        "path = '{}/{}.autosave.model.h5'.format(output_dir, model_name)\n",
        "checkpointer = ModelCheckpoint(filepath=path,\n",
        "                               verbose=1,\n",
        "                               save_weights_only=True,\n",
        "                               save_best_only=True)\n",
        "\n",
        "csv_logger = CSVLogger('{}/training.log'.format(output_dir))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBFfONmUFbxq"
      },
      "source": [
        "# SR: change epsilon to min_delta\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                              factor=0.1, \n",
        "                              patience=10, \n",
        "                              verbose=1, mode='auto', \n",
        "                              min_delta=0.0001, \n",
        "                              cooldown=0, \n",
        "                              min_lr=0)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVfcLEdgFbxq",
        "outputId": "c4d81900-ecb4-4d5d-945a-654e8ffcaf92"
      },
      "source": [
        "# batch_size = 20 \n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, \n",
        "                    epochs=epochs, verbose=1, validation_data=(X_test, Y_test), \n",
        "                    callbacks = [checkpointer, csv_logger, reduce_lr])\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "135/135 [==============================] - 12s 85ms/step - loss: 2.1330 - acc: 0.2719 - val_loss: 0.2158 - val_acc: 0.9478\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.21584, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca300.autosave.model.h5\n",
            "Epoch 2/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.3260 - acc: 0.8948 - val_loss: 0.2163 - val_acc: 0.9389\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.21584\n",
            "Epoch 3/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.1145 - acc: 0.9678 - val_loss: 0.1540 - val_acc: 0.9544\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.21584 to 0.15396, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca300.autosave.model.h5\n",
            "Epoch 4/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0620 - acc: 0.9851 - val_loss: 0.1094 - val_acc: 0.9656\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.15396 to 0.10936, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca300.autosave.model.h5\n",
            "Epoch 5/30\n",
            "135/135 [==============================] - 11s 84ms/step - loss: 0.0326 - acc: 0.9913 - val_loss: 0.0958 - val_acc: 0.9767\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.10936 to 0.09578, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca300.autosave.model.h5\n",
            "Epoch 6/30\n",
            "135/135 [==============================] - 11s 85ms/step - loss: 0.0255 - acc: 0.9919 - val_loss: 0.0963 - val_acc: 0.9722\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.09578\n",
            "Epoch 7/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0284 - acc: 0.9901 - val_loss: 0.1184 - val_acc: 0.9633\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.09578\n",
            "Epoch 8/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0245 - acc: 0.9951 - val_loss: 0.1151 - val_acc: 0.9778\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.09578\n",
            "Epoch 9/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0118 - acc: 0.9957 - val_loss: 0.1102 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.09578\n",
            "Epoch 10/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0126 - acc: 0.9953 - val_loss: 0.1062 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.09578\n",
            "Epoch 11/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.1011 - val_acc: 0.9756\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.09578\n",
            "Epoch 12/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0143 - acc: 0.9939 - val_loss: 0.1046 - val_acc: 0.9767\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.09578\n",
            "Epoch 13/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0074 - acc: 0.9982 - val_loss: 0.0912 - val_acc: 0.9778\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.09578 to 0.09115, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca300.autosave.model.h5\n",
            "Epoch 14/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0042 - acc: 0.9994 - val_loss: 0.1170 - val_acc: 0.9778\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.09115\n",
            "Epoch 15/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.1118 - val_acc: 0.9778\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.09115\n",
            "Epoch 16/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0063 - acc: 0.9989 - val_loss: 0.1377 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.09115\n",
            "Epoch 17/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0030 - acc: 0.9998 - val_loss: 0.1218 - val_acc: 0.9767\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.09115\n",
            "Epoch 18/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.1240 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.09115\n",
            "Epoch 19/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1487 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.09115\n",
            "Epoch 20/30\n",
            "135/135 [==============================] - 11s 83ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1854 - val_acc: 0.9689\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.09115\n",
            "Epoch 21/30\n",
            "135/135 [==============================] - 11s 84ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.2017 - val_acc: 0.9756\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.09115\n",
            "Epoch 22/30\n",
            "135/135 [==============================] - 12s 87ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.1339 - val_acc: 0.9733\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.09115\n",
            "Epoch 23/30\n",
            "135/135 [==============================] - 13s 94ms/step - loss: 0.0042 - acc: 0.9990 - val_loss: 0.1285 - val_acc: 0.9756\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.09115\n",
            "\n",
            "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 24/30\n",
            "135/135 [==============================] - 11s 84ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.1368 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.09115\n",
            "Epoch 25/30\n",
            "135/135 [==============================] - 11s 85ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.1337 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.09115\n",
            "Epoch 26/30\n",
            "135/135 [==============================] - 11s 84ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1304 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.09115\n",
            "Epoch 27/30\n",
            "135/135 [==============================] - 11s 85ms/step - loss: 0.0015 - acc: 0.9999 - val_loss: 0.1338 - val_acc: 0.9733\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.09115\n",
            "Epoch 28/30\n",
            "135/135 [==============================] - 11s 84ms/step - loss: 0.0034 - acc: 0.9982 - val_loss: 0.1312 - val_acc: 0.9733\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.09115\n",
            "Epoch 29/30\n",
            "135/135 [==============================] - 11s 85ms/step - loss: 0.0030 - acc: 0.9996 - val_loss: 0.1281 - val_acc: 0.9733\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.09115\n",
            "Epoch 30/30\n",
            "135/135 [==============================] - 12s 86ms/step - loss: 0.0026 - acc: 0.9988 - val_loss: 0.1290 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.09115\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppzHiTkLFbxq",
        "outputId": "0a1605e8-4d2d-420f-8bd1-8bf96dbb2993"
      },
      "source": [
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.12903091311454773\n",
            "Test accuracy: 0.9744444489479065\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "O9NCt5MkFbxq",
        "outputId": "326bd9a5-84df-4229-d2ce-12cfb82e59d2"
      },
      "source": [
        "plt.plot(history.history['acc'],label=\"accuracy\")\n",
        "plt.plot(history.history['val_acc'],label=\"val_accuracy\")\n",
        "plt.plot(history.history['loss'],label=\"loss\")\n",
        "plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Top 300 features\")\n",
        "plt.xlabel('epoch')\n"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEWCAYAAACZnQc8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZgcVbn48e9bvUzPmj2ZrCSsgWQCSNhlFy4iEFBDRESJAoIsClyVi1su4sZ1VwQisoMQQRSVn8gSCAhRAgZCVgJkmSQkk2Qye/d0d72/P6q60zOZyXSSnul0z/t5nnqq6lR1nVNd3W+dPlV9SlQVY4wxxcHJdwGMMcbkjgV1Y4wpIhbUjTGmiFhQN8aYImJB3RhjiogFdWOMKSIW1I3phohcKSIbRaRZRIbkuzzGZMOCuskZP/ilBldE2jLmL8pRHreKyFoRaRSR1SJyU6flh4nI6yLS6o8Py1gmIvIjEdniDz8SEekmnxDwU+AMVa1Q1S17UObxIqIiEtzdbRiTLQvqJmf84FehqhXAGuCcjLSHcpTN74CJqloFHAdcJCIfBxCRMPBn4EFgEHAf8Gc/HeBy4DzgUGAKcA7wxW7yGQFEgMU5Kvdu809G9l01WbEPiul1IlIiIj8XkfX+8HMRKfGXnSwitSJyk4hsFpFVO6vVq+pyVW3JSHKB/f3pk4Eg8HNVjanqLwEBTvWXfw74iarWquo64CfAJV2U90BguT+7TUSe99MnisgzIrJVRJaLyAUZr/mYiPzH/wWxVkRmZWxyXsa2mkXkWBGZJSIPZry+Q21eRF4Qke+JyD+BVmDfHvI/S0SWiEiTiKwTkf/u7j00xc2CuukL3wCOAQ7DqyUfBXwzY3k1MBQYjRd4Z4vIQd1tTERuFJFmoBYoBx72F00C3tKOfV+85aenlr+ZsezNjGVpqroiI32gqp4qIuXAM35ew4FPAb8RkUP89VqAzwIDgY8BV4rIef6yEzO2VaGqr3a3b51cjPfrohKo6yH/3wFfVNVKYDLwfJZ5mCJjQd30hYuAm1V1k6rWAf+LF7AyfcuvXb8I/A24oPNGUlT1h3iB7kPAA0CDv6giYzqlwV+3q+UNQEV37eqdnA2sUtV7VDWhqv8BHgem+2V6QVUXqaqrqm8BvwdOymK7O3Ovqi5W1QRw5s7yB+LAISJSpar1qvrGHuZtCpQFddMXRgGrM+ZX+2kp9Z2aVDov34F6/gO04Z0kAJqBqk6rVgFN3SyvApo71ey7sw9wtIhsSw14J6tqABE5WkTmikidiDQAV+D9+tgTa7PNH/gEcBawWkReFJFj9zBvU6AsqJu+sB4vKKWM89NSBvnNG90t35kgsJ8/vRiY0qnmPYXtFzsX4zX/pBxK9hdC1wIvqurAjKFCVa/0lz8MPAmMVdUBwB147fkAXZ00WoCyjPnqLtbJfN1O81fV11R1Gl7TzJ+AOVnulykyFtRNX/g98E0RGSYiQ4Fv492hkul/RSQsIifgNXX8ofNGRMQRkS+KyCD/jpCjgKuA5/xVXgCSwLX+xdmr/fRU+/L9wPUiMlpERgE3APdmuQ9/BQ4UkYtFJOQPR4rIwf7ySmCrqkb9cn0647V1eBd0981IWwicKCLjRGQA8D+7m7//vl0kIgNUNQ40+vmZfsiCuukLtwAL8C5aLgLe8NNSPgDq8WrnDwFXqOqybrZ1PvAuXpPKg8Cv/AFVbce7ZfGzwDbg88B5fjrAncBf/DK8jdd2f2c2O6CqTcAZeBco1/tl/hFQ4q/yJeBmEWnCO2nNyXhtK/A94J9+08kxqvoM8Kj/nryOF7T3JP+LgVUi0ojX9JOT/wWYwiP2kAyTTyJyMvCgqo7Jd1mMKQZWUzfGmCJiQd0YY4qINb8YY0wRsZq6McYUkbz1Gjd06FAdP358vrI3xpiC9Prrr29W1WHdLc9bUB8/fjwLFizIV/bGGFOQRGT1zpZb84sxxhQRC+rGGFNELKgbY0wRscdrGWMAiMfj1NbWEo1G810UA0QiEcaMGUMoFNql11lQN8YAUFtbS2VlJePHjye7LuZNb1FVtmzZQm1tLRMmTNil11rzizEGgGg0ypAhQyyg7wVEhCFDhuzWryYL6saYNAvoe4/dPRYFF9RX1K/gl2/8km3RbfkuijHG7HUKLqivaVzDbxf9lo2tG/NdFGOM2esUXFCvDHvPEG5sb8xzSYwxhSqRSOS7CL2m4IJ6Vdh7brAFdWOK03nnnccRRxzBpEmTmD17NgB///vf+dCHPsShhx7KaaedBkBzczMzZ86kpqaGKVOm8PjjjwNQUVGR3tZjjz3GJZdcAsAll1zCFVdcwdFHH83XvvY1/v3vf3Psscdy+OGHc9xxx7F8+XIAkskk//3f/83kyZOZMmUKv/rVr3j++ec577zz0tt95plnOP/88/vi7dhlBXdLY6qm3tTe1MOaxpjd9b9/WcyS9bmtOB0yqorvnDOpx/XuvvtuBg8eTFtbG0ceeSTTpk3jsssuY968eUyYMIGtW7cC8N3vfpcBAwawaNEiAOrr63vcdm1tLa+88gqBQIDGxkZeeuklgsEgzz77LDfddBOPP/44s2fPZtWqVSxcuJBgMMjWrVsZNGgQX/rSl6irq2PYsGHcc889fP7zn9+zN6SXWFA3xuxVfvnLX/LEE08AsHbtWmbPns2JJ56Yvl978ODBADz77LM88sgj6dcNGjSox21Pnz6dQCAAQENDA5/73Od45513EBHi8Xh6u1dccQXBYLBDfhdffDEPPvggM2fO5NVXX+X+++/P0R7nVkEGdUGs+cWYXpRNjbo3vPDCCzz77LO8+uqrlJWVcfLJJ3PYYYexbFl3zyHfUeatgJ3v8y4vL09Pf+tb3+KUU07hiSeeYNWqVZx88sk73e7MmTM555xziEQiTJ8+PR309zYF16buiENFqMJq6sYUoYaGBgYNGkRZWRnLli1j/vz5RKNR5s2bx/vvvw+Qbn45/fTTue2229KvTTW/jBgxgqVLl+K6brrG311eo0ePBuDee+9Np59++unceeed6YupqfxGjRrFqFGjuOWWW5g5c2budjrHCi6og1dbt6BuTPE588wzSSQSHHzwwdx4440cc8wxDBs2jNmzZ/Pxj3+cQw89lBkzZgDwzW9+k/r6eiZPnsyhhx7K3LlzAfjhD3/I2WefzXHHHcfIkSO7zetrX/sa//M//8Phhx/e4W6YSy+9lHHjxjFlyhQOPfRQHn744fSyiy66iLFjx3LwwQf30juw5/L2jNKpU6fq7j4kY/pfplNdVs2vTvtVjktlTP+1dOnSvTpY7Q2uvvpqDj/8cL7whS/0SX5dHRMReV1Vp3b3mr2zUagHleFKa1M3xvSpI444gvLycn7yk5/kuyg7VZBBvSpcxZqmNfkuhjGmH3n99dfzXYSsFGybemPMaurGGNNZj0FdRO4WkU0i8nYP6x0pIgkR+WTuitc1u1BqjDFdy6amfi9w5s5WEJEA8CPgHzkoU4+qwlW0JlqJu/G+yM4YYwpGj0FdVecBW3tY7RrgcWBTLgrVk9S/Spvbm/siO2OMKRh73KYuIqOB84Hbs1j3chFZICIL6urqdjvPVKde1gRjjDEd5eJC6c+Br6uq29OKqjpbVaeq6tRhw4btdobWU6MxJrM3RrNdLm5pnAo84ve3MBQ4S0QSqvqnHGy7S9anujFmb5FIJPaqfmD2uCSqmn7UtYjcC/y1NwM6WE+NxvS6/3cjfLAot9usroGP/rDbxTfeeCNjx47lqquuAmDWrFkEg0Hmzp1LfX098XicW265hWnTpvWYVXNzM9OmTevydffffz8//vGPERGmTJnCAw88wMaNG7niiit47733ALj99tsZNWoUZ599Nm+/7d349+Mf/5jm5mZmzZqV7mjs5Zdf5sILL+TAAw/klltuob29nSFDhvDQQw8xYsQImpubueaaa1iwYAEiwne+8x0aGhp46623+PnPfw7Ab3/7W5YsWcLPfvazPXp7U3oM6iLye+BkYKiI1ALfAUIAqnpHTkqxi6z5xZjiM2PGDL7yla+kg/qcOXN4+umnufbaa6mqqmLz5s0cc8wxnHvuuT0+lDkSifDEE0/s8LolS5Zwyy238MorrzB06NB0Z13XXnstJ510Ek888QTJZJLm5uYe+2dvb28n1dVJfX098+fPR0S46667uPXWW/nJT37SZZ/voVCI733ve/zf//0foVCIe+65hzvvvHNP3760HoO6ql6Y7cZU9ZI9Kk2WrKZuTC/bSY26txx++OFs2rSJ9evXU1dXx6BBg6iurua6665j3rx5OI7DunXr2LhxI9XV1Tvdlqpy00037fC6559/nunTpzN06FBge1/pzz//fLp/9EAgwIABA3oM6qmOxcB7+MaMGTPYsGED7e3t6b7fu+vz/dRTT+Wvf/0rBx98MPF4nJqaml18t7q39zQE7YLSYClBCVpQN6bITJ8+nccee4wPPviAGTNm8NBDD1FXV8frr79OKBRi/PjxO/SR3pXdfV2mYDCI626//2NnfbNfc801XH/99Zx77rm88MILzJo1a6fbvvTSS/n+97/PxIkTc96Nb0F2EyAiVJVUWVcBxhSZGTNm8Mgjj/DYY48xffp0GhoaGD58OKFQiLlz57J69eqsttPd60499VT+8Ic/sGXLFmB7X+mnnXYat9/u3ZWdTCZpaGhgxIgRbNq0iS1bthCLxfjrX/+60/xSfbPfd9996fTu+nw/+uijWbt2LQ8//DAXXph1Y0hWCjKog3UVYEwxmjRpEk1NTYwePZqRI0dy0UUXsWDBAmpqarj//vuZOHFiVtvp7nWTJk3iG9/4BieddBKHHnoo119/PQC/+MUvmDt3LjU1NRxxxBEsWbKEUCjEt7/9bY466ihOP/30neY9a9Yspk+fzhFHHJFu2oHu+3wHuOCCCzj++OOzegzfrijI/tQBPv23T1MVruKO0/NyrdaYomP9qfets88+m+uuu47TTjut23V2pz91q6kbY0wf2rZtGwceeCClpaU7Dei7qyAvlIIX1Nc3r893MYwxebRo0SIuvvjiDmklJSX861//ylOJejZw4EBWrFjRa9sv2KBeFa6y+9SN6edqampYuHBhvouxVyn45pd8XRMwxpi9UUEH9bgbJ5aM5bsoxhiz1yjYoG5dBRhjzI4KPqjbHTDGFA/rTnfPFWxQt/5fjDFmRwUb1K35xZjipap89atfZfLkydTU1PDoo48CsGHDBk488UQOO+wwJk+ezEsvvUQymeSSSy5Jr5urLmwLVcHe0mgPyjCm9/zo3z9i2dZlOd3mxMET+fpRX89q3T/+8Y8sXLiQN998k82bN3PkkUdy4okn8vDDD/Nf//VffOMb3yCZTNLa2srChQtZt25dut/zbdu25bTchaZga+rpoG6dehlTdFIPnwgEAowYMYKTTjqJ1157jSOPPJJ77rmHWbNmsWjRIiorK9l333157733uOaaa/j73/9OVVVVvoufVwVbU7cLpcb0nmxr1H3txBNPZN68efztb3/jkksu4frrr+ezn/0sb775Jk8//TR33HEHc+bM4e677853UfOmYGvqoUCI0mCpBXVjitAJJ5zAo48+SjKZpK6ujnnz5nHUUUexevVqRowYwWWXXcall17KG2+8webNm3Fdl0984hPccsstvPHGG/kufl5l8zi7u4GzgU2qOrmL5RcBXwcEaAKuVNU3c13QrlSGK61N3ZgidP755/Pqq69y6KGHIiLceuutVFdXc99996UfA1dRUcH999/PunXrmDlzZvqBFj/4wQ/yXPr86rHrXRE5EWgG7u8mqB8HLFXVehH5KDBLVY/uKeM97XoX4Pw/n8/4qvH87JT+fbXbmFywrnf3PrvT9W42zyidJyLjd7L8lYzZ+cCYHkuaI9b9rjHGdJTrNvUvAP+vu4UicrmILBCRBXV1dXucmfXUaIwxHeUsqIvIKXhBvdvL5qo6W1WnqurUYcOG7XGe1qZujDEd5eSWRhGZAtwFfFRVt+Rim9mw5hdjjOloj2vqIjIO+CNwsar23uM8ulAVrqKpvQlX3b7M1hhj9lrZ3NL4e+BkYKiI1ALfAUIAqnoH8G1gCPAbEQFI7OzKbC5VhitRlJZ4S/ofpsYY059lc/fLhT0svxS4NGcl2gWZnXpZUDfGmAL+RylYVwHG9Gc763t91apVTJ68w99q+oWCDurWp7oxxnRUsB16gfXUaExv+eD73ye2NLdd75YcPJHqm27qdvmNN97I2LFjueqqqwCYNWsWwWCQuXPnUl9fTzwe55ZbbmHatGm7lG80GuXKK69kwYIFBINBfvrTn3LKKaewePFiZs6cSXt7O67r8vjjjzNq1CguuOACamtrSSaTfOtb32LGjBl7tN99raCDelWJPSjDmGIxY8YMvvKVr6SD+pw5c3j66ae59tprqaqqYvPmzRxzzDGce+65+DdlZOW2225DRFi0aBHLli3jjDPOYMWKFdxxxx18+ctf5qKLLqK9vZ1kMslTTz3FqFGj+Nvf/gZAQ0NDr+xrbyrooG7NL8b0jp3VqHvL4YcfzqZNm1i/fj11dXUMGjSI6upqrrvuOubNm4fjOKxbt46NGzdSXV2d9XZffvllrrnmGgAmTpzIPvvsw4oVKzj22GP53ve+R21tLR//+Mc54IADqKmp4YYbbuDrX/86Z599NieccEJv7W6vKeg29YpQBYJYTd2YIjF9+nQee+wxHn30UWbMmMFDDz1EXV0dr7/+OgsXLmTEiBFEo9Gc5PXpT3+aJ598ktLSUs466yyef/55DjzwQN544w1qamr45je/yc0335yTvPpSQdfUHXGoCFdYTd2YIjFjxgwuu+wyNm/ezIsvvsicOXMYPnw4oVCIuXPnsnr16l3e5gknnMBDDz3EqaeeyooVK1izZg0HHXQQ7733Hvvuuy/XXnsta9as4a233mLixIkMHjyYz3zmMwwcOJC77rqrF/aydxV0UIft/yo1xhS+SZMm0dTUxOjRoxk5ciQXXXQR55xzDjU1NUydOpWJEyfu8ja/9KUvceWVV1JTU0MwGOTee++lpKSEOXPm8MADDxAKhaiuruamm27itdde46tf/SqO4xAKhbj99tt7YS97V4/9qfeWXPSnDnDBXy5geNlwfn3ar3NQKmP6L+tPfe+zO/2pF3SbOlinXsYYk6ngm18qw5Wsbtz1djZjTOFbtGgRF198cYe0kpIS/vWvf+WpRPlX8EHdHpRhTO6o6i7dA55vNTU1LFy4MN/F6BW72zRuzS/GGAAikQhbtmzZ7WBickdV2bJlC5FIZJdfW/A19cpwJW2JNuJunJATyndxjClYY8aMoba2llw8atLsuUgkwpgxu/7I54IP6pk9NQ6ODM5zaYwpXKFQiAkTJuS7GGYPFUXzC1hXAcYYA0UQ1NMPyrCeGo0xpuegLiJ3i8gmEXm7m+UiIr8UkZUi8paIfCj3xexeqqdGq6kbY0x2NfV7gTN3svyjwAH+cDnQp/+rrQz5farHraZujDHZPKN0noiM38kq04D71bsPar6IDBSRkaq6IUdl3Kl0n+rW/JKmqrQnXVRBBAIiOCKIkJN7kF1XiSaSROMubfEk0XiStvYksUSStnaXaDxJe9IlFHAIBx3CAYeSkD8O+ml+ejjo4IiQVEVdcFVJquKq4vrzqemkKknXJZ5UEkkl7rokXSWedEkklYSbGisCBAMOwYAQdISg4xAKiJfmiJ/uTafzUEi63rRmTLvql8vdcUj46yRcxc2YLySOCAL+5wME77OSXuanZctbH38bguN/7lJpjr+C66p3LNPHUUkkXeKuN06luar+Mdt+7EKOd2wDjhDy00MBB8X7bKSOyQ7HzD+Orqs4jiAi/vfDK5fjbJ8WgYAjqIKy/b5xb977TKbSM494d+9n5nuw37AKDh5ZtecHrwu5uPtlNLA2Y77WT9shqIvI5Xi1ecaNG5eDrPfOC6XReJK6phibm2Ndf7C6CAbxpBesvLFLe9Ilnug4n0gq7QmX1niStvYEbfEkre1eQO08nXS7DizpD68IjrN9OpuvrALtSZf2hJvT98uY/uaKk/bbq4N61lR1NjAbvA69crHNSCBC0An2SVBXVeqaY9TWt7GpMcrGxhgb/fGmpiibGmNsbIqyrTWeszy9mohXCwkHHEIBh7JwgEgoQFk4QEVJkGEVJZSFA5SGA5SGgpSGHUpDAQKO49dy/VqoKurXSpOutz9Jf1m2QkGhNOTl740dIh3mvXEoKMQTSnsySSzhnQhS4/aEmz45tCdcFN1+ohH82lJX817tO5Sqtfk1ttR7lFmTU2V77b2b2nw86eKq+rWyjBqb03XeAcdbJxjw0oKOg+NA0HEIOBBwHALpX0Q5+wj0qtSPitSvk8yap7ds1z4fqW1u354/zpz280u9l6madtCvfWfWxIOOgwjpilAiuf14JjNq+gm/QuSIV3vvMGSkBR1JH1P1fxVqxi+x1HTmr7bMXx2pXyGZv2BSx1qk5/czNT2oLLxnB24nchHU1wFjM+bH+Gl9QkR6pauAlliC5RubWP6BNyz7oJHlHzRR3ylgBxxheGUJw6si7DOkjOP2KeeAUB3jZCNDqUdCZbgllRCuhJJKNFyJlFShkUoCoVICfoBINVWEAk46iIcCXsDKmpuEre/Bxrdh4xKItUK4HErKIFQG4TIIlUKo3J9ODRHItq6u6uXjxsBNgCb9+eT2+VgC2tyM5Ynt65AEJ+GNJQFBf73UOskEJNyM12Tkob3xC0G89yTz/QiX++9T5vtW5u17MgaJdm8ci0GyHRKZ45hX1kAIAiUQDPvjEgiEM8YRb1qyvAHNCUBkIJRU7v4ZQxXaW6B1M7RshlgjOCG/LOFuyhvx9iW97xn7mtrfzDQ34e2TE/TKnB4HOqaJ0/W+u/6QDWHHCCZORl7BjLIE8X6apvLupbOuatef3dR8Ki1QBZT0ShFyEdSfBK4WkUeAo4GGvmpPT9nTPtWj8STPLd3E0g2NLPugieUbG1m7tS29vCwc4IARlZxxSDUHVVeyX2WC0foBwxMbqGhZg7Ptfdj6PtS9D++tzz5jJ+R9SUsqoXwYVI2CAWO8cdVofxgFlSMh0OlQtW6FjYv94W1v2LQMEn65JeB9MeOtu/2+5J1kBAMJ+F/GHOfhut57pMkcb7iXSABKB0LpoO1DJHN+ICSiXtBu2bw9gKemE7l5alDBE4ecf5jUBbL8WfPh6+Ajs3Kbv6/HoC4ivwdOBoaKSC3wHSAEoKp3AE8BZwErgVZgZq+UdCcqw5W7XVOfu3wTs55czOotrQQcYcLQcqaMHsDnasqYUraF/QJ1DI7VIttWebXgd9+Htq0dN1IxAgbvC/ue7I0HT4BBE6BqJMTbINbUaWjsOI42QssmqFsGK5+DeEvH7Yvj5VE1GkoqoG4FNGWcPMqGQvVkOPILMGKSNww9yKuBq3pliLd6Q3urt/14W8b0LnzR0zWhzNpQoGNal/MZNbbMeem0rQ41uT5sw0i0d/G+tHk129T7Jk7XNdpgScc0J+jVXDNr9elxZg23PftfH24cog3QVg9t2/xxPTRvgs0rvOloxkOSg6VeRaF8iDcefog3XTbUTx8KJVXedhPtXrDfWXmdQKdfGiV+Lb5TmhPKqJ0mOk6n01K/4nrhgrK63eebmbfbCydxkey+D07QOx69JJu7Xy7sYbkCV+WsRLthd5pf1m1r47tPvsU7S9/kjAHr+czhzYxxNxDYthpWvQfvZARWcbwa9OB94ZBpXtAevK83DBrv/VzPFVXvy9m4DhrXe+OG1HStdwKYcOL24D1iMlQM7z4AinjNB+Gy3JWxGAXD3lA6KN8l2X1u0vvsBEty+5k0BaXw+n5Z9zrMvwMGjE43UVQmE6yLbiN9D19XEu1Qt5TEujdZ+sZLJNYt5KespqwkBlFgRdgL0IMmwPgPbw/cgybAwHHeF74viPg/rwd6QduYbDkBKLP+j/q7wgvqzXWwZr7X/OAmAKgcMojG8jK4ZYTX5FGVapce5TWVbHjTu3DoxgkC47WUD0r3x534WRh/BIycAkMP9C4IGWNMASu8oH7Qmd7gutBSB421VC2+h8YNL6FHXY40bfCaLNbOh8YNUFJJbHgN8wZ+kj9/MJStAw7msmmnccrE6nzviTHG5FzhBfUUx4HKEVA5gsqtC0lseJHoad+gNFiaXiWeSHDfK6v52bPvEHeVL526H1ectB+RUCCPBTfGmN5TuEE9Q+pfpY2xxg5B/erfL+TpxRs55aBhzDp3EvsMsYtHxpjiVvBd70LXPTXGky5zl9Vx0dHjuPuSIy2gG2P6heII6iE/qMe3B/WVm5ppT7ocNWFwQT1I1xhj9kRxBPUuempcvN6bnjSqdzrNMcaYvVFRBPV0m3p7ZlBvoDQUYMLQinwVyxhj+lwRB/VGJo6s3LUOsYwxpsAVVVBPXShVVZaub7SmF2NMv1MUQT3khCgNlqaD+tqtbTTFEkwaNSDPJTPGmL5VFEEdOvbUuHi911vdIb30ZBFjjNlbFU1Qz+xTffH6RgKOcFB1ZZ5LZYwxfatIg3oD+w+rsO4AjDH9TtEE9Y7NL3aR1BjTPxVNUE/V1OuaYmxqinGIBXVjTD+UVVAXkTNFZLmIrBSRG7tYPk5E5orIf0TkLRE5K/dF3blUTX3JhtQ/Se3OF2NM/9NjUBeRAHAb8FHgEOBCEen8gL1vAnNU9XDgU8Bvcl3QnlSGK2lub+btdfWA3flijOmfsqmpHwWsVNX3VLUdeASY1mkdBVJRdACwnj5WFa5CUd5av5Exg0oZUGZPMTLG9D/ZBPXRwNqM+Vo/LdMs4DMiUgs8BVzT1YZE5HIRWSAiC+rq6najuN1L/at06caNdpHUGNNv5epC6YXAvao6BjgLeEBEdti2qs5W1amqOnXYsGE5ytqT6qmxtmGrtacbY/qtbIL6OmBsxvwYPy3TF4A5AKr6KhABhuaigNmqCntBXQJRq6kbY/qtbIL6a8ABIjJBRMJ4F0Kf7LTOGuA0ABE5GC+o57Z9pQep5hcJtNntjMaYfqvHoK6qCeBq4GlgKd5dLotF5GYROTvZcR0AAB3aSURBVNdf7QbgMhF5E/g9cImqam8VuiupmnpFaZzqqkhfZm2MMXuNrB48rapP4V0AzUz7dsb0EuD43BZt16Rq6iMGqj2+zhjTbxXNP0pDUoqqMKgyke+iGGNM3hRNUH+3rgXcCJVlFtSNMf1X0QT1xesb0WQpJeH2fBfFGGPypmiC+pL1jYhbiiut+S6KMcbkTVEF9bJQBc3xpnwXxRhj8qYogrrrKks2NDKwZED6QRnGGNMfFUVQX7O1leZYguHlA2iMNea7OMYYkzdFEdQXr/cC+ZgBQ2iy5hdjTD9WJEG9gYAjjB04hLZEG/FkPN9FMsaYvCiKoL5kQyMHDK9gcKnXO2PqWaXGGNPfFEVQX7y+kUNGVaW7CrCLpcaY/qrgg/qmpih1TTEmjRqQ7tTLaurGmP4qqw699mapi6STRlUR8YO61dSNMf1VwdfUl/hB3ZpfjDGmKGrqDYwdXEpVJETU9YK6Nb8YY/qroqipTxrp3fViberGmP6uoIN6UzTOqi2t6WeSlgRKCDkha34xxvRbWQV1ETlTRJaLyEoRubGbdS4QkSUislhEHs5tMbu2dIMXvCeNrkqVgcpwpdXUjTH9Vo9t6iISAG4DTgdqgddE5En/EXapdQ4A/gc4XlXrRWR4bxU40+L1DQBMGjUgnVYVrrKaujGm38qmpn4UsFJV31PVduARYFqndS4DblPVegBV3ZTbYnZt8fpGhpSHGV5Zkk6rCldZp17GmH4rm6A+GlibMV/rp2U6EDhQRP4pIvNF5MxcFXBnUv8kzXzQdGW40mrqxph+K1cXSoPAAcDJwIXAb0VkYOeVRORyEVkgIgvq6ur2KMP2hMvKTU0dml7Ab36xnhqNMf1UNkF9HTA2Y36Mn5apFnhSVeOq+j6wAi/Id6Cqs1V1qqpOHTZs2O6WGYAVG5uIJzV950tKZbjSml+MMf1WNkH9NeAAEZkgImHgU8CTndb5E14tHREZitcc814Oy7mDJRndA2SqKvEulKpqb2ZvjDF7pR6DuqomgKuBp4GlwBxVXSwiN4vIuf5qTwNbRGQJMBf4qqpu6a1Cg3fnS1k4wPgh5R3SK8OVJDRBW6KtN7M3xpi9UlbdBKjqU8BTndK+nTGtwPX+0CcWr2/k4JFVOI50SE/1/9LY3khZqKyvimOMMXuFgvxHqesqSzc07tD0Atu7CrA7YIwx/VFBBvXVW1tpaU92GdStp0ZjTH9WkEG9q3+SplinXsaY/qxAg3ojQUc4YETFDsus+cUY058VbFDff3gFJcHADssyL5QaY0x/U3BBXVVZsr6hy6YXgIqwV3u3oG6M6Y8KLqhvaoqxubm9y4ukACEnRFmwzJpfjDH9UsEF9e7+SZrJugowxvRXBRfUh1WW8Omjx3FwD0HdaurGmP6o4B48PXn0AL5/fs1O17GeGo0x/VXB1dSzYQ/KMMb0V8UZ1EvskXbGmP6pKIO6takbY/qr4g3q8SaSbjLfRTHGmD5VlEE91VVAc7w5zyUxxpi+VZRB3boKMMb0V0Ud1K1d3RjT3xRlULeeGo0x/VVWQV1EzhSR5SKyUkRu3Ml6nxARFZGpuSvirrM+1Y0x/VWPQV1EAsBtwEeBQ4ALReSQLtarBL4M/CvXhdxV1vxijOmvsqmpHwWsVNX3VLUdeASY1sV63wV+BERzWL7dYs0vxpj+KpugPhpYmzFf66eliciHgLGq+redbUhELheRBSKyoK6ubpcLm62yUBmOODTEGnotD2OM2Rvt8YVSEXGAnwI39LSuqs5W1amqOnXYsGF7mnW3HHGoCFVYTd0Y0+9kE9TXAWMz5sf4aSmVwGTgBRFZBRwDPLk3XCy1nhqNMf1NNkH9NeAAEZkgImHgU8CTqYWq2qCqQ1V1vKqOB+YD56rqgl4pcZbsQRnGmP6ox6CuqgngauBpYCkwR1UXi8jNInJubxdwd1lPjcaY/iirh2So6lPAU53Svt3NuifvebH2XFW4ivda38t3MYwxpk8V5T9KwW9+sT8fGWP6maIN6lVha34xxvQ/RRvUK8OVRJNR2pPt+S6KMcb0maIO6mD9vxhj+peiDerWVYAxpj8q2qBuNXVjTH9UtEHdaurGmP7IgroxxhSRog3q6eYX6yrAGNOPFH1Qt069jDH9SdEG9UgwQtgJ24VSY0y/UrRBHaynRmNM/1PUQX1I6RCWb12Oqua7KMYY0yeKOqh/euKneXvL2zy75tl8F8UYY/pEUQf18/Y/j/0H7s/PXv8Z8WQ838UxxpheV9RBPeAEuGHqDaxtWsujyx/Nd3GMMabXFXVQBzh+1PEcO/JY7njrDhpiDfkujjHG9KqsnnwkImcCvwACwF2q+sNOy68HLgUSQB3weVVdneOyAtD80kts/P4PwHVRFFwF1W7nKz58Atdf9SUueO6z3LXoLm6YekNvFMsYY/YKPQZ1EQkAtwGnA7XAayLypKouyVjtP8BUVW0VkSuBW4EZvVHgQGUlkYMnAgKOAyKIIx3mcQQRwW1to+HPf6bk7UV85pJTeWjpQ8w4aAZjKsf0RtGMMSbvsqmpHwWsVNX3AETkEWAakA7qqjo3Y/35wGdyWchMpYcdxujDDst6/YGf+Djrbvhvzvn+et7/qPLLN37JrSfd2lvFM2av5La2El22jOjbb9P29ttE316MG21j1Pd/QPkxR+e7eCaHsgnqo4G1GfO1wM4+BV8A/l9XC0TkcuBygHHjxmVZxD1TftxxTHj8MWq//BWufWwRT679K28deCFTRh7eJ/kb09fcWIzYsmXp4B19+21i774LrgtAcPhwIpMn075qFWsuvZSRs77DwE9+Ms+lNrmSVZt6tkTkM8BU4KSulqvqbGA2wNSpU/vsH0GhUaPY56EHWfe973Luo4+x+rIvcvA9fyM0bFhfFcGYXqXJJE3PPMvWBx6g7c03IZEAIDB4MJGayVSefjqRyZOJTJpEaMRwAJJNTaz7ynVs+Oa3iL3/PsOvvx4JBPK5GyYHsgnq64CxGfNj/LQOROQjwDeAk1Q1lpvi5Y4TDjP2f7/LP0a6VP/6jyw/7xz2/dXtlH3IauymcLltbWx74gm23nsf8TVrCI0bx5CZM4nUTKa0poZgdTUi0uVrA5WVjL3zDjZ+//ts/d3dtK9azehbf4RTXt7He2FySXr6C72IBIEVwGl4wfw14NOqujhjncOBx4AzVfWdbDKeOnWqLliwYHfLvdsSboKr7zibix5cx9BGGPG1rzHo4s90+8E3Zm+U2LqV+ocepv7hh0nW1xM5dApDPv8FKj9y2m7Vtrc+8CAbf/ADSg46iLG3/4ZQdXUvlNrkgoi8rqpTu12eTb8oInIW8HO8WxrvVtXvicjNwAJVfVJEngVqgA3+S9ao6rk722a+gjrAvNp5fPVvX+LnL+/LwNfeoeqssxj53ZuthmL2eu2rV7Pl3ntp+OMTaCxGxSmnMOQLn6f0iCP2uGLS/OKLrLv+Bpzycsb85jeUTp6Uo1KbXMpJUO8N+Qzqqspl/7iMFVuW8fv6C2i87U7CEyZQ/Z1vU37UUXkpkzE70/bmm2z53d00PfMMEgxSNe1chsycScl+++U0n+jyFdReeSWJrVsZdeuPqDrjjJxu3+y5noJ60f+jtCsiwg1Tb2BbvJE5xyQZd9dvcVtaWPPZz7H2S1cRe+/9fBfR9HPqurS+8R82/eQnvHvWx1g141O0zJ/PkMsuY7/nnmXULbfkPKADRA46kPFzHiVy0EGsu/bLbJ79W+vltMD0y5p6yjde/gZ/f//v/OX8v1AdHMzW++5ny+zZuNEog2bMYOjVVxEcPDivZTT5pa5L28I3aZ47FwkFiUyaRGTSJIIjRuT8OowbjdLyyqs0Pf8czXNfILllCwSDlB91JJWnn07VOecSqOibJkI3GmXDTd+g8amnGHD++Qz/2lcJVFXtVnu9quI2NZHYtIn4xo0kNm4isWkToEgkglNahlMa8adLcSIRJFKKU+ZPp9MiiLP79VBVRWMx3LY2tD2OUxJGSkq8YQ+229es+WUnPmj5gLOfOJuP7PMRfniC1/NBYssW6n79a7bN+QNOaSlDvng5gz/7WZySkryW1fQdTSRoXbCApn88Q9Ozz3oBKBj07vP27/UODB7sB/hDiEyaROmkSQRHjtzlQJ+or6d57gs0Pf8cLf98BW1rw6mooOLEE6g49TQqTjyBQFVVb+xmj1SVzbf9hs2//nU6zamoIDBgAM6AKgJVAwhUVREYMIDAgCqcqgFIOESiri4duBMbNxLftAlta8tJmVIB3ikt9aZTAb+sFCdSiiYSuG2taGsbbtv2QVtbcaPR9PHbYbuhkHfSKCnBSQX6SAlOScQbR0rTY+8EVIoTKfHHEaQ0goRCkHRBXTTpgpvsdlx62GGUH3PM7r0HFtR37pdv/JLfLvotj3zsESYN3X5hKPbuu2z6vx/T/MILBEeNZPh111P1sbPyekZXVdyGhu0fQLunOGfc9nZaX32Vxmeeofm550nW1yORCBUnfJjKM86g4uSTkUCA6PLlRBcvIbp4MdHFi70/9SSTAAQGDSJyyCGE99sXki7a3u4N8Xbc1HR7fHt6LErs3ffAdQlWV1N56ilUnHoa5UcdiYTDeX5Htmt97TWiy5aTbGgg2diA29BAsqGRZGPj9rRtDWjc695aQiGCw4cTHDGC4IjhhIaPSM+HRgz3pocPRwIB3GjUC7ptbduno1HctqgXnKNR3NY23Ggb2hb112n1ptv89Na2dLoEQ16gLy1NB3qn1Kv1eyeBMm9ZOIS2t+PGYmg0hrbHcKMxNBZDY1HcWLuXdyyKRmPe2M9f29q81+3BiWrIZZcy/Ibd64fKgnoPmtub+dgTH2PCgAn87ozfEXA6BsqW+fPZeOutxJYsJVJTw4ivf42yqd2+nzmXbGyk5dX5tLz8Mi3//Cfx9evTy6SkpGONpbQUKY2kP7hOeTmBqkqcyipvXFG5fb6yAqeqikBlJU5FRcGfIFSV2LJlNP7jHzQ/9zxuS4tXm6ysIlBVhVNV6dcsK7399ge3rY2m556nee5c3OZmnPJyKk45hcrTT6fihA/jlJXtNF83GiW2fDltfpCPLl5C+5o1SDCIhMNIOIQTCvvTOw6Rgw6k4tTTiEw6pKBvq1VVNBpFYzGcAQMKel+ylWrO0agf7NvbwQkgAQccx6sABgJdj4PB3a4gWlDPwpzlc/ju/O9ywKADuP6I6zl+1PEdPpTqujQ8+SR1P/s5iY0bKTnwQEoOOMAf9qdk//0JjRmTk8CoiQRtixbR8s9XaHn5ZdreegtcF6e8nLJjj6Hs8A8Bur0mk6qxpGo76aEVt6UVt7ERt6Wlx3yltBSnrAynvNwbyspwystwyso7jAOVlTiVlemgmD5h+CcICXb9fzZNJnHbomhb6/Yytno1scCgQYQnTNjlJi51XdrefJOmZ56l6ZlniK9dC45D2dSphEZWe7XJpibcxgaSjU0kGxu7rF0FBg6k4rRTqTz9dMqPOw5nL6olG9OZBfUsqCpPr36aX7z+C2qbazl65NHccMQNHDzk4A7ruW1t1D/8e1r+/S/a31nZsdYciVCy776UHLA/4f33p+SAAwjvs48X6F0XdRXwuwR2XVBAvTZaTbpEly6h5eV/0jJ/Pm5jI4gQqamh4sPHU3788ZROmeK12e3O/iWTuM3NfoBrJNnUjNvUSLKxCbe5yRu3tuK2tHhDarrzuKWl2zbJFKesDKeqCqe01PvJ6rdtaqyHPxk7DuFx4wjvvx8l++9Pyf7eCTM8fnyHYO+1d79O0z/+sb29OxSi/NhjqDrjDCpOPXWnF7e1vZ1kUxPJhkbcpkZQJTJ5crcnI2P2NhbUd0E8GefR5Y9yx1t30Bhr5Ox9z+aaw69hZMXILtdPNrfQ/u5KYitXEntnJbF33iG2ciWJjRt3K//giBGUf/h4Kj78YcqOOYbgoEF7sjs5p6poW5vXltrYiNvUtH3c0EiyqRG3sckbt7bilER2aMvsMO/f3ZCoq9v+Hr77Lu2rV6fbqVPBvuSA/XHKymie99KO7d0nnZS3i4nG9DUL6ruhsb2R3y36HQ8ueRCAiw65iEtrLqUqnF3gSDY2Elv5LvG1a7wEx8Hr7128djQREAeE9Hx4n30I77dfv2iL7Inb3k77+6uIrfROku0r3yW2ciXJ+nrKjz/eC+RZtHcbU4wsqO+BDc0b+PXCX/OXd/9CVUkVX5zyRWYcNINwwNpcjTH5YUE9B5ZtXcZPF/yUVze8yuiK0Xxxyhc5c8KZlAZL8100Y0w/Y0E9h15Z9wo/e+NnLNu6jMpQJefufy7TD5zOfgNz/3dtY4zpigX1HFNV3tj0BnOWz+GZ1c8Qd+McMeIILjjwAj6yz0esacYY06ssqPeirdGt/Gnln/jD8j9Q21zL4Mhgztv/PD554CcZWzm25w0YY8wusqDeB1x1mb9+PnNWzOGFtS+Q1CTHjzqeaftPY0zFGAZGBjKoZBDloXK7u8UYs0csqPexjS0b+ePKP/LYisfY1Lqpw7KgE2RQyaB0kB9YMtAb/PlBkUHbx/5QErCOxIwx21lQz5OEm2DplqVsjW6lPlZPQ6yB+mg922Lbto9j9WyLbmNbbBtK18ehNFjK4MhgBpYMZFBkEIMjgxlRNoLq8mpGlo+kurya6vJqKsOVfbyHxph86CmoZ/XfaBE5E/gF3uPs7lLVH3ZaXgLcDxwBbAFmqOqq3S10MQg6QWqG1WS1btJN0tTexNbYVrZFvaBfH/MC/9aol7Y1tpX6aD0rt62krrWOpCY7bKMiVJEO8NXl1VSXVVMRriAgAQJOgIAEcMTx5rtI69wsJHjzqfTUfEW4gmGlwxhaOrTXLwqrKglN0J5sJ5aM4apLRaiCSDDSq/kaU8h6DOoiEgBuA04HaoHXRORJVV2SsdoXgHpV3V9EPgX8CJjRGwUuRgEnwMCI1wzDgJ7XT7pJ6trq+KDlg/SwoWWDN936AUu2LGFrdGuvl3tAyYB0gB9WOoyhZd54WOkwqkqqiCaitMRbaI230pJo2T4d96ZbEi20xdtoS7SlA3d7sp2YG+sQyDsLO2GqSqqoCvuDPz2gZEA6zVWX1kRrOr/WRGs6/9R0S7yFuBsnEohQFiqjLFhGabCU0lAppcFSyoJllIXK0tOlQS89EowQCUSIBCNdzocDYYISxBEHR5yCuY6iqiTcBHE3TnuynXa3PT2tqh1+TaZ+4afS0uNd+OUfdIKUBEooCZQQDoSJBCOEnfBuvV+qSlKTCLJDT6u54qpL0k2S1CSuuiQ0gev6Y3Vx1U0f81SFKbPSlJnmSO914Z1NTf0oYKWqvgcgIo8A04DMoD4NmOVPPwb8WkRE7TlYvSLgBNI18u7EkjHa4m0kNeND6CY6fBgzl0F2X9TG9kbqWuuoa6tjc9tm6lq98YLGBWxu20zcjXdbJkEoC5VRHiz3xqFyykPlDCsblv5ilwRKCDv+F9yfTy1zcGiKN9EYa6Sx3R9iXnne3fYujbFGmuJNHfIsCZRQHiqnNFiazq8qXEV1eTVlwTJKAiVEk1Fa4620JdpoTbTS0NLQYb413tpt81g2Ul/moLM90GcG/dR740+k5zv/Skodq9SQ1GQ6mGWmp16bCiaZgSQgAQQvTZAOgXtnx64vpYN8wPsMhJwQSU2ScBMk3SQJTXjTndJSBCHoBL1BggScAEEnSEC8ccgJISIdgnTqPcwM2klNknS3B/Bc+vzkz3PdEdfldJsp2QT10cDajPla4Oju1lHVhIg0AEOAzZkricjlwOUA48aN280im2ykgmFfUlUaYg3UtdXREGugNFRKebA8HUwjwUiv1lDA+xXTHG9GRCgLlhF09rz3RVUlmowSS8SIJqO0JdqIJqIdpzvNp4OCHxg6B4rUsswTZuZJtPMJVdEdmss61wYzTxKpbaeDP0rS9cap4K8oISdEyAkRDoTTATTshAkFQh2WBcSv/WZUotNNdN001WXqnKZ4vwpiydiOQ6LjfNyNp4NyyAmlg3PACRCUYHo6IIH0dpNuMh344248fQJILUtqMt0MmW6W7KKZ0nG2n4Az10+nOdubMwXpcHLd2Yn3sOGH7enHslt92t+oqs4GZoN3obQv8za9T0S2NyPlScAJMKAkizasXSAi6aYXY/Z22VSb1gGZ/6QZ46d1uY6IBPFahrfkooDGGGOyl01Qfw04QEQmiEgY+BTwZKd1ngQ+509/Enje2tONMabv9dj84reRXw08jXdL492qulhEbgYWqOqTwO+AB0RkJbAVL/AbY4zpY1m1qavqU8BTndK+nTEdBabntmjGGGN2Ve/eimCMMaZPWVA3xpgiYkHdGGOKiAV1Y4wpInnrpVFE6oDVu/nyoXT6t2oRKLZ9Krb9geLbp2LbHyi+fepqf/ZR1WHdvSBvQX1PiMiCnXU9WYiKbZ+KbX+g+Pap2PYHim+fdmd/rPnFGGOKiAV1Y4wpIoUa1GfnuwC9oNj2qdj2B4pvn4ptf6D49mmX96cg29SNMcZ0rVBr6sYYY7pgQd0YY4pIwQV1ETlTRJaLyEoRuTHf5ckFEVklIotEZKGILMh3eXaViNwtIptE5O2MtMEi8oyIvOOPB+WzjLuqm32aJSLr/OO0UETOymcZd4WIjBWRuSKyREQWi8iX/fSCPE472Z9CPkYREfm3iLzp79P/+ukTRORffsx71O8CvfvtFFKbuv8Q7BVkPAQbuLDTQ7ALjoisAqaqakH+aUJETgSagftVdbKfdiuwVVV/6J98B6nq1/NZzl3RzT7NAppV9cf5LNvuEJGRwEhVfUNEKoHXgfOASyjA47ST/bmAwj1GApSrarOIhICXgS8D1wN/VNVHROQO4E1Vvb277RRaTT39EGxVbQdSD8E2eaSq8/D60c80DbjPn74P7wtXMLrZp4KlqhtU9Q1/uglYivds4YI8TjvZn4KlnmZ/NuQPCpwKPOan93iMCi2od/UQ7II+kD4F/iEir/sP5y4GI1R1gz/9ATAin4XJoatF5C2/eaYgmio6E5HxwOHAvyiC49Rpf6CAj5GIBERkIbAJeAZ4F9imqgl/lR5jXqEF9WL1YVX9EPBR4Cr/p3/R8B9tWDjtfN27HdgPOAzYAPwkv8XZdSJSATwOfEVVGzOXFeJx6mJ/CvoYqWpSVQ/Dexb0UcDEXd1GoQX1bB6CXXBUdZ0/3gQ8gXcwC91Gv90z1f65Kc/l2WOqutH/0rnAbymw4+S30z4OPKSqf/STC/Y4dbU/hX6MUlR1GzAXOBYYKCKpp9T1GPMKLahn8xDsgiIi5f6FHkSkHDgDeHvnryoImQ8j/xzw5zyWJSdSwc93PgV0nPyLcL8DlqrqTzMWFeRx6m5/CvwYDRORgf50Kd4NIUvxgvsn/dV6PEYFdfcLgH+L0s/Z/hDs7+W5SHtERPbFq52D98zYhwttn0Tk98DJeN2EbgS+A/wJmAOMw+ti+QJVLZgLj93s08l4P+sVWAV8MaM9eq8mIh8GXgIWAa6ffBNeO3TBHaed7M+FFO4xmoJ3ITSAV+Geo6o3+zHiEWAw8B/gM6oa63Y7hRbUjTHGdK/Qml+MMcbshAV1Y4wpIhbUjTGmiFhQN8aYImJB3RhjiogFdWN2g4icLCJ/zXc5jOnMgroxxhQRC+qmqInIZ/w+qheKyJ1+h0nNIvIzv8/q50RkmL/uYSIy3+8M6olUZ1Aisr+IPOv3c/2GiOznb75CRB4TkWUi8pD/L0dj8sqCuilaInIwMAM43u8kKQlcBJQDC1R1EvAi3r9FAe4Hvq6qU/D+qZhKfwi4TVUPBY7D6ygKvJ4BvwIcAuwLHN/rO2VMD4I9r2JMwToNOAJ4za9El+J1WOUCj/rrPAj8UUQGAANV9UU//T7gD36/PKNV9QkAVY0C+Nv7t6rW+vMLgfF4DzYwJm8sqJtiJsB9qvo/HRJFvtVpvd3tKyOz/40k9n0yewFrfjHF7DngkyIyHNLP49wH73Of6vXu08DLqtoA1IvICX76xcCL/lN1akXkPH8bJSJS1qd7YcwusJqFKVqqukREvon3VCkHiANXAS3AUf6yTXjt7uB1a3qHH7TfA2b66RcDd4rIzf42pvfhbhizS6yXRtPviEizqlbkuxzG9AZrfjHGmCJiNXVjjCkiVlM3xpgiYkHdGGOKiAV1Y4wpIhbUjTGmiFhQN8aYIvL/AfLSafUi9GSBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rDuXxTe4giA"
      },
      "source": [
        "## Save the model/weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cQF507YFbxr",
        "outputId": "815c6b32-9f41-4100-95c8-529832832d74"
      },
      "source": [
        "# JSON JSON\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "\n",
        "# save the model architecture to JSON file\n",
        "with open('{}/{}.model.json'.format(output_dir, model_name), 'w') as json_file:\n",
        "    json_file.write(json_model)\n",
        "\n",
        "\n",
        "# YAML YAML\n",
        "# serialize model to YAML\n",
        "model_yaml = model.to_yaml()\n",
        "\n",
        "# save the model architecture to YAML file\n",
        "with open(\"{}/{}.model.yaml\".format(output_dir, model_name), \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "\n",
        "\n",
        "# WEIGHTS HDF5\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"{}/{}.model.h5\".format(output_dir,model_name))\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnvbuBhg2Nz7",
        "outputId": "15b943b2-20f9-4e03-b059-c2032b1bb4fb"
      },
      "source": [
        "# Open the handle\n",
        "json_file = open('{}/{}.model.json'.format(output_dir, model_name), 'r')\n",
        "\n",
        "# load json and create model\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights('{}/{}.model.h5'.format(output_dir, model_name))\n",
        "print(\"Loaded model from disk\")\n",
        "# loaded_model_json"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE3Nx-TvvuH4",
        "outputId": "250fd263-c0bf-42e2-d050-1f6fd6eb5d07"
      },
      "source": [
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', \n",
        "                     metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.12903091311454773\n",
            "Test accuracy: 0.9744444489479065\n",
            "accuracy: 97.44%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWD6Pdif9jN7"
      },
      "source": [
        "# ConvNN(PCA) - top 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Qh4VIjF9jOH"
      },
      "source": [
        "## Train/Test split    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXv0NvYf9jOH"
      },
      "source": [
        "# from keras.utils import to_categorical\n",
        "# outcome = encode(outcome['Project_id'])"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjavFaqj9jOI"
      },
      "source": [
        "TC1data15_selected = TC1data15.loc[:,sum_loading.sort_values(ascending=False)[:500].index]"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WGp6_jO9jOI"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(TC1data15_selected, \n",
        "                                                    outcome, \n",
        "                                                    train_size=0.75, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=123, \n",
        "                                                    stratify = outcome)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "R8D3T3_79jOI",
        "outputId": "ac3fec0d-e8b7-4867-dfd4-aafc9069a2ad"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MTND4P12</th>\n",
              "      <th>COX6CP1</th>\n",
              "      <th>MINOS1P3</th>\n",
              "      <th>H19</th>\n",
              "      <th>COX20P1</th>\n",
              "      <th>LTF</th>\n",
              "      <th>PLA2G2A</th>\n",
              "      <th>CST1</th>\n",
              "      <th>ERAP2</th>\n",
              "      <th>RPS28P7</th>\n",
              "      <th>HCG4P5</th>\n",
              "      <th>NLRP2</th>\n",
              "      <th>OLFM4</th>\n",
              "      <th>SST</th>\n",
              "      <th>MTRNR2L1</th>\n",
              "      <th>RP11-109M17.2</th>\n",
              "      <th>GSTM1</th>\n",
              "      <th>PIGR</th>\n",
              "      <th>NTS</th>\n",
              "      <th>IGLV8-61</th>\n",
              "      <th>IGHD</th>\n",
              "      <th>IGF2</th>\n",
              "      <th>EEF1A2</th>\n",
              "      <th>PRSS21</th>\n",
              "      <th>DEFB1</th>\n",
              "      <th>MSLN</th>\n",
              "      <th>CXCL5</th>\n",
              "      <th>CXCL14</th>\n",
              "      <th>MSMB</th>\n",
              "      <th>IGLV10-54</th>\n",
              "      <th>MTND1P23</th>\n",
              "      <th>RP11-467L13.5</th>\n",
              "      <th>C1DP1</th>\n",
              "      <th>IGLV4-60</th>\n",
              "      <th>CD177</th>\n",
              "      <th>BEX1</th>\n",
              "      <th>PCDHB5</th>\n",
              "      <th>PEG10</th>\n",
              "      <th>REG1A</th>\n",
              "      <th>PCSK1N</th>\n",
              "      <th>...</th>\n",
              "      <th>CMBL</th>\n",
              "      <th>SLC16A9</th>\n",
              "      <th>ADRA2C</th>\n",
              "      <th>MMP3</th>\n",
              "      <th>IGKV1-27</th>\n",
              "      <th>ALDOB</th>\n",
              "      <th>ZNF486</th>\n",
              "      <th>SFTPA2</th>\n",
              "      <th>RET</th>\n",
              "      <th>MAGEA3</th>\n",
              "      <th>CCL19</th>\n",
              "      <th>SPOCK1</th>\n",
              "      <th>KRT4</th>\n",
              "      <th>HPN</th>\n",
              "      <th>C16orf89</th>\n",
              "      <th>WFDC21P</th>\n",
              "      <th>COL17A1</th>\n",
              "      <th>ENPP3</th>\n",
              "      <th>AKR1C2</th>\n",
              "      <th>PVALB</th>\n",
              "      <th>KLK1</th>\n",
              "      <th>COL9A3</th>\n",
              "      <th>ABO</th>\n",
              "      <th>AC069213.1</th>\n",
              "      <th>MIR4768</th>\n",
              "      <th>IGHJ2</th>\n",
              "      <th>PTGES</th>\n",
              "      <th>HLA-DRB5</th>\n",
              "      <th>KLK14</th>\n",
              "      <th>DIO1</th>\n",
              "      <th>LINC01291</th>\n",
              "      <th>KIF1A</th>\n",
              "      <th>SCGN</th>\n",
              "      <th>CYP4B1</th>\n",
              "      <th>GJB2</th>\n",
              "      <th>ETV4</th>\n",
              "      <th>AKR1C3</th>\n",
              "      <th>MMP13</th>\n",
              "      <th>C7</th>\n",
              "      <th>RPS26P47</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>1.630203</td>\n",
              "      <td>0.245745</td>\n",
              "      <td>0.617475</td>\n",
              "      <td>1.531048</td>\n",
              "      <td>0.217401</td>\n",
              "      <td>0.151195</td>\n",
              "      <td>1.115843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.270616</td>\n",
              "      <td>2.456450</td>\n",
              "      <td>1.540806</td>\n",
              "      <td>1.604526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.007129</td>\n",
              "      <td>0.539980</td>\n",
              "      <td>1.672453</td>\n",
              "      <td>1.648313</td>\n",
              "      <td>0.848560</td>\n",
              "      <td>0.477534</td>\n",
              "      <td>1.559609</td>\n",
              "      <td>0.254776</td>\n",
              "      <td>1.392720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259556</td>\n",
              "      <td>2.906409</td>\n",
              "      <td>2.674018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.016438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.061648</td>\n",
              "      <td>1.948268</td>\n",
              "      <td>0.997439</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.106625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.192577</td>\n",
              "      <td>0.871038</td>\n",
              "      <td>1.590481</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.511048</td>\n",
              "      <td>...</td>\n",
              "      <td>1.225151</td>\n",
              "      <td>0.779039</td>\n",
              "      <td>1.197374</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.168982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.062244</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.193099</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.358832</td>\n",
              "      <td>0.472861</td>\n",
              "      <td>0.391652</td>\n",
              "      <td>1.782464</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.665729</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.062490</td>\n",
              "      <td>1.045231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.783736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.231831</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.820319</td>\n",
              "      <td>2.458624</td>\n",
              "      <td>0.423180</td>\n",
              "      <td>0.036477</td>\n",
              "      <td>0.401121</td>\n",
              "      <td>0.792815</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.180383</td>\n",
              "      <td>1.317328</td>\n",
              "      <td>1.260198</td>\n",
              "      <td>0.545236</td>\n",
              "      <td>1.281120</td>\n",
              "      <td>1.359645</td>\n",
              "      <td>0.908437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1425</th>\n",
              "      <td>0.913352</td>\n",
              "      <td>1.187209</td>\n",
              "      <td>1.191948</td>\n",
              "      <td>0.555510</td>\n",
              "      <td>0.101678</td>\n",
              "      <td>0.197502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.837544</td>\n",
              "      <td>2.730934</td>\n",
              "      <td>1.052432</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.726351</td>\n",
              "      <td>1.403615</td>\n",
              "      <td>1.051820</td>\n",
              "      <td>2.120729</td>\n",
              "      <td>0.853222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.094274</td>\n",
              "      <td>2.055905</td>\n",
              "      <td>1.146227</td>\n",
              "      <td>1.219891</td>\n",
              "      <td>2.955669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.038178</td>\n",
              "      <td>0.648074</td>\n",
              "      <td>0.117067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.220576</td>\n",
              "      <td>0.402360</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.686118</td>\n",
              "      <td>0.876908</td>\n",
              "      <td>3.009419</td>\n",
              "      <td>0.875238</td>\n",
              "      <td>...</td>\n",
              "      <td>2.159150</td>\n",
              "      <td>1.823950</td>\n",
              "      <td>0.747452</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.461449</td>\n",
              "      <td>1.447322</td>\n",
              "      <td>1.290438</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.876827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.415055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.280801</td>\n",
              "      <td>0.926189</td>\n",
              "      <td>2.486943</td>\n",
              "      <td>0.803509</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.063930</td>\n",
              "      <td>0.771459</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.063281</td>\n",
              "      <td>0.881658</td>\n",
              "      <td>2.967778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.233882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.967798</td>\n",
              "      <td>0.328345</td>\n",
              "      <td>2.090353</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.810105</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.413547</td>\n",
              "      <td>0.376008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3589</th>\n",
              "      <td>2.220811</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.682109</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.046970</td>\n",
              "      <td>1.167290</td>\n",
              "      <td>0.292887</td>\n",
              "      <td>0.507182</td>\n",
              "      <td>3.079196</td>\n",
              "      <td>0.818919</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.961562</td>\n",
              "      <td>1.040686</td>\n",
              "      <td>0.743894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164106</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.330595</td>\n",
              "      <td>2.815335</td>\n",
              "      <td>1.581307</td>\n",
              "      <td>2.238399</td>\n",
              "      <td>2.180905</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.355650</td>\n",
              "      <td>0.842468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.386654</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.184625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.038657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.255080</td>\n",
              "      <td>0.055619</td>\n",
              "      <td>0.450027</td>\n",
              "      <td>1.667057</td>\n",
              "      <td>0.119861</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.063639</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.722241</td>\n",
              "      <td>1.862186</td>\n",
              "      <td>1.322049</td>\n",
              "      <td>1.030614</td>\n",
              "      <td>3.522314</td>\n",
              "      <td>0.511464</td>\n",
              "      <td>0.009834</td>\n",
              "      <td>1.254213</td>\n",
              "      <td>0.331735</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.029226</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.698625</td>\n",
              "      <td>0.211012</td>\n",
              "      <td>1.953720</td>\n",
              "      <td>1.114105</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.967658</td>\n",
              "      <td>2.039305</td>\n",
              "      <td>0.142991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.364465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.035587</td>\n",
              "      <td>1.861667</td>\n",
              "      <td>1.265352</td>\n",
              "      <td>1.807911</td>\n",
              "      <td>0.822396</td>\n",
              "      <td>0.870495</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3076</th>\n",
              "      <td>2.145148</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.741737</td>\n",
              "      <td>0.293831</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.231487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.559480</td>\n",
              "      <td>3.247094</td>\n",
              "      <td>1.450892</td>\n",
              "      <td>1.563270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.534762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.485607</td>\n",
              "      <td>1.713526</td>\n",
              "      <td>0.350373</td>\n",
              "      <td>0.064323</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.523034</td>\n",
              "      <td>0.764995</td>\n",
              "      <td>0.350342</td>\n",
              "      <td>2.994062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.199072</td>\n",
              "      <td>0.478690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.387969</td>\n",
              "      <td>0.719004</td>\n",
              "      <td>1.892532</td>\n",
              "      <td>1.264773</td>\n",
              "      <td>0.269078</td>\n",
              "      <td>1.413557</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.137254</td>\n",
              "      <td>...</td>\n",
              "      <td>1.274865</td>\n",
              "      <td>1.825101</td>\n",
              "      <td>0.531531</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.047832</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.938033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.580836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.345899</td>\n",
              "      <td>1.497002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.222316</td>\n",
              "      <td>2.019364</td>\n",
              "      <td>1.418039</td>\n",
              "      <td>1.392875</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.621660</td>\n",
              "      <td>0.148880</td>\n",
              "      <td>1.728510</td>\n",
              "      <td>0.808624</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219287</td>\n",
              "      <td>0.959566</td>\n",
              "      <td>2.440548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.477342</td>\n",
              "      <td>0.457544</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.616714</td>\n",
              "      <td>0.924051</td>\n",
              "      <td>1.716899</td>\n",
              "      <td>0.625107</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.408402</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2536</th>\n",
              "      <td>2.424581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.597254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.483586</td>\n",
              "      <td>2.980569</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.404005</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.407930</td>\n",
              "      <td>0.920673</td>\n",
              "      <td>1.255731</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.008415</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.379663</td>\n",
              "      <td>1.571226</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005442</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.881680</td>\n",
              "      <td>...</td>\n",
              "      <td>1.202617</td>\n",
              "      <td>0.003669</td>\n",
              "      <td>1.031663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.834961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.134509</td>\n",
              "      <td>0.057327</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003518</td>\n",
              "      <td>3.001422</td>\n",
              "      <td>0.265657</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.744613</td>\n",
              "      <td>0.434405</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.391634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.373754</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.484699</td>\n",
              "      <td>1.645617</td>\n",
              "      <td>0.538638</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.255596</td>\n",
              "      <td>2.249523</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.171322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.652853</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1.579660</td>\n",
              "      <td>0.208330</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.839656</td>\n",
              "      <td>1.429009</td>\n",
              "      <td>0.255109</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.277703</td>\n",
              "      <td>2.712425</td>\n",
              "      <td>0.794239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.293664</td>\n",
              "      <td>3.313475</td>\n",
              "      <td>0.548254</td>\n",
              "      <td>1.804727</td>\n",
              "      <td>0.996873</td>\n",
              "      <td>0.276268</td>\n",
              "      <td>1.485759</td>\n",
              "      <td>0.428918</td>\n",
              "      <td>0.040674</td>\n",
              "      <td>1.607600</td>\n",
              "      <td>0.255471</td>\n",
              "      <td>1.786542</td>\n",
              "      <td>1.670226</td>\n",
              "      <td>2.619017</td>\n",
              "      <td>0.208159</td>\n",
              "      <td>1.332983</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.692859</td>\n",
              "      <td>0.839632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.397033</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.436764</td>\n",
              "      <td>1.446019</td>\n",
              "      <td>1.019898</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.511442</td>\n",
              "      <td>...</td>\n",
              "      <td>1.129023</td>\n",
              "      <td>1.267007</td>\n",
              "      <td>1.270697</td>\n",
              "      <td>0.926668</td>\n",
              "      <td>0.903188</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.757594</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208591</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.275660</td>\n",
              "      <td>0.560434</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.604473</td>\n",
              "      <td>0.475848</td>\n",
              "      <td>0.639650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.829209</td>\n",
              "      <td>0.701115</td>\n",
              "      <td>0.206979</td>\n",
              "      <td>0.715445</td>\n",
              "      <td>1.028109</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.185136</td>\n",
              "      <td>1.720521</td>\n",
              "      <td>1.078745</td>\n",
              "      <td>0.126936</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.754250</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.097907</td>\n",
              "      <td>1.667582</td>\n",
              "      <td>1.861569</td>\n",
              "      <td>0.658981</td>\n",
              "      <td>1.759356</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.680430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1515</th>\n",
              "      <td>2.750741</td>\n",
              "      <td>1.903935</td>\n",
              "      <td>1.317420</td>\n",
              "      <td>1.590538</td>\n",
              "      <td>0.954487</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.280087</td>\n",
              "      <td>2.433834</td>\n",
              "      <td>1.483788</td>\n",
              "      <td>1.090087</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.186110</td>\n",
              "      <td>0.329995</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.171839</td>\n",
              "      <td>1.353750</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.581947</td>\n",
              "      <td>0.321847</td>\n",
              "      <td>0.084858</td>\n",
              "      <td>1.971798</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.504796</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.933845</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.678913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.798841</td>\n",
              "      <td>0.277061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.789633</td>\n",
              "      <td>1.092416</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.595930</td>\n",
              "      <td>...</td>\n",
              "      <td>2.606671</td>\n",
              "      <td>1.669028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.586920</td>\n",
              "      <td>2.107510</td>\n",
              "      <td>0.818226</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.512646</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.327150</td>\n",
              "      <td>2.637343</td>\n",
              "      <td>1.954986</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.712789</td>\n",
              "      <td>0.964484</td>\n",
              "      <td>2.450759</td>\n",
              "      <td>0.017712</td>\n",
              "      <td>0.241909</td>\n",
              "      <td>1.919993</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.482944</td>\n",
              "      <td>1.081477</td>\n",
              "      <td>2.037096</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.278963</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812427</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.948585</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.356338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>1.180832</td>\n",
              "      <td>0.069298</td>\n",
              "      <td>0.509213</td>\n",
              "      <td>0.609682</td>\n",
              "      <td>0.354218</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.088950</td>\n",
              "      <td>0.872839</td>\n",
              "      <td>0.833113</td>\n",
              "      <td>2.991207</td>\n",
              "      <td>0.993619</td>\n",
              "      <td>0.574628</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.582023</td>\n",
              "      <td>0.192836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.256023</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.111299</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.648261</td>\n",
              "      <td>2.301634</td>\n",
              "      <td>3.350609</td>\n",
              "      <td>0.005845</td>\n",
              "      <td>1.175837</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.512434</td>\n",
              "      <td>1.563923</td>\n",
              "      <td>0.788736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.862815</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.277425</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.908714</td>\n",
              "      <td>...</td>\n",
              "      <td>0.130495</td>\n",
              "      <td>0.861961</td>\n",
              "      <td>2.049534</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.219671</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.019632</td>\n",
              "      <td>0.297701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.879252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.213056</td>\n",
              "      <td>0.183887</td>\n",
              "      <td>1.173761</td>\n",
              "      <td>1.169232</td>\n",
              "      <td>0.950213</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.935473</td>\n",
              "      <td>1.425870</td>\n",
              "      <td>1.203349</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.745126</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.069486</td>\n",
              "      <td>0.490883</td>\n",
              "      <td>1.100826</td>\n",
              "      <td>0.325311</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.293410</td>\n",
              "      <td>1.359844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1701</th>\n",
              "      <td>0.722351</td>\n",
              "      <td>0.007708</td>\n",
              "      <td>0.913464</td>\n",
              "      <td>1.817012</td>\n",
              "      <td>1.188879</td>\n",
              "      <td>0.794850</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.755633</td>\n",
              "      <td>2.921452</td>\n",
              "      <td>1.691892</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.206214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.261600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.705418</td>\n",
              "      <td>0.098885</td>\n",
              "      <td>1.803165</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.144449</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.507038</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.834062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.161650</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.780210</td>\n",
              "      <td>1.148091</td>\n",
              "      <td>1.604973</td>\n",
              "      <td>2.409997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.262343</td>\n",
              "      <td>1.606063</td>\n",
              "      <td>0.834399</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.844443</td>\n",
              "      <td>1.985191</td>\n",
              "      <td>1.033268</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.780140</td>\n",
              "      <td>0.750431</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.116194</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.680451</td>\n",
              "      <td>0.306269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.318424</td>\n",
              "      <td>0.290929</td>\n",
              "      <td>1.027218</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.836095</td>\n",
              "      <td>2.707355</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.976585</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.181038</td>\n",
              "      <td>0.523705</td>\n",
              "      <td>1.561028</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.737877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.488987</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1073</th>\n",
              "      <td>0.842437</td>\n",
              "      <td>0.025683</td>\n",
              "      <td>1.426289</td>\n",
              "      <td>0.770426</td>\n",
              "      <td>1.095488</td>\n",
              "      <td>0.082222</td>\n",
              "      <td>1.945936</td>\n",
              "      <td>1.243680</td>\n",
              "      <td>0.382470</td>\n",
              "      <td>1.664291</td>\n",
              "      <td>0.303180</td>\n",
              "      <td>0.265456</td>\n",
              "      <td>2.356733</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.448552</td>\n",
              "      <td>1.337918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.161308</td>\n",
              "      <td>0.697870</td>\n",
              "      <td>1.613278</td>\n",
              "      <td>0.091775</td>\n",
              "      <td>0.869876</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.729846</td>\n",
              "      <td>0.637325</td>\n",
              "      <td>1.480615</td>\n",
              "      <td>2.578329</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.591709</td>\n",
              "      <td>0.893089</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.100443</td>\n",
              "      <td>0.307338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.955610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.656005</td>\n",
              "      <td>0.741200</td>\n",
              "      <td>0.443110</td>\n",
              "      <td>2.268206</td>\n",
              "      <td>0.890002</td>\n",
              "      <td>1.070010</td>\n",
              "      <td>0.791192</td>\n",
              "      <td>0.413477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.944603</td>\n",
              "      <td>1.024003</td>\n",
              "      <td>0.965495</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.233578</td>\n",
              "      <td>0.454626</td>\n",
              "      <td>1.462897</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.156551</td>\n",
              "      <td>0.945926</td>\n",
              "      <td>1.592899</td>\n",
              "      <td>0.877105</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.920872</td>\n",
              "      <td>1.618731</td>\n",
              "      <td>2.335391</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.924176</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.657897</td>\n",
              "      <td>1.058054</td>\n",
              "      <td>0.919741</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.328426</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2700 rows Ã— 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      MTND4P12   COX6CP1  MINOS1P3  ...     MMP13        C7  RPS26P47\n",
              "78    1.630203  0.245745  0.617475  ...  1.281120  1.359645  0.908437\n",
              "1425  0.913352  1.187209  1.191948  ...  0.000000  0.413547  0.376008\n",
              "3589  2.220811  0.000000  0.000000  ...  0.822396  0.870495  0.000000\n",
              "3076  2.145148  0.000000  0.741737  ...  0.000000  1.408402  0.000000\n",
              "2536  2.424581  0.000000  0.000000  ...  0.000000  0.652853  0.000000\n",
              "...        ...       ...       ...  ...       ...       ...       ...\n",
              "13    1.579660  0.208330  0.000000  ...  1.759356  0.000000  0.680430\n",
              "1515  2.750741  1.903935  1.317420  ...  0.000000  0.000000  0.356338\n",
              "67    1.180832  0.069298  0.509213  ...  0.000000  1.293410  1.359844\n",
              "1701  0.722351  0.007708  0.913464  ...  0.000000  1.488987  0.000000\n",
              "1073  0.842437  0.025683  1.426289  ...  0.000000  0.000000  0.328426\n",
              "\n",
              "[2700 rows x 500 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3PjkVCw9jOJ"
      },
      "source": [
        "## CONV1D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5AgkKoH9jOJ"
      },
      "source": [
        "# parameters  \n",
        "activation='relu'\n",
        "batch_size=20\n",
        "# Number of sites\n",
        "classes=15\n",
        "drop = 0.1\n",
        "feature_subsample = 0\n",
        "loss='categorical_crossentropy'\n",
        "# metrics='accuracy'\n",
        "out_act='softmax'\n",
        "pool=[1, 10]\n",
        "# optimizer='sgd'\n",
        "shuffle = False \n",
        "epochs=30\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.1)\n",
        "metrics = ['acc']"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2LvAoev9jOK"
      },
      "source": [
        "# X_train shape: (3375, 300)\n",
        "# X_test shape:  (1125, 300)\n",
        "# Y_train shape: (3375,15)\n",
        "# Y_test shape:  (1125,15)\n",
        "\n",
        "# 300\n",
        "x_train_len = X_train.shape[1]   \n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "# X_train shape: (3375, 300, 1)\n",
        "# X_test shape:  (1125, 300, 1)\n",
        "\n",
        "filters = 128 \n",
        "filter_len = 20 \n",
        "stride = 1 \n",
        "\n",
        "# inside pool_list loop\n",
        "pool_list = [1,10]\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiFAvKKt9jOK",
        "outputId": "fc603d6e-958d-4b78-cd08-1c38b5704488"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add  CONV1D\n",
        "model.add(Conv1D(filters = filters, \n",
        "                 kernel_size = filter_len, \n",
        "                 strides = stride, \n",
        "                 padding='valid', \n",
        "                 input_shape=(x_train_len, 1)))\n",
        "\n",
        "# x_train_len = 300\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 1))\n",
        "\n",
        "filters = 128\n",
        "filter_len = 10 \n",
        "stride = 1 \n",
        "# Conv1D\n",
        "model.add(Conv1D(filters=filters, \n",
        "                 kernel_size=filter_len, \n",
        "                 strides=stride, \n",
        "                 padding='valid'))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 10))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200))\n",
        "\n",
        "# activation \n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(20))\n",
        "# activation\n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(13))\n",
        "model.add(Activation(out_act))\n",
        "\n",
        "model.compile( loss= loss, \n",
        "              optimizer = optimizer, \n",
        "              metrics = metrics )\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 481, 128)          2688      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 481, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 481, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 472, 128)          163968    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 472, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 47, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6016)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               1203400   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                4020      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 13)                273       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13)                0         \n",
            "=================================================================\n",
            "Total params: 1,374,349\n",
            "Trainable params: 1,374,349\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zcL5MDb9jOK"
      },
      "source": [
        "# save\n",
        "# save = '/content/drive/My Drive/FNL_TC1/'\n",
        "output_dir = \"/content/drive/My Drive/FNL_TC1/Model\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "model_name = 'tc1_pca518'\n",
        "path = '{}/{}.autosave.model.h5'.format(output_dir, model_name)\n",
        "checkpointer = ModelCheckpoint(filepath=path,\n",
        "                               verbose=1,\n",
        "                               save_weights_only=True,\n",
        "                               save_best_only=True)\n",
        "\n",
        "csv_logger = CSVLogger('{}/training.log'.format(output_dir))"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC3-Eg6o9jOL"
      },
      "source": [
        "# SR: change epsilon to min_delta\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                              factor=0.1, \n",
        "                              patience=10, \n",
        "                              verbose=1, mode='auto', \n",
        "                              min_delta=0.0001, \n",
        "                              cooldown=0, \n",
        "                              min_lr=0)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gulgZorh9jOL",
        "outputId": "b8558a11-0486-4249-83f8-8ee3c468cb50"
      },
      "source": [
        "# batch_size = 20 \n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, \n",
        "                    epochs=epochs, verbose=1, validation_data=(X_test, Y_test), \n",
        "                    callbacks = [checkpointer, csv_logger, reduce_lr])\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "135/135 [==============================] - 19s 136ms/step - loss: 2.0970 - acc: 0.2836 - val_loss: 0.2946 - val_acc: 0.9333\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.29455, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca518.autosave.model.h5\n",
            "Epoch 2/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.2121 - acc: 0.9367 - val_loss: 0.1102 - val_acc: 0.9667\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.29455 to 0.11023, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca518.autosave.model.h5\n",
            "Epoch 3/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.1141 - acc: 0.9680 - val_loss: 0.0823 - val_acc: 0.9744\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.11023 to 0.08230, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca518.autosave.model.h5\n",
            "Epoch 4/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0373 - acc: 0.9892 - val_loss: 0.0743 - val_acc: 0.9789\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.08230 to 0.07434, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca518.autosave.model.h5\n",
            "Epoch 5/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0280 - acc: 0.9941 - val_loss: 0.0709 - val_acc: 0.9856\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.07434 to 0.07087, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_pca518.autosave.model.h5\n",
            "Epoch 6/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0164 - acc: 0.9945 - val_loss: 0.0954 - val_acc: 0.9822\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.07087\n",
            "Epoch 7/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.0916 - val_acc: 0.9789\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.07087\n",
            "Epoch 8/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0096 - acc: 0.9973 - val_loss: 0.0963 - val_acc: 0.9822\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.07087\n",
            "Epoch 9/30\n",
            "135/135 [==============================] - 18s 131ms/step - loss: 0.0053 - acc: 0.9995 - val_loss: 0.1125 - val_acc: 0.9811\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.07087\n",
            "Epoch 10/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0063 - acc: 0.9970 - val_loss: 0.0966 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.07087\n",
            "Epoch 11/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0071 - acc: 0.9972 - val_loss: 0.0975 - val_acc: 0.9833\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.07087\n",
            "Epoch 12/30\n",
            "135/135 [==============================] - 18s 135ms/step - loss: 0.0062 - acc: 0.9989 - val_loss: 0.0999 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.07087\n",
            "Epoch 13/30\n",
            "135/135 [==============================] - 18s 135ms/step - loss: 0.0040 - acc: 0.9983 - val_loss: 0.1033 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.07087\n",
            "Epoch 14/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0038 - acc: 0.9991 - val_loss: 0.1172 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.07087\n",
            "Epoch 15/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0039 - acc: 0.9983 - val_loss: 0.0990 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.07087\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 16/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0035 - acc: 0.9991 - val_loss: 0.0982 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.07087\n",
            "Epoch 17/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0989 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.07087\n",
            "Epoch 18/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0062 - acc: 0.9989 - val_loss: 0.0981 - val_acc: 0.9833\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.07087\n",
            "Epoch 19/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0043 - acc: 0.9979 - val_loss: 0.0990 - val_acc: 0.9833\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.07087\n",
            "Epoch 20/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0042 - acc: 0.9992 - val_loss: 0.1003 - val_acc: 0.9833\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.07087\n",
            "Epoch 21/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.1007 - val_acc: 0.9833\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.07087\n",
            "Epoch 22/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.1005 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.07087\n",
            "Epoch 23/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9833\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.07087\n",
            "Epoch 24/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0041 - acc: 0.9990 - val_loss: 0.0992 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.07087\n",
            "Epoch 25/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0969 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.07087\n",
            "\n",
            "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 26/30\n",
            "135/135 [==============================] - 18s 132ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0971 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.07087\n",
            "Epoch 27/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0970 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.07087\n",
            "Epoch 28/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 9.3375e-04 - acc: 0.9999 - val_loss: 0.0970 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.07087\n",
            "Epoch 29/30\n",
            "135/135 [==============================] - 18s 133ms/step - loss: 0.0013 - acc: 0.9999 - val_loss: 0.0973 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.07087\n",
            "Epoch 30/30\n",
            "135/135 [==============================] - 18s 135ms/step - loss: 0.0048 - acc: 0.9971 - val_loss: 0.0975 - val_acc: 0.9844\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.07087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IER414OS9jOL",
        "outputId": "d08baaf4-1bf8-4153-b538-a61bdf7473a1"
      },
      "source": [
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.0974946841597557\n",
            "Test accuracy: 0.9844444394111633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "3jZvmHoA9jOL",
        "outputId": "07df69c5-5899-4e20-ebd1-a2b5965f4de5"
      },
      "source": [
        "plt.plot(history.history['acc'],label=\"accuracy\")\n",
        "plt.plot(history.history['val_acc'],label=\"val_accuracy\")\n",
        "plt.plot(history.history['loss'],label=\"loss\")\n",
        "plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"Top 500 features\")\n",
        "plt.xlabel('epoch')\n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oD3r1zal9jOM"
      },
      "source": [
        "## Save the model/weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aewZiaoE9jOM",
        "outputId": "dcb148e6-a6b6-4b9b-f87b-aab1923c49b1"
      },
      "source": [
        "# JSON JSON\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "\n",
        "# save the model architecture to JSON file\n",
        "with open('{}/{}.model.json'.format(output_dir, model_name), 'w') as json_file:\n",
        "    json_file.write(json_model)\n",
        "\n",
        "\n",
        "# YAML YAML\n",
        "# serialize model to YAML\n",
        "model_yaml = model.to_yaml()\n",
        "\n",
        "# save the model architecture to YAML file\n",
        "with open(\"{}/{}.model.yaml\".format(output_dir, model_name), \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "\n",
        "\n",
        "# WEIGHTS HDF5\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"{}/{}.model.h5\".format(output_dir,model_name))\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS1Xc4Xg9jOM",
        "outputId": "6750f75e-e184-4c97-cf4a-1be72f533164"
      },
      "source": [
        "# Open the handle\n",
        "json_file = open('{}/{}.model.json'.format(output_dir, model_name), 'r')\n",
        "\n",
        "# load json and create model\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights('{}/{}.model.h5'.format(output_dir, model_name))\n",
        "print(\"Loaded model from disk\")\n",
        "# loaded_model_json"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJcbPUxc9jON",
        "outputId": "0d806c53-6f80-4440-d914-bfbac2beffae"
      },
      "source": [
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', \n",
        "                     metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.0974946841597557\n",
            "Test accuracy: 0.9844444394111633\n",
            "accuracy: 98.44%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
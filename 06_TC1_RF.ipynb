{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_TC1_RF.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNtOAzv1snxBrCRRHXD6PAk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mengyaoo/FNL_GenesSelection/blob/main/06_TC1_RF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-iE_t7nyh1Q"
      },
      "source": [
        "# Load the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-23T11:46:55.156880Z",
          "start_time": "2020-11-23T11:46:54.748422Z"
        },
        "id": "V5Zg0wifMGGJ"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os, sys, gzip, glob, json, time, argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "from pandas.io.json import json_normalize\n",
        "\n",
        "from pandas.io.json import json_normalize\n",
        "from keras.utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten\n",
        "from keras import optimizers\n",
        "from keras.optimizers import SGD, Adam, RMSprop\n",
        "from keras.models import Sequential, Model, model_from_json, model_from_yaml\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.linear_model import Lasso, LogisticRegression\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "import sklearn.manifold as sk_manif\n",
        "from keras.utils import to_categorical\n",
        "from google.colab import drive\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwUo3_68MGGJ"
      },
      "source": [
        "# Data Preparation   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNRDQKlmiyGw",
        "outputId": "07d6f0dd-154b-481d-85e2-003f6fafb0ee"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-23T06:24:03.697460Z",
          "start_time": "2020-11-23T06:04:41.100012Z"
        },
        "id": "f8SDzPeuMGGK"
      },
      "source": [
        "# Read features and output files \n",
        "TC1data15 = pd.read_csv(\"/content/drive/My Drive/FNL_TC1/TC1-S1-data15-genename.tsv\", sep=\"\\t\", low_memory = False)\n",
        "#TC1data15 = sfeatures1\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-11-23T06:24:03.787859Z",
          "start_time": "2020-11-23T06:24:03.727784Z"
        },
        "id": "955mydtlMGGK"
      },
      "source": [
        "outcome = pd.read_csv('/content/drive/My Drive/FNL_TC1/TC1-outcome-data15-projectname.tsv', sep='\\t')\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEMDGF4K7D4B"
      },
      "source": [
        "def encode(data): \n",
        "    print('Shape of data (BEFORE encode): %s' % str(data.shape))\n",
        "    encoded = to_categorical(data)\n",
        "    print('Shape of data (AFTER  encode): %s\\n' % str(encoded.shape))\n",
        "    return encoded"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_Relc1R1EnL"
      },
      "source": [
        "# outcome = encode(outcome['Project_id'])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d3-7dxFyH8c"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uzfRSFtsJst",
        "outputId": "eb01c4c8-aa47-41c5-f752-3e7205c67864"
      },
      "source": [
        "np.random.seed(123)\n",
        "# define the model\n",
        "model = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
        "# fit the model\n",
        "model.fit(TC1data15, outcome['Project_id'])\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEH8VH2myVWl"
      },
      "source": [
        "# get importance\n",
        "importance = model.feature_importances_\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlEuwnboz8EF"
      },
      "source": [
        "feature = pd.DataFrame()\n",
        "feature['name'] = TC1data15.columns"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "JW-IKLjYz5XQ",
        "outputId": "a3e939c6-7909-4ab2-b9be-87188ddb76ea"
      },
      "source": [
        "feature['importance'] = importance\n",
        "feature"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TSPAN6</td>\n",
              "      <td>0.000299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TNMD</td>\n",
              "      <td>0.000014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DPM1</td>\n",
              "      <td>0.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SCYL3</td>\n",
              "      <td>0.000063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C1orf112</td>\n",
              "      <td>0.000039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60478</th>\n",
              "      <td>Metazoa_SRP.305</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60479</th>\n",
              "      <td>AJ271736.1.1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60480</th>\n",
              "      <td>MIR6089.1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60481</th>\n",
              "      <td>RP13-465B17.5.1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60482</th>\n",
              "      <td>RP13-465B17.4.1</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60483 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                  name  importance\n",
              "0               TSPAN6    0.000299\n",
              "1                 TNMD    0.000014\n",
              "2                 DPM1    0.000002\n",
              "3                SCYL3    0.000063\n",
              "4             C1orf112    0.000039\n",
              "...                ...         ...\n",
              "60478  Metazoa_SRP.305    0.000000\n",
              "60479     AJ271736.1.1    0.000000\n",
              "60480        MIR6089.1    0.000000\n",
              "60481  RP13-465B17.5.1    0.000000\n",
              "60482  RP13-465B17.4.1    0.000000\n",
              "\n",
              "[60483 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NJhcMKL1eeW"
      },
      "source": [
        "feature_sort = feature.sort_values(by='importance',ascending=False)\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t4JMCrz2Cak"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68AuDd4U3Zs4"
      },
      "source": [
        ""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvc0DUNEFbxk"
      },
      "source": [
        "# ConvNN(RF) - top 150"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h4agjwbFbxl"
      },
      "source": [
        "## Train/Test split    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0niWyzNw6Ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61430d78-064e-4f66-84fa-a5a47a7e6082"
      },
      "source": [
        "# from keras.utils import to_categorical\n",
        "outcome = encode(outcome['Project_id'])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data (BEFORE encode): (4500,)\n",
            "Shape of data (AFTER  encode): (4500, 15)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT6lILqx6g5W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0a14336e-1286-459a-e7b5-c5f5f702363a"
      },
      "source": [
        "#feature_sort_selected = feature_sort[feature_sort['importance'] > 0.001]\n",
        "feature_sort_selected = feature_sort.iloc[:150,:]\n",
        "feature_sort_selected"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3300</th>\n",
              "      <td>MOGAT3</td>\n",
              "      <td>0.003089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57644</th>\n",
              "      <td>FP671120.6</td>\n",
              "      <td>0.002802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12189</th>\n",
              "      <td>KLK4</td>\n",
              "      <td>0.002783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1448</th>\n",
              "      <td>CDH17</td>\n",
              "      <td>0.002782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17545</th>\n",
              "      <td>KLHL14</td>\n",
              "      <td>0.002726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8372</th>\n",
              "      <td>LYPLAL1</td>\n",
              "      <td>0.000929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5174</th>\n",
              "      <td>CSTA</td>\n",
              "      <td>0.000928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7744</th>\n",
              "      <td>ENPEP</td>\n",
              "      <td>0.000920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16372</th>\n",
              "      <td>TRABD2A</td>\n",
              "      <td>0.000915</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>IYD</td>\n",
              "      <td>0.000903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             name  importance\n",
              "3300       MOGAT3    0.003089\n",
              "57644  FP671120.6    0.002802\n",
              "12189        KLK4    0.002783\n",
              "1448        CDH17    0.002782\n",
              "17545      KLHL14    0.002726\n",
              "...           ...         ...\n",
              "8372      LYPLAL1    0.000929\n",
              "5174         CSTA    0.000928\n",
              "7744        ENPEP    0.000920\n",
              "16372     TRABD2A    0.000915\n",
              "237           IYD    0.000903\n",
              "\n",
              "[150 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RS9D16qIFbxn"
      },
      "source": [
        "TC1data15_selected = TC1data15.loc[:,feature_sort_selected['name']]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PWsfc3nFbxo"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(TC1data15_selected, \n",
        "                                                    outcome, \n",
        "                                                    train_size=0.75, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=123, \n",
        "                                                    stratify = outcome)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "ELJV_czkHjbj",
        "outputId": "e1bf4e1a-fce1-407f-8e40-4d1c3967b12f"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MOGAT3</th>\n",
              "      <th>FP671120.6</th>\n",
              "      <th>KLK4</th>\n",
              "      <th>CDH17</th>\n",
              "      <th>KLHL14</th>\n",
              "      <th>NAPSA</th>\n",
              "      <th>VTN</th>\n",
              "      <th>SFTPB</th>\n",
              "      <th>RDH11</th>\n",
              "      <th>RP11-452C8.1</th>\n",
              "      <th>SOX17</th>\n",
              "      <th>SFTPA1</th>\n",
              "      <th>CRYGN</th>\n",
              "      <th>RP11-53M11.5</th>\n",
              "      <th>FP671120.4</th>\n",
              "      <th>AP001187.9</th>\n",
              "      <th>KLK2</th>\n",
              "      <th>F13B</th>\n",
              "      <th>S1PR5</th>\n",
              "      <th>HRG</th>\n",
              "      <th>KLK3</th>\n",
              "      <th>ITIH2</th>\n",
              "      <th>TRPS1</th>\n",
              "      <th>RP5-1021I20.2</th>\n",
              "      <th>ACSM2B</th>\n",
              "      <th>UGT2B4</th>\n",
              "      <th>PRODH2</th>\n",
              "      <th>FEV</th>\n",
              "      <th>MASP2</th>\n",
              "      <th>SFTPC</th>\n",
              "      <th>FP236383.4</th>\n",
              "      <th>KCNJ10</th>\n",
              "      <th>PRAC2</th>\n",
              "      <th>GRHL2</th>\n",
              "      <th>SFTA3</th>\n",
              "      <th>SLC28A1</th>\n",
              "      <th>NXPE1</th>\n",
              "      <th>LINC00483</th>\n",
              "      <th>CHRNA2</th>\n",
              "      <th>SFTPA2</th>\n",
              "      <th>...</th>\n",
              "      <th>SLC13A1</th>\n",
              "      <th>DHRS7</th>\n",
              "      <th>PCAT14</th>\n",
              "      <th>THRSP</th>\n",
              "      <th>RP11-320M16.1</th>\n",
              "      <th>SLC17A5</th>\n",
              "      <th>HNF1B</th>\n",
              "      <th>CITED1</th>\n",
              "      <th>EMX2OS</th>\n",
              "      <th>DAB2</th>\n",
              "      <th>RP11-894P9.2</th>\n",
              "      <th>FAM83D</th>\n",
              "      <th>SOX15</th>\n",
              "      <th>PHGR1</th>\n",
              "      <th>NCAPH</th>\n",
              "      <th>HOXA11-AS</th>\n",
              "      <th>REEP5</th>\n",
              "      <th>C2orf72</th>\n",
              "      <th>PKMP3</th>\n",
              "      <th>HIST1H4C</th>\n",
              "      <th>STX18</th>\n",
              "      <th>NKX2-1</th>\n",
              "      <th>TSPAN8</th>\n",
              "      <th>SFTPD</th>\n",
              "      <th>AC079949.1</th>\n",
              "      <th>GPRASP1</th>\n",
              "      <th>ZNF761</th>\n",
              "      <th>HNF4A</th>\n",
              "      <th>TRIM31</th>\n",
              "      <th>STK32A</th>\n",
              "      <th>SCGB3A2</th>\n",
              "      <th>TMTC2</th>\n",
              "      <th>CTD-2182N23.1</th>\n",
              "      <th>CTD-2033D15.3</th>\n",
              "      <th>MTATP8P1</th>\n",
              "      <th>LYPLAL1</th>\n",
              "      <th>CSTA</th>\n",
              "      <th>ENPEP</th>\n",
              "      <th>TRABD2A</th>\n",
              "      <th>IYD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.808450</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.672119</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.346068</td>\n",
              "      <td>1.155254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.424186</td>\n",
              "      <td>3.167719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.465801</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094042</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022084</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.362394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.636991</td>\n",
              "      <td>2.317114</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.142535</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.722872</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.404875</td>\n",
              "      <td>1.387987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.216216</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.742966</td>\n",
              "      <td>0.574371</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.391520</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.224036</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>1.307300</td>\n",
              "      <td>2.334584</td>\n",
              "      <td>2.117538</td>\n",
              "      <td>3.530239</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.506487</td>\n",
              "      <td>1.195097</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624641</td>\n",
              "      <td>1.173266</td>\n",
              "      <td>3.894196</td>\n",
              "      <td>0.568636</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.323987</td>\n",
              "      <td>1.774033</td>\n",
              "      <td>0.659895</td>\n",
              "      <td>0.378688</td>\n",
              "      <td>0.184754</td>\n",
              "      <td>0.529635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.465524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257574</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.773058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.566138</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.110626</td>\n",
              "      <td>1.734314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137554</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.877394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.056890</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.397143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.302443</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.896840</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.476843</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.905280</td>\n",
              "      <td>0.946957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.124891</td>\n",
              "      <td>1.014214</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.656383</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.794737</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.695195</td>\n",
              "      <td>1.416065</td>\n",
              "      <td>0.875379</td>\n",
              "      <td>0.432093</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157242</td>\n",
              "      <td>0.601505</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.690877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.297473</td>\n",
              "      <td>1.752160</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041478</td>\n",
              "      <td>0.576785</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.296192</td>\n",
              "      <td>0.444143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.557529</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.834996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.713397</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.790730</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.164811</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.264516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.108063</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.198673</td>\n",
              "      <td>1.639945</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.288918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.049239</td>\n",
              "      <td>0.091759</td>\n",
              "      <td>0.079637</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.285677</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.251281</td>\n",
              "      <td>0.892222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.426151</td>\n",
              "      <td>1.161551</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.441804</td>\n",
              "      <td>0.936748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.650158</td>\n",
              "      <td>1.640085</td>\n",
              "      <td>2.584387</td>\n",
              "      <td>0.579072</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4447</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.192705</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.284720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.596492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.039429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.153790</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.478587</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.104923</td>\n",
              "      <td>1.309775</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.169633</td>\n",
              "      <td>1.169120</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.347202</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.135975</td>\n",
              "      <td>0.851538</td>\n",
              "      <td>1.852621</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.073002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.991055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.159981</td>\n",
              "      <td>1.560701</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.234236</td>\n",
              "      <td>0.756711</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.013137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.127141</td>\n",
              "      <td>0.611338</td>\n",
              "      <td>1.133352</td>\n",
              "      <td>1.272749</td>\n",
              "      <td>0.042281</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.948668</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.531098</td>\n",
              "      <td>0.094371</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.352760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.316836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.133977</td>\n",
              "      <td>2.396390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.550796</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.164986</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818311</td>\n",
              "      <td>1.543859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.112370</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.558533</td>\n",
              "      <td>0.581620</td>\n",
              "      <td>1.293007</td>\n",
              "      <td>0.846962</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.340738</td>\n",
              "      <td>1.110707</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.046446</td>\n",
              "      <td>0.930447</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.594739</td>\n",
              "      <td>0.164553</td>\n",
              "      <td>1.987460</td>\n",
              "      <td>0.071945</td>\n",
              "      <td>0.025061</td>\n",
              "      <td>1.383111</td>\n",
              "      <td>1.287079</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.783670</td>\n",
              "      <td>0.652411</td>\n",
              "      <td>2.339878</td>\n",
              "      <td>0.098467</td>\n",
              "      <td>0.960581</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.417634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.715914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.890756</td>\n",
              "      <td>1.302296</td>\n",
              "      <td>0.695939</td>\n",
              "      <td>0.377802</td>\n",
              "      <td>0.475185</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3495</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.671380</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.636459</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.288064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018219</td>\n",
              "      <td>1.585684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.088985</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.446712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.545132</td>\n",
              "      <td>1.356004</td>\n",
              "      <td>1.099013</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.371561</td>\n",
              "      <td>1.543170</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.980783</td>\n",
              "      <td>1.321003</td>\n",
              "      <td>0.293559</td>\n",
              "      <td>1.280170</td>\n",
              "      <td>1.200152</td>\n",
              "      <td>2.072052</td>\n",
              "      <td>0.670167</td>\n",
              "      <td>0.361690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.081560</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.928711</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.923557</td>\n",
              "      <td>0.846342</td>\n",
              "      <td>0.483691</td>\n",
              "      <td>2.416601</td>\n",
              "      <td>0.293333</td>\n",
              "      <td>0.202316</td>\n",
              "      <td>1.030115</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.318919</td>\n",
              "      <td>0.633757</td>\n",
              "      <td>1.025426</td>\n",
              "      <td>2.048362</td>\n",
              "      <td>0.339778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.168646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>1.163849</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.163344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.669915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.229859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.438474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.735723</td>\n",
              "      <td>1.644623</td>\n",
              "      <td>1.537464</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.596512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.849123</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.766706</td>\n",
              "      <td>1.911327</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.298232</td>\n",
              "      <td>1.628883</td>\n",
              "      <td>1.537264</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.511547</td>\n",
              "      <td>2.456354</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.704616</td>\n",
              "      <td>0.192395</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.404002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.279811</td>\n",
              "      <td>0.449992</td>\n",
              "      <td>0.312601</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.985595</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.919941</td>\n",
              "      <td>0.653788</td>\n",
              "      <td>1.241108</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.014076</td>\n",
              "      <td>1.205668</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.295535</td>\n",
              "      <td>0.806354</td>\n",
              "      <td>1.326476</td>\n",
              "      <td>0.615109</td>\n",
              "      <td>2.152830</td>\n",
              "      <td>0.155142</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.148528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.766090</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.383600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.399102</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.593394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.320577</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.065513</td>\n",
              "      <td>1.582818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.660055</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.218918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.928156</td>\n",
              "      <td>1.417927</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.859123</td>\n",
              "      <td>1.720526</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.015730</td>\n",
              "      <td>1.341435</td>\n",
              "      <td>1.992565</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.585731</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.414894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.347956</td>\n",
              "      <td>0.319134</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.813492</td>\n",
              "      <td>1.189119</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.190492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.238744</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.225224</td>\n",
              "      <td>1.023040</td>\n",
              "      <td>1.308796</td>\n",
              "      <td>1.928726</td>\n",
              "      <td>0.631766</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1573</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.657723</td>\n",
              "      <td>0.152280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.482651</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.282959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.991760</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.281678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.905957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.355204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.479118</td>\n",
              "      <td>1.344476</td>\n",
              "      <td>0.602477</td>\n",
              "      <td>0.266197</td>\n",
              "      <td>1.523006</td>\n",
              "      <td>0.620468</td>\n",
              "      <td>0.361499</td>\n",
              "      <td>1.744520</td>\n",
              "      <td>0.393543</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.576877</td>\n",
              "      <td>0.338258</td>\n",
              "      <td>1.875051</td>\n",
              "      <td>0.236506</td>\n",
              "      <td>0.198766</td>\n",
              "      <td>0.113553</td>\n",
              "      <td>1.889366</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.456324</td>\n",
              "      <td>0.491477</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.302135</td>\n",
              "      <td>1.064303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.029043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.436072</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.144267</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3192</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.369517</td>\n",
              "      <td>0.455298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.917144</td>\n",
              "      <td>1.889821</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.852791</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.617423</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.643908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.725373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.392420</td>\n",
              "      <td>2.243345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.962573</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.502918</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.460585</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.165908</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.163904</td>\n",
              "      <td>0.649794</td>\n",
              "      <td>0.068025</td>\n",
              "      <td>0.490507</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.259610</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.485967</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.092849</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.060564</td>\n",
              "      <td>2.440980</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.054731</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.534572</td>\n",
              "      <td>0.793290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.135232</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.971737</td>\n",
              "      <td>3.215473</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.091272</td>\n",
              "      <td>1.267510</td>\n",
              "      <td>0.154179</td>\n",
              "      <td>0.967334</td>\n",
              "      <td>0.566856</td>\n",
              "      <td>1.581944</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3375 rows × 150 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        MOGAT3  FP671120.6      KLK4  ...     ENPEP   TRABD2A       IYD\n",
              "849   0.000000    0.000000  0.000000  ...  0.378688  0.184754  0.529635\n",
              "1050  0.000000    0.000000  0.000000  ...  0.432093  0.000000  0.000000\n",
              "835   0.000000    0.157242  0.601505  ...  0.579072  0.000000  0.000000\n",
              "4447  0.000000    0.000000  0.000000  ...  0.042281  0.000000  0.000000\n",
              "53    0.000000    1.948668  0.000000  ...  0.377802  0.475185  0.000000\n",
              "...        ...         ...       ...  ...       ...       ...       ...\n",
              "3495  0.000000    0.000000  0.000000  ...  0.339778  0.000000  0.168646\n",
              "1737  1.163849    0.000000  0.000000  ...  2.152830  0.155142  0.000000\n",
              "2943  0.000000    0.000000  0.000000  ...  0.631766  0.000000  0.000000\n",
              "1573  0.000000    0.000000  0.000000  ...  0.144267  0.000000  0.000000\n",
              "3192  0.000000    0.000000  0.000000  ...  0.967334  0.566856  1.581944\n",
              "\n",
              "[3375 rows x 150 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4NiRi1SFbxo"
      },
      "source": [
        "## CONV1D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjD0T5I2Fbxo"
      },
      "source": [
        "# parameters  \n",
        "activation='relu'\n",
        "batch_size=20\n",
        "# Number of sites\n",
        "classes=15\n",
        "drop = 0.1\n",
        "feature_subsample = 0\n",
        "loss='categorical_crossentropy'\n",
        "# metrics='accuracy'\n",
        "out_act='softmax'\n",
        "pool=[1, 10]\n",
        "# optimizer='sgd'\n",
        "shuffle = False \n",
        "epochs=30\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.1)\n",
        "metrics = ['acc']"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztdyDFcoTXTH"
      },
      "source": [
        "x_train_len = X_train.shape[1]   \n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "filters = 128 \n",
        "filter_len = 20 \n",
        "stride = 1 \n",
        "\n",
        "# inside pool_list loop\n",
        "pool_list = [1,10]\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muxPrNNYFbxp",
        "outputId": "c160860b-ca3e-4b2b-bf0c-ff9e13620116"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add  CONV1D\n",
        "model.add(Conv1D(filters = filters, \n",
        "                 kernel_size = filter_len, \n",
        "                 strides = stride, \n",
        "                 padding='valid', \n",
        "                 input_shape=(x_train_len, 1)))\n",
        "\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 1))\n",
        "\n",
        "filters = 128\n",
        "filter_len = 10 \n",
        "stride = 1 \n",
        "# Conv1D\n",
        "model.add(Conv1D(filters=filters, \n",
        "                 kernel_size=filter_len, \n",
        "                 strides=stride, \n",
        "                 padding='valid'))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 10))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200))\n",
        "\n",
        "# activation \n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(20))\n",
        "# activation\n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(15))\n",
        "model.add(Activation(out_act))\n",
        "\n",
        "model.compile( loss= loss, \n",
        "              optimizer = optimizer, \n",
        "              metrics = metrics )\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 131, 128)          2688      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 131, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 131, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 122, 128)          163968    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 122, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 12, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               307400    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                4020      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                315       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 478,391\n",
            "Trainable params: 478,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwoVbhQMFbxp"
      },
      "source": [
        "# save\n",
        "# save = '/content/drive/My Drive/FNL_TC1/'\n",
        "output_dir = \"/content/drive/My Drive/FNL_TC1/Model\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "model_name = 'tc1_rf'\n",
        "path = '{}/{}.autosave.model.h5'.format(output_dir, model_name)\n",
        "checkpointer = ModelCheckpoint(filepath=path,\n",
        "                               verbose=1,\n",
        "                               save_weights_only=True,\n",
        "                               save_best_only=True)\n",
        "\n",
        "csv_logger = CSVLogger('{}/training.log'.format(output_dir))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBFfONmUFbxq"
      },
      "source": [
        "# SR: change epsilon to min_delta\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                              factor=0.1, \n",
        "                              patience=10, \n",
        "                              verbose=1, mode='auto', \n",
        "                              min_delta=0.0001, \n",
        "                              cooldown=0, \n",
        "                              min_lr=0)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVfcLEdgFbxq",
        "outputId": "bd4fb0af-d58f-4ffc-ff49-844db871a9b6"
      },
      "source": [
        "# batch_size = 20 \n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, \n",
        "                    epochs=epochs, verbose=1, validation_data=(X_test, Y_test), \n",
        "                    callbacks = [checkpointer, csv_logger, reduce_lr])\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "169/169 [==============================] - 8s 44ms/step - loss: 1.7479 - acc: 0.4423 - val_loss: 0.3709 - val_acc: 0.8782\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.37092, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 2/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.3397 - acc: 0.8906 - val_loss: 0.2738 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.37092 to 0.27380, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 3/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.2417 - acc: 0.9217 - val_loss: 0.2471 - val_acc: 0.9324\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.27380 to 0.24714, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 4/30\n",
            "169/169 [==============================] - 8s 45ms/step - loss: 0.1942 - acc: 0.9296 - val_loss: 0.2115 - val_acc: 0.9404\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.24714 to 0.21154, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 5/30\n",
            "169/169 [==============================] - 8s 46ms/step - loss: 0.1771 - acc: 0.9373 - val_loss: 0.2150 - val_acc: 0.9369\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.21154\n",
            "Epoch 6/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.1716 - acc: 0.9420 - val_loss: 0.2055 - val_acc: 0.9396\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.21154 to 0.20550, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 7/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.1276 - acc: 0.9517 - val_loss: 0.2280 - val_acc: 0.9316\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.20550\n",
            "Epoch 8/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.1310 - acc: 0.9511 - val_loss: 0.5146 - val_acc: 0.8640\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.20550\n",
            "Epoch 9/30\n",
            "169/169 [==============================] - 7s 41ms/step - loss: 0.1184 - acc: 0.9621 - val_loss: 0.2904 - val_acc: 0.9138\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.20550\n",
            "Epoch 10/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.1247 - acc: 0.9577 - val_loss: 0.1963 - val_acc: 0.9378\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.20550 to 0.19634, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 11/30\n",
            "169/169 [==============================] - 7s 41ms/step - loss: 0.1089 - acc: 0.9661 - val_loss: 0.1927 - val_acc: 0.9538\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.19634 to 0.19269, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 12/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0854 - acc: 0.9673 - val_loss: 0.2173 - val_acc: 0.9431\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.19269\n",
            "Epoch 13/30\n",
            "169/169 [==============================] - 7s 43ms/step - loss: 0.0904 - acc: 0.9695 - val_loss: 0.2201 - val_acc: 0.9396\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.19269\n",
            "Epoch 14/30\n",
            "169/169 [==============================] - 7s 41ms/step - loss: 0.0895 - acc: 0.9629 - val_loss: 0.2112 - val_acc: 0.9467\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.19269\n",
            "Epoch 15/30\n",
            "169/169 [==============================] - 7s 41ms/step - loss: 0.0611 - acc: 0.9786 - val_loss: 0.2668 - val_acc: 0.9316\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.19269\n",
            "Epoch 16/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0682 - acc: 0.9750 - val_loss: 0.2037 - val_acc: 0.9458\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.19269\n",
            "Epoch 17/30\n",
            "169/169 [==============================] - 7s 41ms/step - loss: 0.0549 - acc: 0.9850 - val_loss: 0.2208 - val_acc: 0.9493\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.19269\n",
            "Epoch 18/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0579 - acc: 0.9822 - val_loss: 0.2205 - val_acc: 0.9467\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.19269\n",
            "Epoch 19/30\n",
            "169/169 [==============================] - 7s 43ms/step - loss: 0.0468 - acc: 0.9859 - val_loss: 0.2185 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.19269\n",
            "Epoch 20/30\n",
            "169/169 [==============================] - 7s 43ms/step - loss: 0.0474 - acc: 0.9846 - val_loss: 0.2511 - val_acc: 0.9431\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.19269\n",
            "Epoch 21/30\n",
            "169/169 [==============================] - 7s 41ms/step - loss: 0.0579 - acc: 0.9794 - val_loss: 0.2604 - val_acc: 0.9484\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.19269\n",
            "\n",
            "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 22/30\n",
            "169/169 [==============================] - 7s 44ms/step - loss: 0.0325 - acc: 0.9888 - val_loss: 0.2354 - val_acc: 0.9520\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.19269\n",
            "Epoch 23/30\n",
            "169/169 [==============================] - 7s 41ms/step - loss: 0.0183 - acc: 0.9945 - val_loss: 0.2380 - val_acc: 0.9529\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.19269\n",
            "Epoch 24/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0218 - acc: 0.9919 - val_loss: 0.2428 - val_acc: 0.9520\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.19269\n",
            "Epoch 25/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0157 - acc: 0.9957 - val_loss: 0.2429 - val_acc: 0.9511\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.19269\n",
            "Epoch 26/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0158 - acc: 0.9957 - val_loss: 0.2482 - val_acc: 0.9538\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.19269\n",
            "Epoch 27/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0123 - acc: 0.9976 - val_loss: 0.2552 - val_acc: 0.9520\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.19269\n",
            "Epoch 28/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.2600 - val_acc: 0.9547\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.19269\n",
            "Epoch 29/30\n",
            "169/169 [==============================] - 7s 41ms/step - loss: 0.0198 - acc: 0.9901 - val_loss: 0.2609 - val_acc: 0.9529\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.19269\n",
            "Epoch 30/30\n",
            "169/169 [==============================] - 7s 42ms/step - loss: 0.0127 - acc: 0.9955 - val_loss: 0.2654 - val_acc: 0.9538\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.19269\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppzHiTkLFbxq",
        "outputId": "206315cb-4ed8-48d1-ed68-8cd770b95593"
      },
      "source": [
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.26539793610572815\n",
            "Test accuracy: 0.9537777900695801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "O9NCt5MkFbxq",
        "outputId": "8d27ef6f-711d-4a6b-e1b1-2adfb34a3f2a"
      },
      "source": [
        "plt.plot(history.history['acc'],label=\"accuracy\")\n",
        "plt.plot(history.history['val_acc'],label=\"val_accuracy\")\n",
        "plt.plot(history.history['loss'],label=\"loss\")\n",
        "plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"FR Feature Selection\")\n",
        "plt.xlabel('epoch')\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rDuXxTe4giA"
      },
      "source": [
        "## Save the model/weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cQF507YFbxr",
        "outputId": "3d03cf40-f02c-4efa-9df1-1e51c37b33c3"
      },
      "source": [
        "# JSON JSON\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "\n",
        "# save the model architecture to JSON file\n",
        "with open('{}/{}.model.json'.format(output_dir, model_name), 'w') as json_file:\n",
        "    json_file.write(json_model)\n",
        "\n",
        "\n",
        "# YAML YAML\n",
        "# serialize model to YAML\n",
        "model_yaml = model.to_yaml()\n",
        "\n",
        "# save the model architecture to YAML file\n",
        "with open(\"{}/{}.model.yaml\".format(output_dir, model_name), \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "\n",
        "\n",
        "# WEIGHTS HDF5\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"{}/{}.model.h5\".format(output_dir,model_name))\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnvbuBhg2Nz7",
        "outputId": "b4077920-6000-4d7b-a658-5969eca5f88a"
      },
      "source": [
        "# Open the handle\n",
        "json_file = open('{}/{}.model.json'.format(output_dir, model_name), 'r')\n",
        "\n",
        "# load json and create model\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights('{}/{}.model.h5'.format(output_dir, model_name))\n",
        "print(\"Loaded model from disk\")\n",
        "# loaded_model_json"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nE3Nx-TvvuH4",
        "outputId": "b4e4f785-2583-4a59-a053-799ef54672dc"
      },
      "source": [
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', \n",
        "                     metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.26539793610572815\n",
            "Test accuracy: 0.9537777900695801\n",
            "accuracy: 95.38%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TotWnrs86sVp"
      },
      "source": [
        ""
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qYKC2dX6tDe"
      },
      "source": [
        "# ConvNN(RF) - top 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pbow5tSi6tDe"
      },
      "source": [
        "## Train/Test split    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUecTn5M6tDf"
      },
      "source": [
        "# from keras.utils import to_categorical\n",
        "# outcome = encode(outcome['Project_id'])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "kxaEe6UK6tDg",
        "outputId": "76da9d68-cfdd-4632-b048-12f3e2503042"
      },
      "source": [
        "#feature_sort_selected = feature_sort[feature_sort['importance'] > 0.0005]\n",
        "feature_sort_selected = feature_sort.iloc[:500,:]\n",
        "feature_sort_selected"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3300</th>\n",
              "      <td>MOGAT3</td>\n",
              "      <td>0.003089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57644</th>\n",
              "      <td>FP671120.6</td>\n",
              "      <td>0.002802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12189</th>\n",
              "      <td>KLK4</td>\n",
              "      <td>0.002783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1448</th>\n",
              "      <td>CDH17</td>\n",
              "      <td>0.002782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17545</th>\n",
              "      <td>KLHL14</td>\n",
              "      <td>0.002726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15801</th>\n",
              "      <td>RPL7P26</td>\n",
              "      <td>0.000527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4737</th>\n",
              "      <td>LPPR5</td>\n",
              "      <td>0.000527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>PRSS22</td>\n",
              "      <td>0.000527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16085</th>\n",
              "      <td>SRL</td>\n",
              "      <td>0.000527</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12191</th>\n",
              "      <td>KLK5</td>\n",
              "      <td>0.000527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             name  importance\n",
              "3300       MOGAT3    0.003089\n",
              "57644  FP671120.6    0.002802\n",
              "12189        KLK4    0.002783\n",
              "1448        CDH17    0.002782\n",
              "17545      KLHL14    0.002726\n",
              "...           ...         ...\n",
              "15801     RPL7P26    0.000527\n",
              "4737        LPPR5    0.000527\n",
              "72         PRSS22    0.000527\n",
              "16085         SRL    0.000527\n",
              "12191        KLK5    0.000527\n",
              "\n",
              "[500 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mju0x7ig6tDg"
      },
      "source": [
        "TC1data15_selected = TC1data15.loc[:,feature_sort_selected['name']]"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6yffhkU6tDg"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(TC1data15_selected, \n",
        "                                                    outcome, \n",
        "                                                    train_size=0.75, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=123, \n",
        "                                                    stratify = outcome)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Sxjv7l636tDh",
        "outputId": "e573c20b-9739-47f9-d538-f2dccbdc415c"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MOGAT3</th>\n",
              "      <th>FP671120.6</th>\n",
              "      <th>KLK4</th>\n",
              "      <th>CDH17</th>\n",
              "      <th>KLHL14</th>\n",
              "      <th>NAPSA</th>\n",
              "      <th>VTN</th>\n",
              "      <th>SFTPB</th>\n",
              "      <th>RDH11</th>\n",
              "      <th>RP11-452C8.1</th>\n",
              "      <th>SOX17</th>\n",
              "      <th>SFTPA1</th>\n",
              "      <th>CRYGN</th>\n",
              "      <th>RP11-53M11.5</th>\n",
              "      <th>FP671120.4</th>\n",
              "      <th>AP001187.9</th>\n",
              "      <th>KLK2</th>\n",
              "      <th>F13B</th>\n",
              "      <th>S1PR5</th>\n",
              "      <th>HRG</th>\n",
              "      <th>KLK3</th>\n",
              "      <th>ITIH2</th>\n",
              "      <th>TRPS1</th>\n",
              "      <th>RP5-1021I20.2</th>\n",
              "      <th>ACSM2B</th>\n",
              "      <th>UGT2B4</th>\n",
              "      <th>PRODH2</th>\n",
              "      <th>FEV</th>\n",
              "      <th>MASP2</th>\n",
              "      <th>SFTPC</th>\n",
              "      <th>FP236383.4</th>\n",
              "      <th>KCNJ10</th>\n",
              "      <th>PRAC2</th>\n",
              "      <th>GRHL2</th>\n",
              "      <th>SFTA3</th>\n",
              "      <th>SLC28A1</th>\n",
              "      <th>NXPE1</th>\n",
              "      <th>LINC00483</th>\n",
              "      <th>CHRNA2</th>\n",
              "      <th>SFTPA2</th>\n",
              "      <th>...</th>\n",
              "      <th>SPDEF</th>\n",
              "      <th>ARL14</th>\n",
              "      <th>ROS1</th>\n",
              "      <th>RP11-14C10.5</th>\n",
              "      <th>NPNT</th>\n",
              "      <th>HEPHL1</th>\n",
              "      <th>DSC3</th>\n",
              "      <th>SLC37A4</th>\n",
              "      <th>CTC-470C15.1</th>\n",
              "      <th>TINAG</th>\n",
              "      <th>RP11-761N21.2</th>\n",
              "      <th>RFPL2</th>\n",
              "      <th>CDC25C</th>\n",
              "      <th>MEIS1</th>\n",
              "      <th>PTPRZ1</th>\n",
              "      <th>AC019129.2</th>\n",
              "      <th>TNS4</th>\n",
              "      <th>DUOXA1</th>\n",
              "      <th>FTH1P10</th>\n",
              "      <th>PLIN2</th>\n",
              "      <th>WDR86</th>\n",
              "      <th>LINC01428</th>\n",
              "      <th>AC021218.2</th>\n",
              "      <th>RP11-363E7.4</th>\n",
              "      <th>SLC9A1</th>\n",
              "      <th>GRIK3</th>\n",
              "      <th>AC002539.1</th>\n",
              "      <th>AXIN2</th>\n",
              "      <th>HNF1A-AS1</th>\n",
              "      <th>MLF1</th>\n",
              "      <th>RGAG4</th>\n",
              "      <th>MSMB</th>\n",
              "      <th>OR51C1P</th>\n",
              "      <th>SCGB1D2</th>\n",
              "      <th>GALNT12</th>\n",
              "      <th>RPL7P26</th>\n",
              "      <th>LPPR5</th>\n",
              "      <th>PRSS22</th>\n",
              "      <th>SRL</th>\n",
              "      <th>KLK5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.808450</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.672119</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.346068</td>\n",
              "      <td>1.155254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.424186</td>\n",
              "      <td>3.167719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.465801</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094042</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022084</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.362394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.636991</td>\n",
              "      <td>2.317114</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.142535</td>\n",
              "      <td>...</td>\n",
              "      <td>1.850602</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.841232</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.957821</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.304914</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.672750</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.023847</td>\n",
              "      <td>0.571990</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.247294</td>\n",
              "      <td>1.391259</td>\n",
              "      <td>0.090604</td>\n",
              "      <td>1.135320</td>\n",
              "      <td>0.107780</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.132814</td>\n",
              "      <td>1.475548</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.106125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.104966</td>\n",
              "      <td>0.554460</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.838268</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.160419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.465524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257574</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.773058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.566138</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.110626</td>\n",
              "      <td>1.734314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137554</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.840252</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.976508</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.323714</td>\n",
              "      <td>1.220133</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.197140</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.318770</td>\n",
              "      <td>0.473386</td>\n",
              "      <td>0.270057</td>\n",
              "      <td>0.738661</td>\n",
              "      <td>0.412671</td>\n",
              "      <td>0.124101</td>\n",
              "      <td>0.324407</td>\n",
              "      <td>1.906754</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.601587</td>\n",
              "      <td>1.412625</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.830541</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.760403</td>\n",
              "      <td>0.128463</td>\n",
              "      <td>0.434593</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.348407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.906062</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157242</td>\n",
              "      <td>0.601505</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.690877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.297473</td>\n",
              "      <td>1.752160</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041478</td>\n",
              "      <td>0.576785</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.296192</td>\n",
              "      <td>0.444143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.557529</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.834996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.713397</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.790730</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074018</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.153278</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.326644</td>\n",
              "      <td>1.080129</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.219640</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.890011</td>\n",
              "      <td>0.793214</td>\n",
              "      <td>1.808597</td>\n",
              "      <td>0.541247</td>\n",
              "      <td>1.896981</td>\n",
              "      <td>1.401323</td>\n",
              "      <td>0.419719</td>\n",
              "      <td>0.604985</td>\n",
              "      <td>0.157672</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.999394</td>\n",
              "      <td>1.656942</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.586131</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.853027</td>\n",
              "      <td>0.743807</td>\n",
              "      <td>0.031125</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.731726</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.741219</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4447</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.192705</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.284720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.596492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.039429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.153790</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.084699</td>\n",
              "      <td>0.254706</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.178859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.158807</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.676008</td>\n",
              "      <td>0.714604</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.683316</td>\n",
              "      <td>2.344126</td>\n",
              "      <td>1.128113</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.863149</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.056761</td>\n",
              "      <td>1.827997</td>\n",
              "      <td>1.542713</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.524409</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.120357</td>\n",
              "      <td>0.032112</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.842974</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.891055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.948668</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.531098</td>\n",
              "      <td>0.094371</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.352760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.316836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.133977</td>\n",
              "      <td>2.396390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.550796</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.164986</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818311</td>\n",
              "      <td>1.543859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.420519</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.968613</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.233796</td>\n",
              "      <td>1.288215</td>\n",
              "      <td>0.271269</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.544402</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.250054</td>\n",
              "      <td>1.494002</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.251137</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.016395</td>\n",
              "      <td>1.372335</td>\n",
              "      <td>0.220725</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.910802</td>\n",
              "      <td>1.580645</td>\n",
              "      <td>1.080386</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.167842</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.778927</td>\n",
              "      <td>0.762819</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.300788</td>\n",
              "      <td>0.740629</td>\n",
              "      <td>0.084183</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.487913</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.921961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3495</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.671380</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.636459</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.288064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018219</td>\n",
              "      <td>1.585684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.088985</td>\n",
              "      <td>...</td>\n",
              "      <td>1.657988</td>\n",
              "      <td>1.133783</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.161516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.393936</td>\n",
              "      <td>1.143364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.934394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.006088</td>\n",
              "      <td>1.107061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.765419</td>\n",
              "      <td>1.067214</td>\n",
              "      <td>0.510754</td>\n",
              "      <td>1.458602</td>\n",
              "      <td>0.115464</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.822089</td>\n",
              "      <td>1.950666</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.747025</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.499931</td>\n",
              "      <td>0.629204</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.844691</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.848514</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>1.163849</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.163344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.669915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.229859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.438474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.735723</td>\n",
              "      <td>1.644623</td>\n",
              "      <td>1.537464</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.596512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.849123</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.670994</td>\n",
              "      <td>1.463066</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.813827</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.765983</td>\n",
              "      <td>0.448613</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.555550</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.750500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.088283</td>\n",
              "      <td>1.287644</td>\n",
              "      <td>1.057335</td>\n",
              "      <td>1.381218</td>\n",
              "      <td>1.099924</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.327483</td>\n",
              "      <td>0.956783</td>\n",
              "      <td>1.124473</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.764976</td>\n",
              "      <td>1.111838</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.294822</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018204</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.148528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.766090</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.383600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.399102</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.593394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.320577</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.065513</td>\n",
              "      <td>1.582818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.096577</td>\n",
              "      <td>0.194891</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.767820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.422091</td>\n",
              "      <td>1.051456</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.485312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.688254</td>\n",
              "      <td>1.308324</td>\n",
              "      <td>1.003360</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.456734</td>\n",
              "      <td>1.417407</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.779278</td>\n",
              "      <td>0.600311</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.150752</td>\n",
              "      <td>1.904368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.891907</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.640625</td>\n",
              "      <td>1.050524</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.982674</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.138535</td>\n",
              "      <td>1.627720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.809242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1573</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.657723</td>\n",
              "      <td>0.152280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.482651</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.282959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.991760</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.281678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.905957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.080228</td>\n",
              "      <td>0.038048</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.998927</td>\n",
              "      <td>0.121004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.334463</td>\n",
              "      <td>0.399217</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.921382</td>\n",
              "      <td>1.826872</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.871228</td>\n",
              "      <td>1.231665</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222892</td>\n",
              "      <td>1.334027</td>\n",
              "      <td>1.308839</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.458679</td>\n",
              "      <td>1.689267</td>\n",
              "      <td>0.423942</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.098331</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.498894</td>\n",
              "      <td>0.985193</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.246892</td>\n",
              "      <td>1.020823</td>\n",
              "      <td>0.050762</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.944441</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.093077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3192</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.369517</td>\n",
              "      <td>0.455298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.917144</td>\n",
              "      <td>1.889821</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.852791</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.617423</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.643908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.725373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.392420</td>\n",
              "      <td>2.243345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.233160</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.725055</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.288389</td>\n",
              "      <td>1.168501</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.727701</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037470</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.236317</td>\n",
              "      <td>2.145005</td>\n",
              "      <td>0.003031</td>\n",
              "      <td>1.248641</td>\n",
              "      <td>1.759473</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.394155</td>\n",
              "      <td>1.603180</td>\n",
              "      <td>0.273632</td>\n",
              "      <td>0.76379</td>\n",
              "      <td>0.776618</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.210722</td>\n",
              "      <td>1.799542</td>\n",
              "      <td>0.442276</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.742171</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.473435</td>\n",
              "      <td>1.458299</td>\n",
              "      <td>0.174247</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3375 rows × 500 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        MOGAT3  FP671120.6      KLK4  ...    PRSS22       SRL      KLK5\n",
              "849   0.000000    0.000000  0.000000  ...  1.160419  0.000000  0.000000\n",
              "1050  0.000000    0.000000  0.000000  ...  0.906062  0.000000  0.000000\n",
              "835   0.000000    0.157242  0.601505  ...  1.741219  0.000000  0.000000\n",
              "4447  0.000000    0.000000  0.000000  ...  1.891055  0.000000  0.000000\n",
              "53    0.000000    1.948668  0.000000  ...  1.487913  0.000000  1.921961\n",
              "...        ...         ...       ...  ...       ...       ...       ...\n",
              "3495  0.000000    0.000000  0.000000  ...  1.848514  0.000000  0.000000\n",
              "1737  1.163849    0.000000  0.000000  ...  0.000000  0.018204  0.000000\n",
              "2943  0.000000    0.000000  0.000000  ...  1.627720  0.000000  1.809242\n",
              "1573  0.000000    0.000000  0.000000  ...  1.944441  0.000000  1.093077\n",
              "3192  0.000000    0.000000  0.000000  ...  1.473435  1.458299  0.174247\n",
              "\n",
              "[3375 rows x 500 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPz4mZIT6tDh"
      },
      "source": [
        "## CONV1D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVioxP5B6tDh"
      },
      "source": [
        "# parameters  \n",
        "activation='relu'\n",
        "batch_size=20\n",
        "# Number of sites\n",
        "classes=15\n",
        "drop = 0.1\n",
        "feature_subsample = 0\n",
        "loss='categorical_crossentropy'\n",
        "# metrics='accuracy'\n",
        "out_act='softmax'\n",
        "pool=[1, 10]\n",
        "# optimizer='sgd'\n",
        "shuffle = False \n",
        "epochs=30\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.1)\n",
        "metrics = ['acc']"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlf3PDbs6tDi"
      },
      "source": [
        "x_train_len = X_train.shape[1]   \n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "filters = 128 \n",
        "filter_len = 20 \n",
        "stride = 1 \n",
        "\n",
        "# inside pool_list loop\n",
        "pool_list = [1,10]\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LkBfPFt6tDi",
        "outputId": "0d5f05ef-b34d-43e5-d61c-bcd426bcb481"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add  CONV1D\n",
        "model.add(Conv1D(filters = filters, \n",
        "                 kernel_size = filter_len, \n",
        "                 strides = stride, \n",
        "                 padding='valid', \n",
        "                 input_shape=(x_train_len, 1)))\n",
        "\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 1))\n",
        "\n",
        "filters = 128\n",
        "filter_len = 10 \n",
        "stride = 1 \n",
        "# Conv1D\n",
        "model.add(Conv1D(filters=filters, \n",
        "                 kernel_size=filter_len, \n",
        "                 strides=stride, \n",
        "                 padding='valid'))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 10))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200))\n",
        "\n",
        "# activation \n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(20))\n",
        "# activation\n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(15))\n",
        "model.add(Activation(out_act))\n",
        "\n",
        "model.compile( loss= loss, \n",
        "              optimizer = optimizer, \n",
        "              metrics = metrics )\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 481, 128)          2688      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 481, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 481, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 472, 128)          163968    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 472, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 47, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6016)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               1203400   \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                4020      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                315       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 1,374,391\n",
            "Trainable params: 1,374,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuVv6btS6tDi"
      },
      "source": [
        "# save\n",
        "# save = '/content/drive/My Drive/FNL_TC1/'\n",
        "output_dir = \"/content/drive/My Drive/FNL_TC1/Model\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "model_name = 'tc1_rf'\n",
        "path = '{}/{}.autosave.model.h5'.format(output_dir, model_name)\n",
        "checkpointer = ModelCheckpoint(filepath=path,\n",
        "                               verbose=1,\n",
        "                               save_weights_only=True,\n",
        "                               save_best_only=True)\n",
        "\n",
        "csv_logger = CSVLogger('{}/training.log'.format(output_dir))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfBGZeDN6tDi"
      },
      "source": [
        "# SR: change epsilon to min_delta\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                              factor=0.1, \n",
        "                              patience=10, \n",
        "                              verbose=1, mode='auto', \n",
        "                              min_delta=0.0001, \n",
        "                              cooldown=0, \n",
        "                              min_lr=0)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3PnJuAa6tDj",
        "outputId": "bc11c10a-8f9b-48b4-cb2d-bb793c64882f"
      },
      "source": [
        "# batch_size = 20 \n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, \n",
        "                    epochs=epochs, verbose=1, validation_data=(X_test, Y_test), \n",
        "                    callbacks = [checkpointer, csv_logger, reduce_lr])\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "169/169 [==============================] - 21s 123ms/step - loss: 1.7351 - acc: 0.4400 - val_loss: 0.2329 - val_acc: 0.9440\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.23293, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 2/30\n",
            "169/169 [==============================] - 20s 119ms/step - loss: 0.2892 - acc: 0.9048 - val_loss: 0.1635 - val_acc: 0.9502\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.23293 to 0.16347, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 3/30\n",
            "169/169 [==============================] - 20s 121ms/step - loss: 0.1553 - acc: 0.9519 - val_loss: 0.1595 - val_acc: 0.9538\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.16347 to 0.15953, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 4/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.1240 - acc: 0.9606 - val_loss: 0.1366 - val_acc: 0.9609\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.15953 to 0.13657, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 5/30\n",
            "169/169 [==============================] - 20s 119ms/step - loss: 0.1185 - acc: 0.9683 - val_loss: 0.1381 - val_acc: 0.9636\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.13657\n",
            "Epoch 6/30\n",
            "169/169 [==============================] - 21s 122ms/step - loss: 0.0661 - acc: 0.9798 - val_loss: 0.1394 - val_acc: 0.9636\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.13657\n",
            "Epoch 7/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0616 - acc: 0.9818 - val_loss: 0.1540 - val_acc: 0.9591\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.13657\n",
            "Epoch 8/30\n",
            "169/169 [==============================] - 20s 119ms/step - loss: 0.0588 - acc: 0.9839 - val_loss: 0.1397 - val_acc: 0.9636\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.13657\n",
            "Epoch 9/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0551 - acc: 0.9850 - val_loss: 0.1470 - val_acc: 0.9671\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.13657\n",
            "Epoch 10/30\n",
            "169/169 [==============================] - 20s 118ms/step - loss: 0.0383 - acc: 0.9893 - val_loss: 0.1509 - val_acc: 0.9636\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.13657\n",
            "Epoch 11/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0459 - acc: 0.9836 - val_loss: 0.1554 - val_acc: 0.9618\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.13657\n",
            "Epoch 12/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0433 - acc: 0.9854 - val_loss: 0.3104 - val_acc: 0.9289\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.13657\n",
            "Epoch 13/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0532 - acc: 0.9812 - val_loss: 0.2054 - val_acc: 0.9573\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.13657\n",
            "Epoch 14/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0319 - acc: 0.9928 - val_loss: 0.1730 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.13657\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 15/30\n",
            "169/169 [==============================] - 21s 122ms/step - loss: 0.0132 - acc: 0.9967 - val_loss: 0.1651 - val_acc: 0.9680\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.13657\n",
            "Epoch 16/30\n",
            "169/169 [==============================] - 20s 121ms/step - loss: 0.0139 - acc: 0.9950 - val_loss: 0.1648 - val_acc: 0.9671\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.13657\n",
            "Epoch 17/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0118 - acc: 0.9966 - val_loss: 0.1653 - val_acc: 0.9698\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.13657\n",
            "Epoch 18/30\n",
            "169/169 [==============================] - 21s 122ms/step - loss: 0.0129 - acc: 0.9961 - val_loss: 0.1686 - val_acc: 0.9680\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.13657\n",
            "Epoch 19/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0111 - acc: 0.9967 - val_loss: 0.1676 - val_acc: 0.9707\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.13657\n",
            "Epoch 20/30\n",
            "169/169 [==============================] - 20s 121ms/step - loss: 0.0089 - acc: 0.9974 - val_loss: 0.1725 - val_acc: 0.9707\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.13657\n",
            "Epoch 21/30\n",
            "169/169 [==============================] - 21s 122ms/step - loss: 0.0110 - acc: 0.9973 - val_loss: 0.1762 - val_acc: 0.9716\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.13657\n",
            "Epoch 22/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0088 - acc: 0.9963 - val_loss: 0.1795 - val_acc: 0.9707\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.13657\n",
            "Epoch 23/30\n",
            "169/169 [==============================] - 20s 119ms/step - loss: 0.0060 - acc: 0.9992 - val_loss: 0.1817 - val_acc: 0.9707\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.13657\n",
            "Epoch 24/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0100 - acc: 0.9959 - val_loss: 0.1817 - val_acc: 0.9724\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.13657\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 25/30\n",
            "169/169 [==============================] - 20s 119ms/step - loss: 0.0057 - acc: 0.9991 - val_loss: 0.1818 - val_acc: 0.9733\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.13657\n",
            "Epoch 26/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0059 - acc: 0.9981 - val_loss: 0.1816 - val_acc: 0.9724\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.13657\n",
            "Epoch 27/30\n",
            "169/169 [==============================] - 21s 122ms/step - loss: 0.0055 - acc: 0.9992 - val_loss: 0.1812 - val_acc: 0.9716\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.13657\n",
            "Epoch 28/30\n",
            "169/169 [==============================] - 20s 120ms/step - loss: 0.0106 - acc: 0.9987 - val_loss: 0.1806 - val_acc: 0.9724\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.13657\n",
            "Epoch 29/30\n",
            "169/169 [==============================] - 20s 119ms/step - loss: 0.0062 - acc: 0.9991 - val_loss: 0.1806 - val_acc: 0.9724\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.13657\n",
            "Epoch 30/30\n",
            "169/169 [==============================] - 24s 142ms/step - loss: 0.0100 - acc: 0.9968 - val_loss: 0.1806 - val_acc: 0.9724\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.13657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPJK06xF6tDj",
        "outputId": "9fa85006-47f5-4c4e-d706-45a9b68eb0a3"
      },
      "source": [
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.18058907985687256\n",
            "Test accuracy: 0.9724444150924683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "2m67fTHc6tDj",
        "outputId": "fa59728e-70e2-4b5f-9b4f-90e0a615c79b"
      },
      "source": [
        "plt.plot(history.history['acc'],label=\"accuracy\")\n",
        "plt.plot(history.history['val_acc'],label=\"val_accuracy\")\n",
        "plt.plot(history.history['loss'],label=\"loss\")\n",
        "plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"FR Feature Selection\")\n",
        "plt.xlabel('epoch')\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEWCAYAAACZnQc8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8ddn1qwzWdkDARVxYVNE1K/iWhUXrIqoaF2q/lpb19ZKbbV8lbbWtra1tS7t1621VcTq168gtCqKiorsKCAqQghrErJvs53fH3dmmIQsE0iYzOTzfHAfd517z82Qd86ce+dcMcaglFIqNdgSXQCllFLdR0NdKaVSiIa6UkqlEA11pZRKIRrqSimVQjTUlVIqhWioK3UQicg7InJDD+z3DRG5prv3q5KPhrrqlIhsFpFGEamLGQaJSLGImJhlm0VkZif7MiJSH/Oaqm4onxGRQw90P1043hAReVlEykWkWkQ+FZFrD+LxZ4nI32OXGWPONcY8e7DKoHovR6ILoJLGBcaYN2MXiEhxeDLHGBMQkQnAuyKy3Bjznw72NdYY82UPlbPLRMRujAl24SV/A1YDw4BmYDQwoCfKplRXaU1ddRtjzDLgM2BcV18brvm/LCJlIvK1iNwas26iiHwoIlUiskNE/iQirvC6xeHNVodr/tNF5FoReb/V/qO1eRF5RkQeE5H5IlIPnNbR8dtwHPCMMabeGBMwxqw0xrwRc6xJIrIkXN7VInJqB+d9vYisF5FKEVkoIsNi1h0lIv8RkT0isktE7hGRc4B7gOnh810d3jbarCMiNhH5qYhsEZHdIvKciHjD6yKfrq4RkZLwp42fxPEWqSShoa66jYhMAo4GulQLFxEb8H9Ytd/BwBnA7SJydniTIHAHUACcEF5/M4Ax5pTwNmONMVnGmBfjPOyVwM+BbGBJJ8dv7SPgURG5XESGtjqXwcA8YDaQB/wQeFlECts476lYAX0xUAi8B/wzvC4beBNYAAwCDgXeMsYsAH4BvBg+37FtlO/a8HAaMALIAv7Uapv/Ag4Pn+t9InJEO+eqkoyGuorXq+GaZ5WIvNpqXbmINAIfAn8GWq9vbUXMvh7BqvkWGmPuN8b4jDGbgL8AlwMYY5YbYz4K14o3A08Akw/wfP7XGPOBMSaE1XzS7vHbMA0rgO8FvhaRVSJyXHjdVcB8Y8x8Y0wo3Ay1DJjSxn6+A/zSGLPeGBPACutx4dr6+cBOY8xvjTFNxphaY8zHcZ7bDOBhY8wmY0wd8GPgchGJbW79b2NMozFmNdYfs7b+OKgkpG3qKl4XtW5Tj1EAGOA2rBqwE/B1sK9jYtvUReQyYFCri6Z2rOBEREYCDwMTgAys/7fL9/M8IrbGTA/r6PitGWMqgZnATBEpAH6D9UdvSHhf00TkgpiXOIFFbexqGPAHEfltzDLB+rRQBHzVtVOKGgRsiZnfgvUz6x+zbGfMdANWbV6lAK2pq25hjAkaYx4Gmgg3jXTBVuBrY0xOzJBtjInUbh8DNgCHGWM8WE0W0sH+6rHCHwARaesiZmz3pJ0dv13GmHKsUB+E1dyyFfhbq31lGmMebOe8/1+rbdONMUvC60a0d9hOirUd6w9GxFAgAOzq7HxU8tNQV93tQeBHIpLWhdcsBWpF5G4RSRcRu4gcHdOkkQ3UAHUiMgr4bqvX76JlAK4GjhKRceFyzDrA47cgIr8Kr3eE276/C3xpjKkA/g5cICJnh/eTJiKnhmvxrT0O/FhEjgrv1ysi08LrXgcGisjtIuIWkWwROT7mfIvD1yLa8k/gDhEZLiJZ7G2DD3Tyc1ApQENddbd5QCVwY7wvCN9OeD7WXTNfA+XAXwFveJMfYjXr1GK1dbe+GDoLeDbcRn+ZMWYjcD/WhcYvgPfpQBzHby0DeAWoAjZh1YovDO9rKxC5AFqGVeO+izZ+14wxrwC/Al4QkRrgU+Dc8Lpa4CzgAqymki+wLnwCvBQeV4jIijbK9xTWbZeLw+fTBNzS0c9ApQ7Rh2QopVTq0Jq6UkqlEA11pZRKIRrqSimVQjTUlVIqhSTsy0cFBQWmuLg4UYdXSqmktHz58nJjzD7dTkQkLNSLi4tZtmxZog6vlFJJSUS2dLRem1+UUiqFaKgrpVQK0VBXSqkUoqGulFIpRENdKaVSiIa6UkqlEA11pZRKIUkX6it2reD3y39PyIQSXRSllOp1ki7UPy3/lP/59H+o89cluihKKdXrdBrqIvKUiOwWkU/bWS8i8oiIfCkia0TkmO4v5l5et/Xcgprmmp48jFJKJaV4aurPAOd0sP5c4LDwcBPW8yR7TCTUq33VPXkYpZRKSp32/WKMWSwixR1sMhV4zliPUPpIRHJEZKAxZkc3lbEFj8sDQHWzhro6cMGQwW7r6BnW8fEHQzQ0B2nwB/AHDHa74LAJdps1dthtLeZF9u+YxhgCIUMgaAiEQgRD1nwwZPAHrfmusIlgswl2EWw2sItVRgmPI8tDIaLH8wdN+Lj7Hh8g3Wkn3WUn3WknzWnH7bDFfb7+YIhGf5Amf5AmnzUd2W/nPxsIGUPQGELhMlnT+y437D1Xm02wCeFzDS+LOf9AKIQ/aJ2fNRgCwRC+mGl/MIQB0hx23E4bbocNd/jc01qN3Q47nnQHboe9S+9VvLqjQ6/BWM9hjCgNL9sn1EXkJqzaPEOHDt2vg2nzi+oKXyDE9qpGSvY0ULKnga3hcWS6pimA3SZt//LFzLvsNitwfFZwN/iCVoj7AuHg6WqYgsNmI95sN8YK1S5mdq8gYoXd3qC3gi0QCtHkD4e4L0ijP0ggGU9wPzxw0dFcPWlYj+z7oPbSaIx5EngSYMKECfv17kWbX7Sm3i0CwRAN/mDc2wtEazKR2oxN2O+aZ2eMMdFaUnMgRF1TgNpmP3VNAeqaraE2Mh0e1zT62V7dyNY9jeyobmwRhC67jSF56QzNy+DYYbnkZbrwB61waQ4EafaHaAqEaPYHo+OaRj/NgRAuu5DustMvO40Mlz08OEh32clw2slwO8hw2XHabYSiNdhQTM3Wmt9b0zZYdcZ4fu6C0763pm+32faZj3wS6MofipAxVi02RLQma83vXR4yJuY4ez95tFxmw2EXjDF7g9ofbBHYjf4gjb6QVQv3B3HabaQ5baS7rBp9emSInXfZu/TJxiZEP3m0qHHbrP+jkeVAzHnGTIdr95HzD4XAbhdc4U9aTocNp82G0yE47S2nAZoD1vk1h/8/NbUaR5ZPLM6L703aD90R6tuAopj5IeFlPSLa/KJt6gCEQoZ6nxVsNU1+a9xojasb/S2Gmjam633xB3pHbMLej+0xYb/3o33Mctvej7o2EUIhgy8YIhAO79jprtTc7DYhy+0gy+1goDeN44fnMSQvg6ExQ79sN7ZuaG5RqrfqjlB/Dfi+iLwAHA9U91R7OoDL7iLdkZ6yNXV/MERFnY+y2mbK6pqscWSoa6aizkdNU4DaJiuY65oDnX4kz3DZ8aY78aY78aQ7KcrLwJPmjC7LdMfftmdMuEYXbZ9sVcOLWb63Frh3HFkerQkZY9U6beGaj8Oq9bkcVk3UabeFB6u2lJ3mJCvNQbbbQVaaFeDWvJM0Z/xtt0qlqk5DXUT+CZwKFIhIKfAzwAlgjHkcmA9MAb4EGoDreqqwEV63t1eHeiAYYsPOWr7cXUdD+KNn5CNnY8xH0dj5yno/ZXXN7Kn3tblPT5qDwmw3+ZluBuek40nLxpPuJDvNgSctPG41HwnxyEdDpRIiFIJA097B3wiBZgj5IRSAUBCCkenwfCiwd70xYHO0HOyt5m12sDlbztud+74uMoit5TH2KUPM0BOyB0JGzzTBxHP3yxWdrDfA97qtRHHwury9qvmlrjnAypJKlm2uZPmWSlaWVLbZrGET9mkzjIyLCzI4bnguBVluCrPdFEbG2W4KstykOXvgSnnAB01V1i9YmgfcHuJukE1GoSA010BjlXXejVVWwERDIRIYzpbzkcHfCL568NVCc114ug6aa2Om6yDoA0caONOscWRoPe9wWz97X/j1zXXWPiL78YWP0VxrbRcXExOKwZjQig3LgBVgtA7LNoIxNgTjOnwQ/E0tQzzYdkWlTzvvYTju2z2y64Q9zu5AeN3ehN79sr2qkeVfl7F20zY2lOxgZ1kZ6aaJLGni8FzhomIbh+UKgzPB7bQu9EQuagnthKY7GzILIKMgPPZCmje+kA36oaEC6suhvsyabqiAxsqWARYdV1vT/oaW+xGbdcy0HEjPiRnHLHNmxoSTGxzp1tgZHkcCKyMf3FkH/sOOR2MlVG7eO1SVWD+LFuddbQV6nBcmu8zmAFeW9T7anVYIB5rCAdcI8XZr4cwEV6b1s3OFh6x+1s+2vf87bZWldTBHa60xQY1YIRxvbTkeYgv/X2jnD1ns/x27q1WZ2viDYnda+21RnmDLmnQw0P66FutjBhNq9Ue8rXKE53uiojNgTPfvMyxpQ31T1aaeO0AoBHU7oXILzeVfUbblcxp2fYWtegvepu3kmVouED8XRLZ3xby2PjyUdEM5bM6YoM+3xs50aNgDDeVWcDWUWyHdHld2y4DOP6RVYOdYv2BN1XsDMHa6unRvOIb88ZfdmQGTfwSTvgcOV+fbd8bXACVLwsG9JSbEt0Drprj0PCsI03LAMwj6HdHGH6rwHytXhvV+t/ilbyscgtbPKRK0saHrzgqHbgeC/nDNtXlv80OgKWaf4TC39cy9y6rvSMpQ97g8XW9+8TftW1ONrb3Wl2Eqt+Ar34SjpgR7yPrI6AYGGWEHeey2D6DcM5HM3H70yy+gID8fe1p2uGaVve8vuzON+GpXBppqwkFdER6X7Q3tyLLKLVYgZORbIT9w7L6hH1vbT8ux2h67gzHWsf2NVs2zRTg17htYG+bBm7Ng9Qtw3m+h+L/277gBH6x4Ft59COp3W8vsLsgZBrnFUHS8Nc4thtxh1vI0T/ecc3eyO63BnZ3okqgUl5ShHrlQaoxBgn6o3Q7V26xaZU2pNa4utZY1VITbjZs63Ge9ZLIl1I/NoUK2msMpcwzEVTCC/KKRDD9kFGOK+zE+q5Pa2IFI80JOUefbJYqIVat1ZcS3/fgZ8Pkb8MaP4JnzYMzl8I0HrBp0PEJBWPsSLPoFVG2BoSfCRX+GfkdaF5lsevFXqbYkX6hvXIh3wwL8IT+Nvx1FRt0u9mknzcgHz2Cr5jbk2H0/cqfnQFouq8oNv1m8iw+3Byku9HDiIQWMK8rhzKE5DM/P1PuZD9Th58LwyfDeb+GDP8DGN+CM++DY69pvZjAGPp8Pb8+G3etgwGiYMRcOPTO1L+Iq1U2SL9Rrd+Ct3Q3pUHPIf5GRe5gV4N4h1uAZ3GltclNZHQ++sYF/r9vFQG8av77scC4aN1hDvCe4MuCMe2HMdJj/A5j3A1j5d+vq/+BWHXp+/R689d9Q+gnkHQKXPgVHflNr5Up1QfKF+rHX4i0YAu/cQfXkHzEg7/C4X7qn3scf3tzI8x+X4HbYuOvsw7n+pOGku/TiVI8rHAnfeg0+fRkW3gN/Od26pev0e6Hya3jrfvjqbcgeBBf8AcbN2Hvng1IqbskX6nS9/5cmf5Bnlmzm0be/pMEf5IqJRdx2xkgKs3uwjVztSwRGXwqHnQVv/xw++QusmWPdapieB9+YDcfdYN3ho5TaL0kZ6vH2/xIKGf5vzXYeWvA526oaOfOIfsw8dxSH9tM7EBIqzQtTHoJxV8L7D0PhKDjh+73zrhWlkkxShno8NXVjDNc98wnvbizjqEEefn3pGE48tOBgFVHFY9A4uOy5RJdCqZSSsqG+o7qJdzeWcdMpI5h5zii9CKqU6hOS8raCNHsaLpurw+aXFSWVAJw/ZqAGulKqz0jKUBeRTvt/WVlShdthY9QAbadVSvUdSRnq0Hn3uytKKhkzxIvLkbSnqJRSXZa0iddR/y/NgSCfbath/NDcg1wqpZRKrOQNdben3eaXz7bX4AuGGF+Uc5BLpZRSiZW0od7RgzJWllQBcMwwrakrpfqW5A31DtrUV5ZUMsibRn9P2kEulVJKJVZSh3pjoBFfG4/KWllSxXitpSul+qDkDXWX9QWkGl/LdvVdNU1sq2rU9nSlVJ+UvKHezrdKV4a/dKTt6UqpvihpQ93jDnfqtU+oV+Gy2zhqkH7pSCnV9yRtqLdXU19RUslRgz24HdpHulKq70neUA+3qcfe1ugPhlhTWs34Im16UUr1Tckb6m3U1DfsqKU5EGL8UL1IqpTqm5I21LOcWdjF3iLUV+hFUqVUH5e0oS4ieFyeFrc0riyppF+2m0Fe/dKRUqpvStpQh32/VbqipIpjhuYiov2nK6X6pqQOdY/bEw318rpmSvY0aHu6UqpPS+pQj+3USzvxUkqpOENdRM4Rkc9F5EsRmdnG+qEiskhEVorIGhGZ0v1F3Vds88vKkkocNmH0YO/BOLRSSvVKnYa6iNiBR4FzgSOBK0TkyFab/RSYY4wZD1wO/Lm7C9qW2EfarSyp4shBHtKc+qUjpVTfFU9NfSLwpTFmkzHGB7wATG21jQEi38v3Atu7r4jt87q81PprafL7WF1apZ14KaX6vHhCfTCwNWa+NLws1izgKhEpBeYDt7S1IxG5SUSWiciysrKy/ShuS5H+X1Zt20mDL6iPr1NK9XnddaH0CuAZY8wQYArwNxHZZ9/GmCeNMROMMRMKCwsP+KCRb5UuLSkF4BgNdaVUHxdPqG8DimLmh4SXxfo2MAfAGPMhkAYUdEcBOxLp/2X19h3kZ7ooykvv6UMqpVSvFk+ofwIcJiLDRcSFdSH0tVbblABnAIjIEVihfuDtK52I1NQ37N7JeP3SkVJKdR7qxpgA8H1gIbAe6y6Xz0TkfhG5MLzZD4AbRWQ18E/gWmOM6alCR0RCfVddpX7pSCmlAEc8Gxlj5mNdAI1ddl/M9DrgpO4tWuc8LutCqdgbtD1dKaVI8m+UZruyAbDZGxkzRL90pJRSSR3qDpsDm0knzxMg0x3Xhw6llEppSR3qoZAhFEgnJyuQ6KIopVSvkNSh/mVZHcFAOunu5kQXRSmleoWkDvUVWyoxwQxsjsZEF0UppXqFpA71lSVVOCWTplBtoouilFK9QnKH+tZKCjJyoj01KqVUX5e0oV7T5OeL3XUM9hRQ7asmZEKJLpJSSiVc0ob66q1VGAOH5BcSMiHq/fWJLpJSSiVc0ob6ii1ViMCofv0BWjyAWiml+qqkDfWVWysZ2S+b/pl5ANFnlSqlVF+WlKEeChlWllQxfmhOtFMvrakrpVScHXr1Nl9X1FPd6A+Huh9A74BRSimSNNRXbKkErCcdecPfJtWaulJKJWmor9xaRXaag0MKswgYN6Bt6kopBcka6iVVjCvKwWYTXLhId6RrTV0ppUjCC6V1zQE+31nD+JiHYnjdXg11pZQiCUN9TWkVIQPHxDy+zuvyavOLUkqRhM0vK0uqABhf1LKmrne/KHVg/H4/paWlNDU1JbooCkhLS2PIkCE4nc4uvS7pQv2yCUUcOdCDN2PviXrdXjZVbUpgqZRKfqWlpWRnZ1NcXIyIJLo4fZoxhoqKCkpLSxk+fHiXXpt0zS+F2W5OG9WvxTKPy6PNL0odoKamJvLz8zXQewERIT8/f78+NSVdqLfF4/ZQ3VyNMSbRRVEqqWmg9x77+16kRKh7XV78IT+NAX0CklKqb0uNUA/3/1Lj04ulSqm+LaVCXe9VV0rFIxAIJLoIPSbp7n5pi9elNXWlutN//99nrNvevb9PRw7y8LMLjup0u4suuoitW7fS1NTEbbfdxk033cSCBQu45557CAaDFBQU8NZbb1FXV8ctt9zCsmXLEBF+9rOfcckll5CVlUVdXR0Ac+fO5fXXX+eZZ57h2muvJS0tjZUrV3LSSSdx+eWXc9ttt9HU1ER6ejpPP/00hx9+OMFgkLvvvpsFCxZgs9m48cYbOeqoo3jkkUd49dVXAfjPf/7Dn//8Z1555ZVu/Rl1h9QIda2pK5UynnrqKfLy8mhsbOS4445j6tSp3HjjjSxevJjhw4ezZ88eAB544AG8Xi9r164FoLKystN9l5aWsmTJEux2OzU1Nbz33ns4HA7efPNN7rnnHl5++WWefPJJNm/ezKpVq3A4HOzZs4fc3FxuvvlmysrKKCws5Omnn+b666/v0Z/D/tJQV0rtI54adU955JFHojXgrVu38uSTT3LKKadE79fOy7MejPPmm2/ywgsvRF+Xm5u7785amTZtGna7HYDq6mquueYavvjiC0QEv98f3e93vvMdHA5Hi+NdffXV/P3vf+e6667jww8/5LnnnuumM+5eKRHqHpcH0J4alUp277zzDm+++SYffvghGRkZnHrqqYwbN44NGzbEvY/YWwFb3+edmZkZnb733ns57bTTeOWVV9i8eTOnnnpqh/u97rrruOCCC0hLS2PatGnR0O9tUuJCabojHafNqTV1pZJcdXU1ubm5ZGRksGHDBj766COamppYvHgxX3/9NUC0+eWss87i0Ucfjb420vzSv39/1q9fTygU6rDNu7q6msGDBwPwzDPPRJefddZZPPHEE9GLqZHjDRo0iEGDBjF79myuu+667jvpbhZXqIvIOSLyuYh8KSIz29nmMhFZJyKficg/ureYnZZPe2pUKgWcc845BAIBjjjiCGbOnMmkSZMoLCzkySef5OKLL2bs2LFMnz4dgJ/+9KdUVlZy9NFHM3bsWBYtWgTAgw8+yPnnn8+JJ57IwIED2z3Wj370I3784x8zfvz4FnfD3HDDDQwdOpQxY8YwduxY/vGPvXE2Y8YMioqKOOKII3roJ3DgpLNvYYqIHdgInAWUAp8AVxhj1sVscxgwBzjdGFMpIv2MMbs72u+ECRPMsmXLDrT8URe9ehEjckbw8KkPd9s+lepL1q9f36vDqjf4/ve/z/jx4/n2t799UI7X1nsiIsuNMRPae008NfWJwJfGmE3GGB/wAjC11TY3Ao8aYyoBOgv0nqA1daVUTzr22GNZs2YNV111VaKL0qF4WvoHA1tj5kuB41ttMxJARD4A7MAsY8yC1jsSkZuAmwCGDh26P+Vtl8ftYUfdjm7dp1JKRSxfvjzRRYhLd10odQCHAacCVwB/EZGc1hsZY540xkwwxkwoLCzspkNb9EEZSikVX6hvA4pi5oeEl8UqBV4zxviNMV9jtcEf1j1FjI82vyilVHyh/glwmIgMFxEXcDnwWqttXsWqpSMiBVjNMQf1qRVet5fGQCO+oO9gHlYppXqVTkPdGBMAvg8sBNYDc4wxn4nI/SJyYXizhUCFiKwDFgF3GWMqeqrQbdH+X5RSKs5vlBpj5gPzWy27L2baAHeGh4SI7SqgIL0gUcVQSh0ksR13qb1S4hulYN39Atr/i1Lq4Opt3fj2zs4L9oN26qVUN3pjJuxc2737HDAazn2w3dUzZ86kqKiI733vewDMmjULh8PBokWLqKysxO/3M3v2bKZObf01mX3V1dUxderUNl/33HPP8Zvf/AYRYcyYMfztb39j165dfOc732HTJutS4GOPPcagQYM4//zz+fTTTwH4zW9+Q11dHbNmzYr2SfP+++9zxRVXMHLkSGbPno3P5yM/P5/nn3+e/v37t9k9cHV1NWvWrOH3v/89AH/5y19Yt24dv/vd7w7oxxuROqEeblPX2xqVSk7Tp0/n9ttvj4b6nDlzWLhwIbfeeisej4fy8nImTZrEhRde2OnzO9PS0njllVf2ed26deuYPXs2S5YsoaCgINqvy6233srkyZN55ZVXCAaD1NXVddqVr8/nI/Kt+MrKSj766CNEhL/+9a889NBD/Pa3v22ze2Cn08nPf/5zfv3rX+N0Onn66ad54oknDvTHF5U6oa41daW6Twc16p4yfvx4du/ezfbt2ykrKyM3N5cBAwZwxx13sHjxYmw2G9u2bWPXrl0MGDCgw30ZY7jnnnv2ed3bb7/NtGnTKCiwrrtFutV9++23o13p2u12vF5vp6Ee6YMGrH7ap0+fzo4dO/D5fNFugtvrHvj000/n9ddf54gjjsDv9zN69Ogu/rTalzKhnuXMwi52DXWlkti0adOYO3cuO3fuZPr06Tz//POUlZWxfPlynE4nxcXF+3Sn25b9fV0sh8NBKBSKznfUje8tt9zCnXfeyYUXXsg777zDrFmzOtz3DTfcwC9+8QtGjRrV7T0+psyFUhEh25WttzQqlcSmT5/OCy+8wNy5c5k2bRrV1dX069cPp9PJokWL2LJlS1z7ae91p59+Oi+99BIVFdYd15HmlzPOOIPHHnsMgGAwSHV1Nf3792f37t1UVFTQ3NzM66+/3uHxIt34Pvvss9Hl7XUPfPzxx7N161b+8Y9/cMUVV8T744lLyoQ66LdKlUp2Rx11FLW1tQwePJiBAwcyY8YMli1bxujRo3nuuecYNWpUXPtp73VHHXUUP/nJT5g8eTJjx47lzjutu7D/8Ic/sGjRIkaPHs2xxx7LunXrcDqd3HfffUycOJGzzjqrw2PPmjWLadOmceyxx0abdqD97oEBLrvsMk466aS4ntjUFZ12vdtTurvrXYAZ82aQ5criibO676KDUn2Fdr17cJ1//vnccccdnHHGGe1u01Nd7yYNj9ujNXWlVK9WVVXFyJEjSU9P7zDQ91fKXCgFq/llc/XmRBdDKXWQrF27lquvvrrFMrfbzccff5ygEnUuJyeHjRs39tj+UyvUtftdpfqU0aNHs2rVqkQXo1dJqeYXr9tLra+WYCiY6KIopVRCpFyoA9T6ahNcEqWUSoyUCnWPK9yplzbBKKX6qJQKde0qQKnklpWVlegiJD0NdaWUSiGpFeraU6NSKcEYw1133cXRRx/N6NGjefHFFwHYsWMHp5xyCuPGjePoo4/mvffeIxgMcu2110a37a4ubJNVat3SqDV1pbrFr5b+ig17NnTrPkfljeLuiXfHte2//vUvVq1axerVqykvL+e4447jlFNO4R//+Adnn302P/nJTwgGgzQ0NLBq1Sq2bdsW7fe8qqqqW8udbFKqpp7tygagplk79VIqmUUePmG32+nfvz+TJ0/mk/jhItQAACAASURBVE8+4bjjjuPpp59m1qxZrF27luzsbEaMGMGmTZu45ZZbWLBgAR6PJ9HFT6iUqqk7bA6yndna/KLUAYq3Rn2wnXLKKSxevJh58+Zx7bXXcuedd/Ktb32L1atXs3DhQh5//HHmzJnDU089leiiJkxK1dRB+39RKhWcfPLJvPjiiwSDQcrKyli8eDETJ05ky5Yt9O/fnxtvvJEbbriBFStWUF5eTigU4pJLLmH27NmsWLEi0cVPqJSqqYN2v6tUKvjmN7/Jhx9+yNixYxERHnroIQYMGMCzzz4bfQxcVlYWzz33HNu2beO6666LPtDil7/8ZYJLn1gp1fUuwE3/von6QD3PT3m+2/etVCrTrnd7nz7f9S5YNXW9UKqU6qtSMtS1+UUp1VelXKh7XB6qfdWETKjzjZVSKsWkXKh73V5CJkS9vz7RRVFKqYMu5UI92lOjNsEopfqglAv1aFcB+gUkpVQflLqhrjV1pVQfFFeoi8g5IvK5iHwpIjM72O4SETEi0u49lD0t0lOj3taoVGrrqO/1zZs3c/TRRx/E0vQenYa6iNiBR4FzgSOBK0TkyDa2ywZuAxL6GO9ITb3Gp6GulOp74ukmYCLwpTFmE4CIvABMBda12u4B4FfAXd1awi7yuPVCqVIHaucvfkHz+u7tetd9xCgG3HNPu+tnzpxJUVER3/ve9wCYNWsWDoeDRYsWUVlZid/vZ/bs2UydOrVLx21qauK73/0uy5Ytw+Fw8PDDD3Paaafx2Wefcd111+Hz+QiFQrz88ssMGjSIyy67jNLSUoLBIPfeey/Tp08/oPM+2OIJ9cHA1pj5UuD42A1E5BigyBgzT0TaDXURuQm4CWDo0KFdL20c3HY36Y50DXWlksz06dO5/fbbo6E+Z84cFi5cyK233orH46G8vJxJkyZx4YUXIiJx7/fRRx9FRFi7di0bNmzgG9/4Bhs3buTxxx/ntttuY8aMGfh8PoLBIPPnz2fQoEHMmzcPgOrq5MuRA+7QS0RswMPAtZ1ta4x5EngSrL5fDvTY7Yl8AUkptX86qlH3lPHjx7N79262b99OWVkZubm5DBgwgDvuuIPFixdjs9nYtm0bu3btYsCAAXHv9/333+eWW24BYNSoUQwbNoyNGzdywgkn8POf/5zS0lIuvvhiDjvsMEaPHs0PfvAD7r77bs4//3xOPvnknjrdHhPPhdJtQFHM/JDwsohs4GjgHRHZDEwCXkvoxVLtKkCppDRt2jTmzp3Liy++yPTp03n++ecpKytj+fLlrFq1iv79+9PU1NQtx7ryyit57bXXSE9PZ8qUKbz99tuMHDmSFStWMHr0aH76059y//33d8uxDqZ4auqfAIeJyHCsML8cuDKy0hhTDRRE5kXkHeCHxpju74IxThrqSiWn6dOnc+ONN1JeXs67777LnDlz6NevH06nk0WLFrFly5Yu7/Pkk0/m+eef5/TTT2fjxo2UlJRw+OGHs2nTJkaMGMGtt95KSUkJa9asYdSoUeTl5XHVVVeRk5PDX//61x44y57VaagbYwIi8n1gIWAHnjLGfCYi9wPLjDGv9XQhu8rr8rK5ZnOii6GU6qKjjjqK2tpaBg8ezMCBA5kxYwYXXHABo0ePZsKECYwaNarL+7z55pv57ne/y+jRo3E4HDzzzDO43W7mzJnD3/72N5xOJwMGDOCee+7hk08+4a677sJms+F0Onnsscd64Cx7Vsr1pw4wa8ksFpcu5u3L3u6R/SuVirQ/9d5H+1MPizzSLlF/sJRSKlFS7nF2YDW/+EI+moJNpDvSE10cpVQPWbt2LVdffXWLZW63m48/Tuh3IBMqNUM9pv8XDXWl4meM6dI94Ik2evRoVq1alehi9Ij9bWlIyeYX7dRLqa5LS0ujoqJCmy17AWMMFRUVpKWldfm1qVlTd2n/L0p11ZAhQygtLaWsrCzRRVFYf2SHDBnS5delZqhrTV2pLnM6nQwfPjzRxVAHSJtflFIqhaRkqEcfaaf9vyil+piUDPV0RzpOm1Nr6kqpPiclQ11EtP8XpVSflJKhDtYdMHr3S+/n37YN4/cnuhhKpYyUDfVIVwGq9wpUVvLVeeez68FfJbooSqWMlA11r0ubX3q72oX/xjQ1UTlnDv5t2zp/gVKqUykb6h63Pv2ot6uZNw/HwIEIUP7444kujlIpIWVDXS+U9m7+XbtoWLaMnEsuIWf6dKr+9Qq+/XgAglKqpdQNdZeXxkAj/qBehOuNaua/AcbgOW8K+TfdiDidlP/5z4kullJJL3VDPfKtUm2C6ZVq5s0j7cgjcQ8fjrNfP3KvvJLq/3ud5k2bEl00pZJayod6TbPe1tjb+DZvpunTT/Gcd150Wf4N30bS0ij/058SWDKlkl/qhrpLa+q9VfX8+QB4ppwbXebIyyPv6qupmf8GTZ9/nqiiKZX0UjfUtVOvXskYQ828+aRPOBbnwIEt1uVffx227GzK/vjHBJVOqeSXsqHucYc79dJQ71WaP/8c31df4Y1peomwe73kXXsNdW++ReOnnyWgdEolv5QNda2p90418+aB3U722We3uT7vmmuwe72U/fGRg1wypVJDyoZ6ljMLm9jY2bAz0UVRYZGml8wTT8SRl9fmNvasLPJu+Db17y6mYeXKg1xCpZJfyoa6TWycMuQU5m6cy466HYkujgIaV63Cv307nvOmdLhd3owZ2PPzKXtEa+tKdVXKhjrAzIkzMcbwy6W/THRRFFAzbz7idpN95pkdbmfLyCD/xhto+PAj6pcuPUilUyo1JF2om2Aw7otog7MG891x32XR1kW8XfJ2D5dMdcQEAtQsWEDW5MnYs7I63T738stx9OtH2SOP6NPtleqCpAv18kcfZcuVV9L4WXzBfvWRV3NY7mH8cukvafA39HDpVHsali4lWF7e4gtHHbGlpZH/nf9H47Ll1H+wpIdLp1TqSLpQz73qKuz5+Wy79TaCVVWdbu+0Oblv0n3srN/Jo6sePQglVG2pnjcPW2YmWZNPifs1OZdeimPQQK2tK9UFSRfqjrw8hvz+d/h372bb3XdjQqFOXzOu3zimjZzG8+ufZ8OeDQehlCpWyOej9t//IfvMM7GlpcX9OpvLReHNN9O0Zg1177zTcwVUKoUkXagDpI8dS/8fz6T+3cVUPPFEXK+57Zjb8Lq93P/h/QRDwR4uoYpV/957hGpr8ZwfX9NLLO/UqTiHDqXskT/G9Qdcqb4urlAXkXNE5HMR+VJEZrax/k4RWScia0TkLREZ1v1FbSn3iivwXHgBZY/8kbr3P+h0e6/by4+O+xFry9cyZ+Ocni6eilEzbx723FwyJ03q8mvF6aTwezfTvH49tf95swdKp1Rq6TTURcQOPAqcCxwJXCEiR7babCUwwRgzBpgLPNTdBW2jXAycNQv3oYey/Yc/jOtxaFOGT2HSwEk8suIRdjfs7ukiKiBUX0/t24vIPudsxOncr314zj8f14gR7H74tzR/8UU3l1Cp1BJPTX0i8KUxZpMxxge8AEyN3cAYs8gYE7m15CNgSPcWs222jAyG/PERTCBA6e13EPL5OtxeRLh30r34gj4e+qTH/+4ooPbtRZimpjb7eomX2O0MuO8+glXVbPrmxex66NcE6+q7sZRKpY54Qn0wsDVmvjS8rD3fBt5oa4WI3CQiy0RkWVlZWfyl7ICruJhBD/6SprVr2fWLX3S6/VDPUG4ccyMLNy/k/W3vd0sZVPtq5s3DMWAA6cccc0D7yZx0PIcseIOcb36TPU8/zaYpU6ieN0/vilGqlW69UCoiVwETgF+3td4Y86QxZoIxZkJhYWG3HTf7zDPJv+HbVL3wIlWvvtrp9tcffT3FnmJmfzSbxkBjt5VDtRSsqqLugw/wTJmC2A78v5ojN5eBD9xP8Qv/xFFYyPYf/JCSa6+j+csvu6G0SqUGRxzbbAOKYuaHhJe1ICJnAj8BJhtjmrunePErvP12GtesZefPZpE2ahRpo0a1u63L7uK+E+7j+oXX8+SaJ7ntmNsOYkn7jpp//xv8/k77eumq9LFjKZ7zIlUvzWX3737Hpou+Sd63vkXBzTdjz8rs1mOp9hljwO8n1NREqLEJ09iA8Xf9mcDRT1stPnS19QlMrH8iEDvELrfZwstt1qqYeQSrchHeTmw2sDsQuw3s9vC83dpPEpPOPr6KiAPYCJyBFeafAFcaYz6L2WY81gXSc4wxcV3JmjBhglm2bNn+lrtNgfJyvr74EiQtjeFzX8Lu8XS4/U/f/ynzNs3jpQte4tDcQ7u1LAq2XHMtgV27GPHG/B77RQlUVlL28MNUvTQXR79+9J95N9nnnpv0v5g9yRiDaWggWFtLsKaGUOy4uoZgbQ2hmtqYcS2hxgZMQ6MV4E2NmMYmQo2NEEzB24NtrUK+1eruaPAbcM+Pybn00v16rYgsN8ZMaHd9PG2SIjIF+D1gB54yxvxcRO4HlhljXhORN4HRQKQ7xBJjzIUd7bMnQh2gYcUKtnzrGrJOOYUhf/pjhx/7K5squfDVCxnhHcHT5zyNTZLytv1eyb9rN1+eeioFN99M4S3f7/HjNa5ezc77H6Dps8/ImDQJ79SpuIYNwzW8GHtOTsqGvAkECFTsIVhRTqCigkB5BcGqKoI11YSqawjW1LScrq4mWFsLndSoJSMDe3Y2dk82tqxsbBkZ2DLSkbR0bGlpe6fT05C0NGzpGda00xmuPXdWcNNqu/B07LLY1Sb8Gow1Nsaq4be1PBSZDoXnQ+HtYuZDBkJBTDCECQYgGMKEgta41XzbP6AD+/+UfdZZZBwzfr9e2y2h3hN6KtQB9jz3HLt+8UsK77yTgptu7HDbV754hfuW3MesE2ZxychLeqQ8fdGeZ59l1y8fZMT8+bhHDD8oxzTBIFUvvUTZ735PsHrvw1FsHg+u4mJcxcOsoC8uxjXMmo+nc7Eul8MYQvUNhGprCNbU7h3X1e4zD1i1QYcTcTgQhx0cDsTuQJwOxOEAuwMT8BMsr7CCu6KcYHl5NMBp63dYBJvHgz0yeL3YvB7sHm943hNe77WCO9tjjT0e7FlZ+337qep5fTLUjTFs/8EPqFmwkJzpl+HIL8Cek2MNXq81zrXmJSOD6/99PRv3bOQPp/+B4wYc1yNl6mu+vmw6JuBnxL/+ddCPbfx+/Nu24duyBd/mzTRv3ox/yxaaN28msL1l3/q2rKy9H7Fj2lutNtpIe6yATazaXjCIMeGaXjBo1RZDIQiFwjXAkNWu3Mm3XyU9HVtWJiI2TCCACQQgPDaBQJuvl7Q0HAUFOAoKsBfk48gvCM/nY8/Px1FQaE3n5GDLyuqWi9Oq9+ks1OO5UJp0RISBDzxAsKqamtfnEaqtbX9jh4OZniw2ZzbywifXs/nau5k29qqDV9gU5Nu6laY1a+h31w8TcnxxOsM182KYPLnFulBTE76SEnybN+PbsoXA7jIrQMMf4aMf1UOhfedtNrAJYrOHxzaITIvNuvhmt4HDgT3bg82TjT1SA872YM/O2lsTdrk6PAcTCrUIebHbkYyMlG1GUt0nJWvqrZlAwGpLrK622hurqghWxU5XUb96Jf7Pv6AuDbZPHsVZdz5MxrCD02zQmWBNDfUffUT9kiX4d+wg49gJZJ5wAmlHHoHY7T1+fBMMWu2xVVUEKysJVFQQ3FNJcE8FgT2VBCsqCFTuIVixxxpXVkEgwKFvv4Vz0KAeL59SfUmfrKm3Jg4Hjvx8HPn57W5jjKF+2TKW/mkWh/x7A5v/PQX3KScx4JrryTjhhINaQzJ+P42rV1O/ZAn1Hyyhce1aCIWwZWTgGDCAsncXUwbYvF4yjz+ezBNPIPOEE3AOHRp3OUMNDfi2luIv3Yp/+469f/Baj6uqCNXUtLsfW1YW9vw8HLl5OIuKSB87BntePmlHHKGBrlQC9Imaele9sfTvrH7iIU5fFSS7PoTrkEPInXElOVOnYsvs/vugjTH4vt5M/QcfUL9kCQ1LlxKqrwebjfTRo8k86SQyTzqR9DFjEKeTQFkZ9R99TP2HH1L/4YcEdljtxM5Bg8gIB3zmpEkQClnBvbUEX8lW/KVb8ZVsxbd1K8Hy8n3KYcvObnndITKOTnux5+bhyM/DnmcNtk6aEZRS3atPXijtDp+Wf8oPFt7KkasruXZDP1wbS7BlZeG9+Ju4DzkU4/NhfM0Yn4+Qz4dp9lnLmq1lxh9e7veD34/x+TH+Ngafj1Bzc7Q27Bw61Kp5n3QSmccf3+m99sYY/Fu2WAG/5EPqP/647Zq1CI6BA3ANKcI5tAjXkCJcQ4twFhXhHDQIu9dr3WmhlOrVNNQPQFlDGbe/cztrdq/m7syLOfXjBmoX/nvfe3xFELcbcbkQtwub02VNRwans/0hvN49ciSZJ52Iq6io7cLEyQSDNK1bR8PSTxC3e29wDx6stWqlUoCG+gFqDjbzwIcP8L9f/S9nDD2D2WN/jNsP4nJhC4c2DofelaCUOig6C3W9kbUTbrubB056gLsm3MWirYu4+r3v8KVjD47cXGyZmVZtWwNdKdVLaKjHQUT41lHf4rEzHmN3w24ue/0yZsyfwWtfvUZz8KD3XaaUUu3S5pcuqm6u5rWvXmPO53PYXLMZr9vLRYdcxGWHX8ZQz9BEF08pleK0Tb2HGGNYunMpL37+IotKFhEwAU4YeALTD5/O5KLJOGx6J4lSqvtpqB8EZQ1lvPzFy8zdOJddDbvol9GPSw+7lIsPu5j+mf0TXTylVArRUD+IAqEAi0sXM+fzOXyw/QNsYmPigIlMGT6FM4edSbYrO9FFVEolOQ31BNlas5VXv3qV+ZvmU1pXisvmYnLRZKYMn8LJQ07GbXcnuohKqSSkoZ5gxhjWlq9l3qZ5LNi8gD1Ne8h2ZnPmsDM5b8R5TOg/Abut5zvlUkqlBg31XiQQCrB0x1LmfT2PN7e8SUOggcL0Qs4Zfg6nFZ3GmMIxWoNXSnVIQ72Xago08U7pO8zfNJ/3tr1HIBTAbXczrt84jh9wPBMHTuSo/KP0LhqlVAsa6kmg1lfL8l3L+XjHxyzduZSNlRsByHRmcmz/Y5k4YCLHDzyekbkj9TmqSvVx2p96Esh2ZXNq0amcWnQqAHua9rBs5zKW7lzKxzs+ZnHpYgC8bi/jC8cz1DOUouyi6DAwayBOmz5TUimlNfWksKt+F0t3LmXpzqWsLVtLaV1pi+4J7GJnQOaAFkFflF3EoTmHMtQzVGv3SqUQbX5JQSEToqyhjK21W6NDaV0ppbWlbK3dSlVzVXTbDEcGo/JGcWT+kYzKG8UR+UcwwjtC2+qVSlLa/JKCbGKjf2Z/+mf2Z8KAfd/bWl8tJbUlbNyzkfV71rO+Yj0vf/EyjYFGwOp5cmTuSI7IO4JR+aM4LOcw+mX0Iz89X+++USrJaU29jwiGgmyp2RIN+ci41l/bYrtsVzb5afkUpBdEh/x0az4/LR+7zU4gFCAYChIw1tgf8lvLTDA6jjQJDcwcyIDMAXhcHu2iWKluoDV1BYDdZmdEzghG5IzgvBHnAdYXo7bVbWNT9SYqGisobyxvMazfs57yxnLq/fUHfPxMZ2Y04AdlDmJg1kAGZlpDblouXrcXj8ujzUJKHSD9DerDRIQh2UMYkj2kw+0aA43R0DcY7GLHYXNgFztOm9OattlxiDV22pz4gj521u9kR/2O6LC9bjs763fyafmnLdr9Y2U6M/G6vHjcnujY4/JE57Nd2dYyp7Us25WNx+Uhy5WldwAphYa6ikO6Iz2u8G+tMKOQ0YWj21zX4G+Ihn5lcyXVzdXU+Gqoaa6hxlcTnf+q6qvovD/kb3NfERmODLJd2datn/3Gc3bx2Rzb/1i9+0f1KdqmrpKCMYamYBO1vlpqmmuo9ddG/wDU+Gqo9dVa63w1VDRWsGzXMhoDjfRL78c3ir/B2cVnM7ZwrLbrq6SnbeoqJYgI6Y500h3p9Mvo1+n2Df4GFpcuZsHmBcz5fA5/X/93BmYO5Jziczh7+NkcmXekBrxKSVpTVymvzlfHoq2LWLB5AUu2LSFgAgzNHsrZxWczaeAk7DY7IRPCGEMIaxyZji43Iau93+3F6/aS484hzZGW6FNTfVC3fPlIRM4B/gDYgb8aYx5std4NPAccC1QA040xmzvap4a6SoTq5mreKnmLBV8v4OOdHxMyof3eV5o9DY/bQ447Jxr0XreXNHsajYHG6NAQaNg7729ssc5us+OyuXDb3bjse8ex0267G5fNhdPmxGl3WuPW0zHzgmCw/jABGPb+jhtjovOCYLfZoxe+I4Nd7NYFb3FG10fHbUzbxBadD5kQtf5a6nx11PprqffVU+evo9ZXu3fsq6M+UI/L5iLLlUW2M5tMV6Y1dmaS7comy5lFliuLLGcW6Y70FuWLXJx32Bw4xIFNbPv1qSsYCrKnaQ+7Gnaxq34XOxt2Rqcj4/LGcjKcGeSn57e41Tc/Ld9aFnO7b4Yzg3p/PQ3+Bur99dZ0wJqu89e1WH7WsLMY12/cfv2/O+BQFxE7sBE4CygFPgGuMMasi9nmZmCMMeY7InI58E1jzPSO9quhrhKtorGCzys/xyY2bFjBYBObFRKINY8teqG13l9Pta+aquYqqpuro0OLeV81jYHGaFNRuiOdDEfG3nnn3uVp9jQMhuZgM76gD1/QF52OLgvtnfaH/PiDfmscGYJ+fCFfgn+SnRMkGtSZzkwynZn4gr5o4NX6aju9EN6RSNhH3j+72KPTsfORcXOwmbKGMgIm0GI/TpuT/hnWF/v6Z/SnIL2AxkAj5Y3lVDRVRO8Ci+2mo6vSHenMnDiTiw+7eL9e3x1t6hOBL40xm8I7fAGYCqyL2WYqMCs8PRf4k4iISVTbjlJxyE/P58T0ExNdjANmjCForC+B+YJ7A15EEKwabOSPVGQarBp89AtjoWB0OvaLZAFjzYdMKLpN0AQJhoKETIiAablOEKv2Ha5tR8YZzoxO70LyBX3U+mqp99dHa/uRGm5s2aKDCeAP+a0vwsWUO2RC0XF70y6bKxrc/TP6MyBzAP0z+5Przu201m+Mod5fHw36yPc6mgJN0T9YGc4Ma9rRcj7DkdHjD8WJJ9QHA1tj5kuB49vbxhgTEJFqIB8oj91IRG4CbgIYOnTofhZZKRVLRHCI1RyR7khPdHH2m8vuijZp9GYi1h+uLFcWxd7iRBdnHwf1Bl5jzJPGmAnGmAmFhYUH89BKKdUnxBPq24CimPkh4WVtbiMiDsCLdcFUKaXUQRRPqH8CHCYiw0XEBVwOvNZqm9eAa8LTlwJva3u6UkodfJ22qYfbyL8PLMS6pfEpY8xnInI/sMwY8xrwP8DfRORLYA9W8CullDrI4vpGqTFmPjC/1bL7YqabgGndWzSllFJdpT0dKaVUCtFQV0qpFKKhrpRSKSRhHXqJSBmwZT9fXkCrLzalgFQ7p1Q7H0i9c0q184HUO6e2zmeYMabdL/okLNQPhIgs66jvg2SUaueUaucDqXdOqXY+kHrntD/no80vSimVQjTUlVIqhSRrqD+Z6AL0gFQ7p1Q7H0i9c0q184HUO6cun09StqkrpZRqW7LW1JVSSrVBQ10ppVJI0oW6iJwjIp+LyJciMjPR5TlQIrJZRNaKyCoRScrn+4nIUyKyW0Q+jVmWJyL/EZEvwuPcRJaxK9o5n1kisi38Pq0SkSmJLGNXiUiRiCwSkXUi8pmI3BZenpTvUwfnk7Tvk4ikichSEVkdPqf/Di8fLiIfhzPvxXBvue3vJ5na1ON5XmqyEZHNwARjTNJ+YUJETgHqgOeMMUeHlz0E7DHGPBj+45trjLk7keWMVzvnMwuoM8b8JpFl218iMhAYaIxZISLZwHLgIuBakvB96uB8LiNJ3yexnqOXaYypExEn8D5wG3An8C9jzAsi8jiw2hjzWHv7SbaaevR5qcYYHxB5XqpKIGPMYqwul2NNBZ4NTz+L9QuXFNo5n6RmjNlhjFkRnq4F1mM9hjIp36cOzidpGUtdeNYZHgxwOtaznyGO9yjZQr2t56Um9RuJ9ab9W0SWh5/hmir6G2N2hKd3Av0TWZhu8n0RWRNunkmKZoq2iEgxMB74mBR4n1qdDyTx+yQidhFZBewG/gN8BVQZYwLhTTrNvGQL9VT0X8aYY4Bzge+FP/qnlPBTsJKnna9tjwGHAOOAHcBvE1uc/SMiWcDLwO3GmJrYdcn4PrVxPkn9PhljgsaYcViPDZ0IjOrqPpIt1ON5XmpSMcZsC493A69gvZGpYFe43TPS/rk7weU5IMaYXeFfuBDwF5LwfQq3074MPG+M+Vd4cdK+T22dTyq8TwDGmCpgEXACkBN+9jPEkXnJFurxPC81aYhIZvgiDyKSCXwD+LTjVyWN2OfWXgP8bwLLcsAiwRf2TZLsfQpfhPsfYL0x5uGYVUn5PrV3Psn8PolIoYjkhKfTsW4IWY8V7peGN+v0PUqqu18Awrco/Z69z0v9eYKLtN9EZARW7RysRwv+IxnPR0T+CZyK1U3oLuBnwKvAHGAoVhfLlxljkuLiYzvncyrWR3oDbAb+X0xbdK8nIv8FvAesBULhxfdgtUMn3fvUwflcQZK+TyIyButCqB2rwj3HGHN/OCdeAPKAlcBVxpjmdveTbKGulFKqfcnW/KKUUqoDGupKKZVCNNSVUiqFaKgrpVQK0VBXSqkUoqGu1H4QkVNF5PVEl0Op1jTUlVIqhWioq5QmIleF+6heJSJPhDtMqhOR34X7rH5LRArD244TkY/CnUG9EukMSkQOFZE3w/1crxCRQ8K7zxKRuSKyQUSeD3/LUamE0lBXKUtEjgCmAyeFO0kKAjOATGCZMeYo4F2sb4wCPAfcbYwZg/VNxcjy54FHjTFjgROxOooCq2fA24EjgRHAST1+Ukp1wtH5JkolrTOAY4FPwpXodKwOq0LAi+Ft/g78EoIe4AAAAPtJREFUS0S8QI4x5t3w8meBl8J98ww2xrwCYIxpAgjvb6kxpjQ8vwooxnqwgVIJo6GuUpkAzxpjftxioci9rbbb374yYvvfCKK/T6oX0OYXlcreAi4VkX4QfR7nMKz/95Fe764E3jfGVAOVInJyePnVwLvhp+qUishF4X24RSTjoJ6FUl2gNQuVsowx60Tkp1hPlrIBfuB7QD0wMbxuN1a7O1jdmj4eDu1NwHXh5VcDT4jI/eF9TDuIp6FUl2gvjarPEZE6Y0xWosuhVE/Q5hellEohWlNXSqkUojV1pZRKIRrqSimVQjTUlVIqhWioK6VUCtFQV0qpFPL/AV6Bb9WNdkzXAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqBcJ8xX6tDj"
      },
      "source": [
        "## Save the model/weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9EkryyD6tDj",
        "outputId": "7ecb68ea-f95a-44b1-e9a3-c3045dd334ba"
      },
      "source": [
        "# JSON JSON\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "\n",
        "# save the model architecture to JSON file\n",
        "with open('{}/{}.model.json'.format(output_dir, model_name), 'w') as json_file:\n",
        "    json_file.write(json_model)\n",
        "\n",
        "\n",
        "# YAML YAML\n",
        "# serialize model to YAML\n",
        "model_yaml = model.to_yaml()\n",
        "\n",
        "# save the model architecture to YAML file\n",
        "with open(\"{}/{}.model.yaml\".format(output_dir, model_name), \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "\n",
        "\n",
        "# WEIGHTS HDF5\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"{}/{}.model.h5\".format(output_dir,model_name))\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnn8quy36tDk",
        "outputId": "dca00393-9fa4-4020-b783-b1cd33e36d9b"
      },
      "source": [
        "# Open the handle\n",
        "json_file = open('{}/{}.model.json'.format(output_dir, model_name), 'r')\n",
        "\n",
        "# load json and create model\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights('{}/{}.model.h5'.format(output_dir, model_name))\n",
        "print(\"Loaded model from disk\")\n",
        "# loaded_model_json"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOH5Uzwz6tDl",
        "outputId": "d63c31bb-0184-4476-d79b-aa0f8f90df5f"
      },
      "source": [
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', \n",
        "                     metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.18058907985687256\n",
            "Test accuracy: 0.9724444150924683\n",
            "accuracy: 97.24%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfNdknXdWMIF"
      },
      "source": [
        "# ConvNN(RF) - top 300"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUXRYNVOWMIJ"
      },
      "source": [
        "## Train/Test split    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KZUSHxfWMIK"
      },
      "source": [
        "# from keras.utils import to_categorical\n",
        "# outcome = encode(outcome['Project_id'])"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "oRyPQL84WMIK",
        "outputId": "ffabd259-afe5-408d-9f4e-52a8850c1a48"
      },
      "source": [
        "feature_sort_selected = feature_sort.iloc[:300,:]\n",
        "feature_sort_selected"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>importance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3300</th>\n",
              "      <td>MOGAT3</td>\n",
              "      <td>0.003089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57644</th>\n",
              "      <td>FP671120.6</td>\n",
              "      <td>0.002802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12189</th>\n",
              "      <td>KLK4</td>\n",
              "      <td>0.002783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1448</th>\n",
              "      <td>CDH17</td>\n",
              "      <td>0.002782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17545</th>\n",
              "      <td>KLHL14</td>\n",
              "      <td>0.002726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13377</th>\n",
              "      <td>PURG</td>\n",
              "      <td>0.000656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3286</th>\n",
              "      <td>TFR2</td>\n",
              "      <td>0.000656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11610</th>\n",
              "      <td>HEPACAM</td>\n",
              "      <td>0.000651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5738</th>\n",
              "      <td>OVOL2</td>\n",
              "      <td>0.000651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2547</th>\n",
              "      <td>CDH20</td>\n",
              "      <td>0.000651</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             name  importance\n",
              "3300       MOGAT3    0.003089\n",
              "57644  FP671120.6    0.002802\n",
              "12189        KLK4    0.002783\n",
              "1448        CDH17    0.002782\n",
              "17545      KLHL14    0.002726\n",
              "...           ...         ...\n",
              "13377        PURG    0.000656\n",
              "3286         TFR2    0.000656\n",
              "11610     HEPACAM    0.000651\n",
              "5738        OVOL2    0.000651\n",
              "2547        CDH20    0.000651\n",
              "\n",
              "[300 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKPm44RhWMIL"
      },
      "source": [
        "TC1data15_selected = TC1data15.loc[:,feature_sort_selected['name']]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6p7sF87WMIN"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(TC1data15_selected, \n",
        "                                                    outcome, \n",
        "                                                    train_size=0.75, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=123, \n",
        "                                                    stratify = outcome)"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "cztMXzlVWMIN",
        "outputId": "2974eb09-8c39-4d36-d992-3a8d91336fe1"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MOGAT3</th>\n",
              "      <th>FP671120.6</th>\n",
              "      <th>KLK4</th>\n",
              "      <th>CDH17</th>\n",
              "      <th>KLHL14</th>\n",
              "      <th>NAPSA</th>\n",
              "      <th>VTN</th>\n",
              "      <th>SFTPB</th>\n",
              "      <th>RDH11</th>\n",
              "      <th>RP11-452C8.1</th>\n",
              "      <th>SOX17</th>\n",
              "      <th>SFTPA1</th>\n",
              "      <th>CRYGN</th>\n",
              "      <th>RP11-53M11.5</th>\n",
              "      <th>FP671120.4</th>\n",
              "      <th>AP001187.9</th>\n",
              "      <th>KLK2</th>\n",
              "      <th>F13B</th>\n",
              "      <th>S1PR5</th>\n",
              "      <th>HRG</th>\n",
              "      <th>KLK3</th>\n",
              "      <th>ITIH2</th>\n",
              "      <th>TRPS1</th>\n",
              "      <th>RP5-1021I20.2</th>\n",
              "      <th>ACSM2B</th>\n",
              "      <th>UGT2B4</th>\n",
              "      <th>PRODH2</th>\n",
              "      <th>FEV</th>\n",
              "      <th>MASP2</th>\n",
              "      <th>SFTPC</th>\n",
              "      <th>FP236383.4</th>\n",
              "      <th>KCNJ10</th>\n",
              "      <th>PRAC2</th>\n",
              "      <th>GRHL2</th>\n",
              "      <th>SFTA3</th>\n",
              "      <th>SLC28A1</th>\n",
              "      <th>NXPE1</th>\n",
              "      <th>LINC00483</th>\n",
              "      <th>CHRNA2</th>\n",
              "      <th>SFTPA2</th>\n",
              "      <th>...</th>\n",
              "      <th>ZDHHC22</th>\n",
              "      <th>HMGA1</th>\n",
              "      <th>DSCAM</th>\n",
              "      <th>AQP4</th>\n",
              "      <th>LRRC2</th>\n",
              "      <th>CFHR2</th>\n",
              "      <th>RP11-713P17.3</th>\n",
              "      <th>RIPK4</th>\n",
              "      <th>CH507-513H4.5</th>\n",
              "      <th>KRT6A</th>\n",
              "      <th>RPL7P38</th>\n",
              "      <th>SCD5</th>\n",
              "      <th>GNG7</th>\n",
              "      <th>SLC44A4</th>\n",
              "      <th>RP11-283I3.4</th>\n",
              "      <th>LINC01158</th>\n",
              "      <th>LCN12</th>\n",
              "      <th>RP11-999E24.3</th>\n",
              "      <th>POU3F4</th>\n",
              "      <th>APOH</th>\n",
              "      <th>DUOX2</th>\n",
              "      <th>TTYH2</th>\n",
              "      <th>HMGN2P46</th>\n",
              "      <th>ATP8B1</th>\n",
              "      <th>ESR1</th>\n",
              "      <th>ASGR1</th>\n",
              "      <th>GPR37L1</th>\n",
              "      <th>RP11-114N19.3</th>\n",
              "      <th>CH17-360D5.2</th>\n",
              "      <th>RUFY3</th>\n",
              "      <th>SLC22A2</th>\n",
              "      <th>CYP2S1</th>\n",
              "      <th>HULC</th>\n",
              "      <th>C8B</th>\n",
              "      <th>PEA15</th>\n",
              "      <th>PURG</th>\n",
              "      <th>TFR2</th>\n",
              "      <th>HEPACAM</th>\n",
              "      <th>OVOL2</th>\n",
              "      <th>CDH20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.808450</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.672119</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.346068</td>\n",
              "      <td>1.155254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.424186</td>\n",
              "      <td>3.167719</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.465801</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.094042</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022084</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.362394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.636991</td>\n",
              "      <td>2.317114</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.142535</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.398765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.489150</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.076708</td>\n",
              "      <td>0.405134</td>\n",
              "      <td>1.469228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.382962</td>\n",
              "      <td>0.811005</td>\n",
              "      <td>2.359632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.556286</td>\n",
              "      <td>0.000471</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.544855</td>\n",
              "      <td>0.499250</td>\n",
              "      <td>0.201011</td>\n",
              "      <td>1.839588</td>\n",
              "      <td>0.044883</td>\n",
              "      <td>0.184257</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.129937</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.882607</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.079015</td>\n",
              "      <td>2.339121</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.477503</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.465524</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.257574</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.773058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.566138</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.110626</td>\n",
              "      <td>1.734314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.137554</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.912051</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.435274</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.242087</td>\n",
              "      <td>0.180709</td>\n",
              "      <td>0.493004</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.926807</td>\n",
              "      <td>0.200731</td>\n",
              "      <td>1.455283</td>\n",
              "      <td>0.757515</td>\n",
              "      <td>0.109061</td>\n",
              "      <td>0.209082</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.007618</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.921733</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.736137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.085994</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.330262</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>835</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.157242</td>\n",
              "      <td>0.601505</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.690877</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.297473</td>\n",
              "      <td>1.752160</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.041478</td>\n",
              "      <td>0.576785</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.296192</td>\n",
              "      <td>0.444143</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.557529</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.834996</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.713397</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.790730</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.506128</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.277739</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.513443</td>\n",
              "      <td>0.317196</td>\n",
              "      <td>3.511951</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.819393</td>\n",
              "      <td>0.124728</td>\n",
              "      <td>0.241889</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.744653</td>\n",
              "      <td>0.762830</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.822466</td>\n",
              "      <td>0.706622</td>\n",
              "      <td>0.122293</td>\n",
              "      <td>1.633034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.535041</td>\n",
              "      <td>1.043782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.558877</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.322910</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.164639</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.378516</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4447</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.192705</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.284720</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.596492</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.039429</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.153790</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.496690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.578958</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.786010</td>\n",
              "      <td>0.615578</td>\n",
              "      <td>1.350820</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.079273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103834</td>\n",
              "      <td>0.463922</td>\n",
              "      <td>0.431615</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.473572</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.208826</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.617325</td>\n",
              "      <td>0.604954</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.847522</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.431690</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.739043</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.784825</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.948668</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.531098</td>\n",
              "      <td>0.094371</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.352760</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.316836</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.133977</td>\n",
              "      <td>2.396390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.550796</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.164986</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.818311</td>\n",
              "      <td>1.543859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.833029</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.169070</td>\n",
              "      <td>1.191010</td>\n",
              "      <td>0.100771</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.527646</td>\n",
              "      <td>0.178553</td>\n",
              "      <td>2.259882</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.325293</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.995120</td>\n",
              "      <td>0.271508</td>\n",
              "      <td>1.646923</td>\n",
              "      <td>1.585088</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.074854</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.703209</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.613192</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.991211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.588367</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.290742</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3495</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.125576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.671380</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.636459</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.288064</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.436981</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.018219</td>\n",
              "      <td>1.585684</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.088985</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.529270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.642953</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.753029</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.986313</td>\n",
              "      <td>0.579845</td>\n",
              "      <td>2.572061</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291273</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.449436</td>\n",
              "      <td>0.445850</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.098800</td>\n",
              "      <td>0.765404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012666</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.870126</td>\n",
              "      <td>0.770270</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.350425</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.420477</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.756517</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.610595</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>1.163849</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.163344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.669915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.229859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.438474</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.735723</td>\n",
              "      <td>1.644623</td>\n",
              "      <td>1.537464</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.596512</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.849123</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.575072</td>\n",
              "      <td>0.106509</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.387669</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.068521</td>\n",
              "      <td>1.142299</td>\n",
              "      <td>0.699643</td>\n",
              "      <td>1.090601</td>\n",
              "      <td>1.785539</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.286730</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.952789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.282986</td>\n",
              "      <td>0.282386</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.039946</td>\n",
              "      <td>2.016984</td>\n",
              "      <td>0.407390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.475399</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2943</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.291902</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.148528</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.766090</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.383600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.399102</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.593394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.320577</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.026789</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.065513</td>\n",
              "      <td>1.582818</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.046281</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.761895</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.376670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.715761</td>\n",
              "      <td>0.514583</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.095160</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.027521</td>\n",
              "      <td>0.848705</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.513569</td>\n",
              "      <td>0.703840</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.093707</td>\n",
              "      <td>0.975021</td>\n",
              "      <td>0.039349</td>\n",
              "      <td>0.762424</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.457220</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028215</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.950010</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1573</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.657723</td>\n",
              "      <td>0.152280</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.482651</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.282959</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.991760</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.281678</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.200227</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.905957</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.614031</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.796235</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.924033</td>\n",
              "      <td>1.084208</td>\n",
              "      <td>0.812813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.742154</td>\n",
              "      <td>0.959958</td>\n",
              "      <td>0.413586</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.769852</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.546614</td>\n",
              "      <td>1.317632</td>\n",
              "      <td>0.132485</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.812482</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.858813</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.484224</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.305283</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3192</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.369517</td>\n",
              "      <td>0.455298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.917144</td>\n",
              "      <td>1.889821</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.852791</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.617423</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.027439</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.643908</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.725373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065058</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.392420</td>\n",
              "      <td>2.243345</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.344721</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.577214</td>\n",
              "      <td>0.977498</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.575888</td>\n",
              "      <td>0.470070</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.335087</td>\n",
              "      <td>1.146701</td>\n",
              "      <td>1.079314</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.253740</td>\n",
              "      <td>0.610550</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.385463</td>\n",
              "      <td>1.060680</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.484293</td>\n",
              "      <td>1.556381</td>\n",
              "      <td>0.162502</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.907122</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.370773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.476386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.502892</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.081213</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3375 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        MOGAT3  FP671120.6      KLK4  ...  HEPACAM     OVOL2  CDH20\n",
              "849   0.000000    0.000000  0.000000  ...      0.0  1.477503    0.0\n",
              "1050  0.000000    0.000000  0.000000  ...      0.0  1.330262    0.0\n",
              "835   0.000000    0.157242  0.601505  ...      0.0  1.378516    0.0\n",
              "4447  0.000000    0.000000  0.000000  ...      0.0  0.784825    0.0\n",
              "53    0.000000    1.948668  0.000000  ...      0.0  1.290742    0.0\n",
              "...        ...         ...       ...  ...      ...       ...    ...\n",
              "3495  0.000000    0.000000  0.000000  ...      0.0  1.610595    0.0\n",
              "1737  1.163849    0.000000  0.000000  ...      0.0  0.000000    0.0\n",
              "2943  0.000000    0.000000  0.000000  ...      0.0  0.950010    0.0\n",
              "1573  0.000000    0.000000  0.000000  ...      0.0  1.305283    0.0\n",
              "3192  0.000000    0.000000  0.000000  ...      0.0  1.081213    0.0\n",
              "\n",
              "[3375 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smpF7T_vWMIN"
      },
      "source": [
        "## CONV1D "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-o8INSiWMIO"
      },
      "source": [
        "# parameters  \n",
        "activation='relu'\n",
        "batch_size=20\n",
        "# Number of sites\n",
        "classes=15\n",
        "drop = 0.1\n",
        "feature_subsample = 0\n",
        "loss='categorical_crossentropy'\n",
        "# metrics='accuracy'\n",
        "out_act='softmax'\n",
        "pool=[1, 10]\n",
        "# optimizer='sgd'\n",
        "shuffle = False \n",
        "epochs=30\n",
        "\n",
        "optimizer = optimizers.SGD(lr=0.1)\n",
        "metrics = ['acc']"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJXEj0FvWMIO"
      },
      "source": [
        "x_train_len = X_train.shape[1]   \n",
        "\n",
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "filters = 128 \n",
        "filter_len = 20 \n",
        "stride = 1 \n",
        "\n",
        "# inside pool_list loop\n",
        "pool_list = [1,10]\n",
        "\n",
        "K.clear_session()"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvObEwDSWMIO",
        "outputId": "cacbe711-6c2d-4bfb-b474-2c17f31f29de"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# model.add  CONV1D\n",
        "model.add(Conv1D(filters = filters, \n",
        "                 kernel_size = filter_len, \n",
        "                 strides = stride, \n",
        "                 padding='valid', \n",
        "                 input_shape=(x_train_len, 1)))\n",
        "\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 1))\n",
        "\n",
        "filters = 128\n",
        "filter_len = 10 \n",
        "stride = 1 \n",
        "# Conv1D\n",
        "model.add(Conv1D(filters=filters, \n",
        "                 kernel_size=filter_len, \n",
        "                 strides=stride, \n",
        "                 padding='valid'))\n",
        "# Activation\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# MaxPooling\n",
        "model.add(MaxPooling1D(pool_size = 10))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(200))\n",
        "\n",
        "# activation \n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(20))\n",
        "# activation\n",
        "# model.add(Activation('relu')) # SR\n",
        "model.add(Activation(activation))\n",
        "\n",
        "#dropout\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Dense(15))\n",
        "model.add(Activation(out_act))\n",
        "\n",
        "model.compile( loss= loss, \n",
        "              optimizer = optimizer, \n",
        "              metrics = metrics )\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 281, 128)          2688      \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 281, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 281, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 272, 128)          163968    \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 272, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 27, 128)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3456)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               691400    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20)                4020      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 15)                315       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 862,391\n",
            "Trainable params: 862,391\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgho0oXYWMIP"
      },
      "source": [
        "# save\n",
        "# save = '/content/drive/My Drive/FNL_TC1/'\n",
        "output_dir = \"/content/drive/My Drive/FNL_TC1/Model\"\n",
        "\n",
        "if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "model_name = 'tc1_rf'\n",
        "path = '{}/{}.autosave.model.h5'.format(output_dir, model_name)\n",
        "checkpointer = ModelCheckpoint(filepath=path,\n",
        "                               verbose=1,\n",
        "                               save_weights_only=True,\n",
        "                               save_best_only=True)\n",
        "\n",
        "csv_logger = CSVLogger('{}/training.log'.format(output_dir))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VG5goixWMIP"
      },
      "source": [
        "# SR: change epsilon to min_delta\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', \n",
        "                              factor=0.1, \n",
        "                              patience=10, \n",
        "                              verbose=1, mode='auto', \n",
        "                              min_delta=0.0001, \n",
        "                              cooldown=0, \n",
        "                              min_lr=0)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqSPynzGWMIP",
        "outputId": "a56e65a1-10ae-4ab5-f27e-29054569853b"
      },
      "source": [
        "# batch_size = 20 \n",
        "history = model.fit(X_train, Y_train, batch_size=batch_size, \n",
        "                    epochs=epochs, verbose=1, validation_data=(X_test, Y_test), \n",
        "                    callbacks = [checkpointer, csv_logger, reduce_lr])\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 1.7581 - acc: 0.4441 - val_loss: 0.2959 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.29592, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 2/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.3428 - acc: 0.8798 - val_loss: 0.2413 - val_acc: 0.9253\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.29592 to 0.24131, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 3/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.2416 - acc: 0.9242 - val_loss: 0.2268 - val_acc: 0.9316\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.24131 to 0.22683, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 4/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.1894 - acc: 0.9428 - val_loss: 0.1585 - val_acc: 0.9547\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.22683 to 0.15853, saving model to /content/drive/My Drive/FNL_TC1/Model/tc1_rf.autosave.model.h5\n",
            "Epoch 5/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.1594 - acc: 0.9514 - val_loss: 0.3390 - val_acc: 0.8907\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.15853\n",
            "Epoch 6/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.1507 - acc: 0.9501 - val_loss: 0.1962 - val_acc: 0.9476\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.15853\n",
            "Epoch 7/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.1241 - acc: 0.9590 - val_loss: 0.1685 - val_acc: 0.9600\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.15853\n",
            "Epoch 8/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.1120 - acc: 0.9662 - val_loss: 0.1721 - val_acc: 0.9582\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.15853\n",
            "Epoch 9/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0672 - acc: 0.9794 - val_loss: 0.1713 - val_acc: 0.9547\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.15853\n",
            "Epoch 10/30\n",
            "169/169 [==============================] - 13s 77ms/step - loss: 0.0660 - acc: 0.9801 - val_loss: 0.1899 - val_acc: 0.9573\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.15853\n",
            "Epoch 11/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.0620 - acc: 0.9801 - val_loss: 0.1652 - val_acc: 0.9556\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.15853\n",
            "Epoch 12/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0716 - acc: 0.9762 - val_loss: 0.1644 - val_acc: 0.9556\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.15853\n",
            "Epoch 13/30\n",
            "169/169 [==============================] - 14s 85ms/step - loss: 0.0461 - acc: 0.9854 - val_loss: 0.1649 - val_acc: 0.9591\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.15853\n",
            "Epoch 14/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0488 - acc: 0.9871 - val_loss: 0.1890 - val_acc: 0.9591\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.15853\n",
            "\n",
            "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
            "Epoch 15/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0272 - acc: 0.9917 - val_loss: 0.1708 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.15853\n",
            "Epoch 16/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0322 - acc: 0.9916 - val_loss: 0.1745 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.15853\n",
            "Epoch 17/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.0198 - acc: 0.9962 - val_loss: 0.1747 - val_acc: 0.9627\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.15853\n",
            "Epoch 18/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0261 - acc: 0.9913 - val_loss: 0.1763 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.15853\n",
            "Epoch 19/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.0329 - acc: 0.9879 - val_loss: 0.1754 - val_acc: 0.9653\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.15853\n",
            "Epoch 20/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.0262 - acc: 0.9897 - val_loss: 0.1760 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.15853\n",
            "Epoch 21/30\n",
            "169/169 [==============================] - 13s 74ms/step - loss: 0.0163 - acc: 0.9953 - val_loss: 0.1815 - val_acc: 0.9653\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.15853\n",
            "Epoch 22/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0165 - acc: 0.9937 - val_loss: 0.1822 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.15853\n",
            "Epoch 23/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.0157 - acc: 0.9954 - val_loss: 0.1811 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.15853\n",
            "Epoch 24/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0174 - acc: 0.9941 - val_loss: 0.1835 - val_acc: 0.9662\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.15853\n",
            "\n",
            "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "Epoch 25/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0140 - acc: 0.9958 - val_loss: 0.1833 - val_acc: 0.9653\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.15853\n",
            "Epoch 26/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0189 - acc: 0.9936 - val_loss: 0.1843 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.15853\n",
            "Epoch 27/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.0170 - acc: 0.9945 - val_loss: 0.1848 - val_acc: 0.9644\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.15853\n",
            "Epoch 28/30\n",
            "169/169 [==============================] - 13s 76ms/step - loss: 0.0178 - acc: 0.9949 - val_loss: 0.1851 - val_acc: 0.9636\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.15853\n",
            "Epoch 29/30\n",
            "169/169 [==============================] - 13s 74ms/step - loss: 0.0171 - acc: 0.9952 - val_loss: 0.1854 - val_acc: 0.9636\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.15853\n",
            "Epoch 30/30\n",
            "169/169 [==============================] - 13s 75ms/step - loss: 0.0131 - acc: 0.9969 - val_loss: 0.1852 - val_acc: 0.9636\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.15853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGgmmmbNWMIP",
        "outputId": "dc9acaf5-3675-4dd5-cf87-0340a2ab34c2"
      },
      "source": [
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.18524613976478577\n",
            "Test accuracy: 0.9635555744171143\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "krBeAg-2WMIQ",
        "outputId": "0ba90b7b-f703-4785-e9c0-1c65ad3052a2"
      },
      "source": [
        "plt.plot(history.history['acc'],label=\"accuracy\")\n",
        "plt.plot(history.history['val_acc'],label=\"val_accuracy\")\n",
        "plt.plot(history.history['loss'],label=\"loss\")\n",
        "plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.title(\"FR Feature Selection\")\n",
        "plt.xlabel('epoch')\n"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epoch')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eLP8aEDWMIQ"
      },
      "source": [
        "## Save the model/weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_T48k5-PWMIQ",
        "outputId": "788c47b9-c9f7-4cd9-8b80-52ae51284065"
      },
      "source": [
        "# JSON JSON\n",
        "# serialize model to json\n",
        "json_model = model.to_json()\n",
        "\n",
        "# save the model architecture to JSON file\n",
        "with open('{}/{}.model.json'.format(output_dir, model_name), 'w') as json_file:\n",
        "    json_file.write(json_model)\n",
        "\n",
        "\n",
        "# YAML YAML\n",
        "# serialize model to YAML\n",
        "model_yaml = model.to_yaml()\n",
        "\n",
        "# save the model architecture to YAML file\n",
        "with open(\"{}/{}.model.yaml\".format(output_dir, model_name), \"w\") as yaml_file:\n",
        "    yaml_file.write(model_yaml)\n",
        "\n",
        "\n",
        "# WEIGHTS HDF5\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"{}/{}.model.h5\".format(output_dir,model_name))\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujUx01jlWMIQ",
        "outputId": "c05e43cc-0945-4d27-f0cc-14a6081ee005"
      },
      "source": [
        "# Open the handle\n",
        "json_file = open('{}/{}.model.json'.format(output_dir, model_name), 'r')\n",
        "\n",
        "# load json and create model\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "# load weights into new model\n",
        "loaded_model.load_weights('{}/{}.model.h5'.format(output_dir, model_name))\n",
        "print(\"Loaded model from disk\")\n",
        "# loaded_model_json"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnWNemmfWMIR",
        "outputId": "ce3c67f2-c67e-4db2-ca31-8f14d86be2ca"
      },
      "source": [
        "# evaluate loaded model on test data\n",
        "loaded_model.compile(loss='categorical_crossentropy', optimizer='sgd', \n",
        "                     metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test score: 0.18524613976478577\n",
            "Test accuracy: 0.9635555744171143\n",
            "accuracy: 96.36%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}